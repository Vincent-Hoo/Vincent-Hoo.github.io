<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Nameless rookie</title>
  
  <subtitle>keep foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://vincentho.name/"/>
  <updated>2022-07-05T12:27:53.477Z</updated>
  <id>http://vincentho.name/</id>
  
  <author>
    <name>Vincent Ho</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>致逝去的三年研究生时光</title>
    <link href="http://vincentho.name/2022/07/05/%E8%87%B4%E9%80%9D%E5%8E%BB%E7%9A%84%E4%B8%89%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%97%B6%E5%85%89/"/>
    <id>http://vincentho.name/2022/07/05/致逝去的三年研究生时光/</id>
    <published>2022-07-05T12:20:34.000Z</published>
    <updated>2022-07-05T12:27:53.477Z</updated>
    
    <content type="html"><![CDATA[<img src="/2022/07/05/%E8%87%B4%E9%80%9D%E5%8E%BB%E7%9A%84%E4%B8%89%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%97%B6%E5%85%89/cover.jpeg" class="" width="500" height="500"><p>2022年7月4日，星期一，阴雨，7月7日就要入职了，6月29日回家休息了几天，马上就要开始新的生活，结束了7年大学生活，也结束了19年的学生生涯，可以说出生到现在的25年里，有八成的时间都在学校做学生，马上就要拥有新的社会人身份了，感慨万千，还是像本科一样总结一下过去的三年研究生生活吧，对比本科的各种悲剧收尾，研究生还是有很多值得纪念的难忘瞬间的，下面从各个方面总结研究生的三年：学校学院篇、科研工作篇、课外活动篇、朋友篇。</p><span id="more"></span><p><br></p><h2 id="学校学院篇"><a href="#学校学院篇" class="headerlink" title="学校学院篇"></a>学校学院篇</h2><p>其实我现在能拿到清华大学的研究生毕业证和计算机一级学科的学位证，我应该感谢我的学院：清华-伯克利深圳学院，还有当时面试看上我的夏树涛老师。按照我本科的成绩，我应该是进不去清华的，当时我保研夏令营拿到的offer也就只有南京大学和中大，清华和北大的夏令营连入营资格都没有，邮件套辞也没有什么回复，因为我的成绩和简历根本不够。但当时在保研论坛给我注意到了清华-伯克利深圳学院（TBSI），一开始投简历的时候就觉得这个学院很international，各种材料都需要中英文两份，夏令营也基本都是英文展示，面试也是英文的，当时大三的我，是在出国和国内读研之间纠结的，但是遇到TBSI，当时就想那不是完美解决了我的纠结了吗，研一在国内读，研二去美国伯克利读，但后面问了一些当时在tbsi的师兄师姐了解了之后发现，其实没多少人去伯克利的，大多数也都是在深圳读三年，因为去伯克利是完全自己自费，并且拿到的学位也不是很有用的学位，好像是什么领导力学位啥的，上的课也都是很普通的课，就感觉含金量非常低。所以到了九月份的到最后决定的时候，我又还在南京大学和清华深研院之间纠结，当时我参加TBSI的夏令营面试，面试官之一就是夏树涛老师，当时我面试完就受到夏树涛老师的短信，说让我去他办公室聊一下，我当时就感到很奇怪，因为我在tbsi的官网里，并没有看到夏老师的信息，但不知道为啥他会出现在tbsi的面试，后来在我了解之后，原来夏老师和江勇老师是比较好的朋友，然后江勇老师是在tbsi有名额的，并且会把他在tbsi的学生交给夏老师来带，所以夏老师才会出现在tbsi的面试里面，而夏老师是计算机系在深研院的扛把子，所以选择tbsi的话，我就能拿到计算机的学位，也能认识计算机系的同学，并且清华的牌子也是南大比不了的，即使在深研院，在各种因素的驱动下，我最终就选择了清华，扎根在深研院，对于我这种广东人来说，有好有坏吧，好处是考虑到以后找工作大概率在珠三角这边，所以在深圳上学的话，实习比较方便，而坏处就是读了那么多年书，都没出过省，没在其他地方长时间生活过，多多少少也是一种遗憾吧，并且在深研院读，而不是在北京本部读，也少了一些归属感吧，本来想毕业典礼能够去北京的，也因为疫情的原因去不了，更是遗憾中的遗憾吧。</p><p>南国清华，坐落在深圳大学城，地铁7号线终点站西丽湖站，大学城由清华北大哈工大三所学校组成，这里真的好小，跟本科任何一个校区都没法比，宿舍饭堂实验室就在一块，没有特别多的活动（这个就很想吐槽了，隔壁北大的学生会真的很会办活动好吗，为什么咱们清华啥活动都没有呢，只能表示羡慕了）。再来谈谈tbsi吧，其实我比绝大多数人都要更早地了解到真正的tbsi，可能在外人看来tbsi很高级，毕竟是和伯克利一起办学的，吹嘘的很多东西都很高级：三个中心，三条track，双导师等等，但实际上伯克利的老师基本都是挂名而已，甚至很多国内的老师也只是挂名（包括我的导师江勇老师），真正在深圳科研教学的老师少之又少，我在读研之前就已经知道这个状况了，但幸好我是跟在夏老师的课题组，实验室的同学也都是计算机系的同学，所以我没有太觉得自己是tbsi的，反而我更觉得自己是计算机系的（最后也是拿的计算机的学位）。所以对比其他tbsi的同学，我觉得我很幸运了，可以在夏老师的课题组，蹭到计算机系的光，如果不是夏老师捞了我，我都不知道我在tbsi能选哪个实验室，感觉就没有自己感兴趣的实验室了。研二的时候，据说伯克利那边没有和清华继续合作了，因此tbsi的一三中心也并入了深研院，只剩下一个二中心继续挂羊头卖狗肉。另外tbsi三年里换了无数个行政和教务老师，每一个都做不长久，也不知道为什么，可能这就是tbsi吧，虽然我在这里疯狂吐槽tbsi，但我又要非常感谢tbsi，没有tbsi，我硕士进不了清华，我进不去夏老师课题组，拿不到计算机学位，感谢tbsi！</p><p>其实我来到清华，我是挺自卑的，因为我觉得身边的同学都挺优秀的，特别是本科就在清华的同学，这里每个人都或多或少有些特长和技能，而我总觉得自己是那么的普通，可能就只是本科的时候会读书会考试所以成绩稍微好了一点，然后又恰逢给tbsi这种像调剂专业一样的学院给捞了，才来到的清华读研。每次家庭聚会，都会听到某些夸赞我在清华上学的声音，说实话，听到这些声音的时候，我总会觉得很尴尬，除了一笑了之和说谢谢之外，也不知道怎么回应，清华对比其他大学，在一般人眼里显得太过显著了，毕竟大家都会知道清华北大，而其他好大学可能一般人都没什么耳闻，也不会一直记着，但家族里有一个人在清华读书，就会被大家所铭记，这也成为了我的一种负担，有时在想，我真的达到了一个清华人应有的水平了吗，我真的是个合格的清华人吗，清华人该有的那种自强不息厚德的家国情怀我有吗，清华人为祖国健康工作五十年的体魄我有吗，这些灵魂拷问会使我为自己的清华人的身份而感到困惑，以至于有时候有人问我在哪个大学读书，我都不能很自豪很大方地和别人说我在清华读书，这种压力来自于人们对于清华学子的那种高期待，会觉得清华人是那种天之骄子，赚大钱做大事的人，但当他知道你可能没有达到他的预期的时候，这种落差可能尤为明显，因为我知道我自己真的是一个普通人，我的工作能力学习能力等可能还不如一个别的学校的同学，我可能真的是个水货，但我也希望自己不要妄自菲薄，虽然我不能做很多很宏大的事情，虽然我很平凡，但我不平淡，我能来到清华，我一定有比其他人优胜的地方，只是我们常常都是当局者迷，不会发现自己的美罢了，清华三年，带给我的肯定不仅仅是一张毕业证，在这里我也留下了很多深刻的回忆，我成长了不少，认清了自己的实力范围，以后挺起胸膛，骄傲地和别人说，我硕士毕业于清华大学，专业是计算机科学与技术！</p><h2 id="科研工作篇"><a href="#科研工作篇" class="headerlink" title="科研工作篇"></a>科研工作篇</h2><p>在本科的总结篇章里，我并没有过多地说到我本科的学习经历，只是说了我经常泡图书馆，那是因为本科的学习并没有给我带来过多的困扰，大多数课程也都在我的能力范围里，因此只要我认真上课完成作业，期末复习，就能取得不错的成绩。而计算机专业的研究生对比本科，毕业要求完全不同，本科更多的是上课考试，毕业要求仅仅是修够学分不挂科即可，而我们专业的研究生的毕业要求除了要修少量的学分外，还要发表论文，tbsi的毕业要求对于论文完全没有要求，而计算机专业或者说我们导师的要求是发表一篇清华计算机系B类论文即可，而三年里只有第一年有课程，并且课程不多且成绩不是那么重要，所以三年里极大部分时间都会是在做科研和发论文。</p><p>但说实话，我的科研道路真的不是那么顺利，这也导致我的科研热情不断消退，大四的时候我就已经来到这边做本科的毕业论文了，在深圳呆了几个月，刚开始戴涛师兄让我尝试下知识蒸馏在超分应用下是否可行，刚接触计算机视觉的我，花了大半个月的时间才入门，然后就开始我的科研之路了，说实话，我到现在都没有找到做科研的窍门，按道理做科研首先要从问题出发，找到问题，然后解决问题，但由于深度学习过度的玄学化，就会导致一个想法看着挺合理的，但是实验却不work，或者一个想法挺不合理的，但是实验却work了，而大四的我压根不懂得如何发现问题和解决问题（其实到现在我也不懂，所以很羡慕其他同学他们懂得分析任务本身的特殊性，再从中找到改进的地方），所以我的科研方法就是其他方法的迁移和拼凑，看到一个比较有趣的论文方法，就想着套过来看看有没有用，但结果大多数都是不太行的，就这样大四做毕业论文的时候就疯狂迁移和尝试各种方法，还有调节更种超参数（这在AI领域称为炼丹），要知道跑一个超分的实验可是要一天半到两天的，就这样我还跑了几十个实验，这个时间成本是很高的，但即使我跑了那么多的实验，实验结果也还是很不理想，最终就把这个半成品写成了本科毕业论文，当时大四在夏老师课题组组会上汇报的时候，当我汇报完我的毕业论文，我都尴尬地想找个洞钻进去了，要创新性没创新性，要好的实验效果也没有，看着别的同学的实验方法，都是一二三列举的，然后分别针对什么问题，做出什么改进什么解决方法，而我的方法就只是个简单的合并和套用，也说不出来为什么要这样做（记得我在wxg实习的mentor和我说，方法的依据很重要，要突出每一步的逻辑严谨性），但就这样的一篇毕业论文，竟然还拿到了本科优秀毕业论文，我简直一个大无语了，可能本科做AI方向的同学不多吧，真正懂行的都知道这是一个什么烂工作。。</p><p>对于我身边的同学，本科毕业论文都只是科研道路上的小试牛刀，但谁能想到我本科毕业论文的这个工作（简称超分蒸馏）竟然也是我硕士毕业论文的一个工作，那就是意味着我研究生三年都没有做出什么其他能够写进硕士毕业论文的的科研成果，确实是一件很丢人的事，可能也就只有我是这样吧。研究生一年级，戴涛师兄建议我把本科毕业论文投稿出去，一来是把之前那个半成品工作收个尾，二来是如果文章中了就能满足毕业要求了，以后就不用为毕业苦恼，就这样我又开始我的科研之旅了，同样还是各种玄学调参数和尝试（苦笑），但幸运的是，这次竟然给我找到了一个有用的方法，实验结果也好看了许多，这个工作终于可以收个尾了，于是就开始整理实验，开始写论文准备投稿10月的ICASSP（ccf-b类会议，清华列表也是b类），对比很多同学，我算是比较早就开始投稿论文的了，毕竟8月底才开学，我10月份就投稿论文了，研究生第一次写英文学术论文，第一次用latex，也是困难重重，但最终还是投出去了。投完这个工作之后，我就感觉我自己已经能够毕业了，但显然投稿的结果也没出，也不是必中，即使是必中，也还有两年半才要毕业，难道就不继续科研吗？但当时的我确实是这样想的，投完稿之后我的科研就停了，记忆中好像很少一段时间都没怎么科研看论文，也没人监督我啥的，也没啥idea，再加上当时被拉去做vivo的项目，所以好像就没怎么科研。但这篇我看来好像一定会中的论文究竟中没中呢？答案是否定的，印象非常深刻，ICASSP公布结果是在2020年的大年初一，当时群里好多同学都中了论文，新春佳节+中稿论文，多么开心的事情，但我没中，多多少少有点失落和遗憾吧，而我也知道科研路从来都不是一帆风顺的，就这样春节休息了几天之后，我就开始改论文和做实验，将原来的论文改投到ICIP（另外一个毕业神会），而幸运的是，这次论文终于中稿了，也是达到了实验室的毕业要求，意味着可以毕业了。</p><p>2020年春，当时疫情很严重，在家隔离的期间，基本就在做项目，vivo项目和悦动圈项目，完全没有做科研，还记得当时戴涛师兄问我科研进展的时候，我都哑口无言。就这样到了暑假，我听说实验室很多同学都去实习了，有腾讯AI Lab的，有华为诺亚实验室的等，而且都是科研岗，说白了就是去公司做科研，有mentor指导，那时我也想去公司做科研发论文，因为在学校实验室基本没人指导，而我又不知道怎么做科研，而在公司的话，有服务器有人指导有讨论，并且目标就是发论文，这样科研起来会更加顺利。就这样我也投了几个公司，最开始面试我的是商汤，面了一轮就录用了，hr给我打电话说是工程岗，一听就是那种特别缺人干工程的岗位，不然也不会就只有一轮面试，所以我拒绝了。后面我投了腾讯的teg，当时的官网还只能具体到bg，不能具体到部门，因为我也想去ai lab做科研，但没想到teg的没捞我的简历，反而ieg的捞了我，面了两三轮后就过了，我当时也没仔细问是不是科研岗，发论文啥的，就稀里糊涂地答应了，现在想起来是真的很后悔，去的部门是ieg的光子学习发展组，去了三个月，啥东西都没做，也有可能是我去得晚，我7月再去，当时的暑期实习生8月就答辩了，而我是日常实习生，当时给我的任务就是交接某一个暑期实习生的工作，然后一交接就交接了一个月，每天无所事事就是看他的代码和文档，然后全程mentor也没有和我讨论啥的，也没有管我，就一个星期或者两个星期丢给我一两篇论文让我看看能不能用到项目里，我印象很深刻的是，当时坐我旁边那个实习生和我聊天说到，这个组招很多实习生，但又不管，并且也全部不能转正留用，完全不懂为啥要招那么多人，她因为是不考虑转正的，mentor也没给她布置任务，她每天就在工位准备秋招，真正的带薪摸鱼，就这样我呆了三个月就离职了，离职之后没有继续找实习又是一个错误的决定，起码在现在看来是的，当时离职的另外一个原因是回学校和实验室同学打算一起投稿一篇cvpr，毕竟谁能拒绝cvpr这种顶级会议的魅力呢，简历上多一篇cvpr加的分可不是一点点，大家都知道都认可cvpr，但很少人知道icip这种水会，想着再发一篇论文，我就离职回学校继续科研了，当时三个人合作，最开始的时候决定给我第三作者，但怎么说呢，我很积极讨论，也很积极地写论文，甚至idea很大一部分也是我提的（虽然又是把别人的方法迁移过来），只是我没有参与过实验部分（实验部分是刘沛东用华为的服务器跑的实验），最终改为大家都是共同第一作者，我是第三个，同样很幸运的是，实验work了，我们也顺利投稿出去了，但没中，后面改投了ACMMM2021，幸运的是中了，虽然MM没有cvpr出名，但也比icip好不少了，这也是我研究生阶段唯二的论文了。</p><p>上面说到我没有继续找实习是一个错误的决定，因为我高估了自己的科研能力，当时2020年11月份投稿完cvpr后，我就尝试自己做科研，自己尝试idea做实验（其实又是简单拼凑和迁移。。），结果可想而知，就是没有进展，那个时候实验室的同学基本都出去实习了，他们都是科研岗，都是拿着工资在公司做科研，还有mentor指导讨论，而我没工资，自己一个人在实验室做科研，心酸。所以我说我在ieg的那份实习很失败，别人研二的实习都是半年以上的，长的能达一年，然后都有不少的科研成果产出，而我去ieg一来不是科研岗，mentor也不管，二来时间短，就是纯纯的浪费时间，当时如果自己的目标更加明确一点，更加清楚知道自己想要什么的话，我可能会更加果断，更早离职去找下一份科研实习，或者说如果我不那么急答应ieg那边，等学校和优图的专业实践会不会更好一点呢，毕竟优图就是类似AI Lab的科研部门，但没有如果了。</p><p>后面当我意识到我不能自己一个人漫无目的的科研时，已经太晚了，我那个时候再去投简历，别人已经不招人了，并且时间马上就来到研二下学期，要开始找暑期实习和秋招了，所以我也没再找要发论文的科研岗了，而是选择对以后工作更有帮助的业务部门，这里感谢我本科的inpluslab，不得不说本科实验室的资源是真的丰富，我暑期实习就是靠着本科实验室师兄的内推才能去到的广州wxg实习，在wxg实习的四个月里面，给我布置了一个不适图片检测的任务，四个月里面，我其实没有干太多的工作，可能是前两年没有受到科研思维的训练，我在想解决方案的时候，思维会比较局限，然后遇到问题了，也不会解决，因此最终也没有很好的完成这个任务，虽说最后还是转正成功了，马上就要入职工作了，我真的很怕以后工作的时候会应付不来，毕竟我实习的时候就是很不适应，但也希望以后工作能慢慢培养出自己的一套方法论吧，但可能就需要付出沉重的试错成本吧。</p><p>秋招结束决定了工作后的研三，可能慢慢地习惯了自己不适合科研，科研热情早就被燃尽了，到了要写毕业论文的时候，才又草草地做了一个工作出来，这里感谢白杨师姐的帮助，幸运的是实验work了，不然我的毕业论文是真的愁死。</p><p>曾几何时，我也希望有一个mentor能够手把手地教我科研，能到一个科研岗，或者科研氛围强一点的小组，每天头脑风暴，分享论文，可惜我没有遇到，或许我遇到了，但归根到底羊毛出在羊身上，我对科研的那把火始终没有燃烧地特别旺盛，对未知的探索也不那么激动，有时候听别人分享论文，听不懂的地方也不会追问，就我这种需要人推着前进的人，怎么能做好科研，毕竟科研本身就是孤独的，有的人能够沉的住这种孤独，能够自我驱动，而我不是这种人，对比本科的学习，本科更多的是考试这种有标准答案的题目，而研究生的科研、未来工作上布置给你的任务，更多是那些不存在唯一解的题目，可能需要你更多的自我思考，需要你有一定的探索能力和创新能力，这也是我在本科的时候很少训练自己的能力。另外我觉得自己对于我自己从事的这个行业并不是特别的感兴趣，有些人喜欢去看每天都有什么好论文，什么best paper啥的，而我压根不关注这些，久而久之，我的知识面就变得非常窄，在想解决方案的时候也少能发散思维，因此在后面的工作中，也是需要提高自己知识面的广度，少看一点b站游戏，每天看下论文推送吧哈哈！</p><h2 id="课外活动篇"><a href="#课外活动篇" class="headerlink" title="课外活动篇"></a>课外活动篇</h2><p>本科四年，我都很少有参加其他课外活动，也就只有大一的时候参加了一下合唱团和学生会，大二开始就没有参加过任何的社团和课外活动了，所以我本科基本就一直在图书馆学习，生活极其无聊，可能唯一的课外活动就是打打球，看看电影啥的吧，但可能也是因为本科的学习比较重要，学习比较有目标（考试，保研，考英语啥的），所以花了很多时间在学习上，这样想没有本科四年的学习又怎能上得了清华的研究生呢。而研究生三年，对比本科四年的学习，科研是比较没有目标的，并且也没有必须要上的课程，时间安排上就会比本科要多很多，甚至没有了周中和周末的概念，而上面也说了，研究生的我在科研上比较喜欢摆烂，所以就多了很多分配给课外活动的时间，因此研究生我尝试了很多课外活动，生活相较本科丰富了不少，也留下了不少难忘的时刻。</p><p>研一的时候又重新加入了合唱团，本科是在男高声部，研究生尝试了一下男低声部，果然是难唱的一批，基本没有主旋律可言，但也不为是一种新的尝试了。加入了合唱团后，有幸能参加深圳举办的国庆70周年大型交响合唱演出——祖国颂，合唱的曲目分为上下两个乐章，第一乐章是关于祖国的组曲，第二乐章是黄河大合唱，参加这次演出我非常的自豪，并且现场指挥的是姚贝娜的父亲姚峰老师，到现在，这次演出合唱的曲目还在我的歌单里面，每每播放这个歌单，我都能感到很激动澎湃，能为自己出生在神州大地、生活在中国而自豪！然后就到了学校举办129合唱的时候，一班班长看我是在合唱团，就把我拉去组织同学合唱，我也当了一回指挥，教其他人唱旋律，果然当指挥是很难的事，相对于合唱队员只用学会自己的旋律，指挥要学会每一个声部的旋律，还要准确地引领每一个声部进行演唱，是个非常有挑战的工作，唱的两首歌曲也是非常红的歌曲，分别是在灿烂阳光下和另外一首忘了，演出的当晚，由于我们tbsi是在最后一个学部演唱，然后唱完之后要光速换衣服参加合唱团的压轴演出，于是就有了我光速换衣的一幕了哈哈，tbsi合唱穿的是军装，而合唱团要求是西装，于是我就把西裤衬衫穿里面，然后唱完，马上脱掉军装，套上外套换个皮鞋急匆匆地上台了哈哈，然后后面有同学把我脱下来的衣服收好，合唱团唱的歌是东方之珠，恰逢最近香港回归25周年，这首歌又再一次进入了人们的眼前，也是一首能唤起很多记忆的歌了，研一下学期疫情在家，参与了合唱团的原创抗疫歌曲的录制，也是挺自豪的，然后到了研二就没再去合唱团了，一是热情消退了（可能本身也不怎么热爱合唱吧，还是喜欢自己瞎唱做个浴室歌手），二是社恐的我，合唱团里都是新人，没我认识的，我就不想去了，至此我学生时代的合唱生涯就结束了。</p><p>相对于唱歌这个我一直伴随着我的兴趣，研究生阶段我尝试了跳舞，首先是迎新晚会上和tbsi的其他同学一起尝试了一些简单的舞蹈。然后当时社团招新，我有两个选择，一是街舞，二是国标舞（摩登和拉丁），我选择了后者，但其实现在回想起来，可能街舞更适合我这种完全零基础的人，毕竟街舞要相对简单一点，国标舞，尤其是拉丁，太要求时间的积累了，很多跳拉丁的同学都是小时候学过的，这对于零基础的我十分困难，所以研一刚开始试跳了两节课之后，我也放弃了拉丁舞，专心跳摩登舞，摩登舞相对于拉丁舞，可能对于新手稍微适合一点，也会更加适合social，但因为跳摩登舞需要讲究两个人的配合，但是我们上课是没有固定的舞伴的，每节课可能都会和不同的人跳，这其实对于新手是不友好的，因为两个人需要磨合，对于新手的我，没有一个固定的舞伴，进步就会非常慢。但幸运的是，研一上学期隔壁汇丰商学院举办假面舞会，然后我有幸能参加表演，这其实对于我来说，既是机遇又是挑战吧，因为刚学跳舞没多久就要上台，好在我的舞伴稍微老道一点，然后我们一遍遍的抠动作，磨合，才勉强跟上了其他人，但是最后表演的时候，或许还是太紧张了，我们表演一共五对，只有我疯狂在抢拍，并且也没和其他四对跳到一块去，就特别尴尬，以前本科总是以合唱队员的身份上台演出，有一堆人在身边安全感很够，但现在作为舞蹈者站在舞台，本来在舞台上就只能有平时的五成不到，一紧张，3成都没了，但是也算是一种不一样的体验吧。接下来的两年里，我也断断续续地在上摩登舞的课，和国标队的小伙伴们也逐渐混熟，一起参加过一些舞蹈相关的活动，比如研二的男生节舞会的开场表演，然后研三的时候他们国标队的去溧阳参加国标舞的比赛，叫上了我让我做领队，我也十分乐意，虽然我自己不能参加比赛，也不敢参加（毕竟是个新手），但能看到很多专业选手同台竞技也是一种享受。</p><p>虽然我硕士的三年经常吐槽南国清华这边没什么氛围，羡慕北京本部啥的，但现在想想我应该感谢深研院，因为要不是深研院这边人少，很多活动可能压根就轮不到我去参加，我也不会有那么多不一样的体验，就比如研二的时候为了庆祝国庆，深研院这边就打算录制《我和我的祖国》再做个mv给祖国母亲献礼，当时就在招募歌手，我厚着脸皮报名了，没想到报名的就没几个，最终我也入选了，去了录音室录歌，这也是我第一次去录音室，在其他同学面前，疯狂地唱一句还唱不好，属实有点尴尬。然后研二下学期，为了庆祝清华110周年，深研院这边也打算拍一个mv，也是同样的招募歌手拍摄mv，但这次不用我们唱了，就单纯拍mv而已，我又是厚着脸皮报名了，然后又是没什么人报名，我又蹭到了一次拍摄mv的体验，那天还正好是4.2我的生日，你说是不是值得纪念，但可惜的是后面做的mv本部那边没有接收，但我觉得不遗憾，我有不一样的体验就够了，并且正片花絮啥的原视频我也拿到了，以后拿来纪念也好。所以说嘛，深研院人少确实挺好的，只要你够勇敢，机会就是你的，另外研二参加了学校的十大歌手比赛，我虽然说一直都喜欢唱歌，喜欢录歌，也被各种同学夸赞唱歌好听，但其实我知道我唱歌有很多不足，只是外人看不出来罢了，要不然我怎么会一直在本科参加维纳斯歌手比赛都是一轮游呢，来到深研院这边，我继续参加唱歌比赛，人少的好处就是，我终于打破了多年一轮游的命运，成功进入了复赛，当时还想着如果进入决赛，我就唱《爱是永恒》，朋友圈文案我都想好了，就是有始有终，爱是永恒开始（本科第一次参加比赛就是唱的这个），爱是永恒结束。做梦真的好，梦里什么都有，但现实就是复赛被刷了，其实我早就认清了自己的实力了，我就是一个ktv歌手，我就喜欢瞎唱，但有时候发下白日梦也挺好的哈哈。另外还有一件值得纪念的事就是，当时加入了中大跑跑卡丁车车队，然后一起合作演唱了队歌《繁荣山丘》，现在在qq音乐和网易云音乐都能搜到，咱就是说我也是在qq音乐有歌的人了～</p><p>在研究生的三年里，我的民族自豪感在一次次的国庆校庆献礼里得到增强，让我对自己的祖国能有更深的情感。在本科阶段我压根没有尝试过去不同的地方，感受不同地方的文化，四年里就保研的时候去了北京上海南京这三座大城市，毕业旅游去了三亚玩了一会，而研究生三年我去了更多的城市，宁夏、成都、云南、溧阳，让我得以感受更多不同的地方文化，在研一寒假参加了清华的社会实践，去宁夏红寺堡进行十天的地方社会调查，拜访当地人了解当地习俗，参观当地葡萄酒产业等等，因为冬天去，本广东人还第一次感受了一下北方的冬天，暖气、炕、下雪、滑雪等等，</p><p>总的来说，在学业压力较小的研究生三年，我得以尝试不同的东西，体验不同的生活，这一篇章我很满意。</p><h2 id="朋友篇"><a href="#朋友篇" class="headerlink" title="朋友篇"></a>朋友篇</h2><p>还记得本科的朋友篇最终是以悲剧收尾，那研究生的朋友篇呢，庆幸的是，研究生结束了，还是有那么几个还在活跃的群聊，和能聊天的朋友，足矣！希望以后这些群聊会成为我们周末的快乐源泉和吐槽地方，大家晒一晒自己做的饭菜，养的猫狗。</p><p>我研究生阶段活跃的两个群体分别是实验室（尤其是小白菜们，钟昊翔、徐佳、严欣）和国标队的朋友们（尤其是罗阳），我的毕业照基本就是和这两个群体在拍。和小白菜们的“邂逅“发生在研一上学期，当时夏老师拉了一个悦动圈的项目，然后我们研一正好四个人报名了，那时就经常一起去悦动圈公司那里上班做项目，一起打车一起吃饭，渐渐就熟起来了，咱们的小白菜群最开始还是收车费而建的，后来就是一起做项目，一起在腾讯实习，在我影响下开始入坑王者荣耀（虽然现在大家都不玩了，在翔哥的影响下大家都开始玩原神了），一起去顺德吃喝，一起去欢乐谷过万圣节，一起云南毕业旅游，可以说研究生阶段最熟的人就是他们三了，咱们基本每一个生日都是一起过的，除了疫情阻隔外，现在翔哥和佳佳去了杭州蚂蚁工作，我和欣姐都在腾讯，但我在广州她在深圳，希望友谊能长存吧，我们都不是善于表达自己内心情感的人，但我相信他们也是像我这样认为彼此是重要的人。</p><p>另一波比较熟的人是国标队的朋友们，比如钱伟师兄、罗阳、李婉思、杨若凝，他们几个本来就比较熟的，因为他们都是跳国标舞的，并且都有基础，都是国标队的骨干成员，而我是研二才逐渐才和他们熟起来的，但对比他们几个，我就显得很内向很寡言了，因为他们真的太能说了，太能带动气氛了，和他们在一起的时候就会被他们带动着一起各种“哇哦哇哦”的叫（这些是和小白菜们在一起都没有的，毕竟小白菜们都不是很活泼外向的人），因此我在小白菜群体可能我是那个比较活泼的人，但我在国标队群体里我就是比较不说话的人，还有一个原因是我不读博，他们都读博，我是唯一一个出来工作的。这几个人里面最熟的就是罗阳了，他是和我一个班的同学，他和钱伟钱叔都是我初次摩登舞的启蒙老师，最开始也是跳舞课上交流一下，到后面就是经常一起吃饭，出去玩，国标队群体还有一个最爱的活动，就是玩桌游，虽然我玩桌游没什么天赋，但和他们在一起就会很快乐很解压，毕竟他们很有梗，很能带动气氛，“你清醒一点”，“听我说谢谢你”，每次听到都能笑很久哈哈。</p><p>我现在反思我本科的人际关系，比较失败的点在于没有一个可以维系的小群体（比如常说的闺蜜群基友群），而研究生找到两个可维系的群体，以后去深圳还能和他们约约饭啥的，也挺好的。但研究生阶段我觉得我自己的人系关系处理能力还有待提高吧，不知道是不是性格原因，我总喜欢冷处理对待所有有问题的人际关系，我不喜欢将东西摊开说，就解决问题那样，反而总是把东西都藏着掖着，比如研三和舍友在作息上发现了矛盾，然后我们就一个多月没说过话，但其实就是聊一聊相互妥协一下就能解决的问题，我的冷处理就非常愚蠢，所以有时候我很羡慕那些大大方方的人，他们的神经可能比较大条，不会有隔夜仇，睡了一觉啥事就没有了，而我发生了矛盾后，我再看到这个人或者和这个人交流，就会不自觉地想起之前的矛盾，然后不断地强化这个矛盾在我心里的位置，咱就是说是一个恶性循环吧，只能等时间过去，慢慢冲淡了才能解决，和陈煜钊等关系就是这样，我俩本来是很熟的朋友吧，以前都是戴涛师兄带的，也都是做vivo项目，有时候我也去他姐家吃饭，可以说无话不谈吧，但研二我们都去广州微信实习，就决定一起合租，但其实也不是相处容易同住难的问题，而是有一次他和我的对话，让我感觉自己不被尊重，就让我很不爽，自此之后我就没和他聊天，他好像也看出来也没找我聊，从此我们的关系就很普通了，毕业典礼才见到面聊了天，甚至有段时间我还在想他以后工作去深圳不在广州就好了，我们就不会再见面，但是最终他也是选择留在广州，不过现在时间也冲淡了很多东西了，以后我们都在一间公司，也不在一起住了，所有的过去都称为过去了，也可以慢慢熟络回来了。从这就可以看出来，我其实是一种逃避型人格，人际关系遇到问题了就会选择逃避，不主动解决问题，这在所有的关系里面可不是一种好的品质哦，有可能会损失很多朋友，因为没有朋友之间是不发生矛盾和争吵的，那万一发生了争吵，就需要冷静下来解决问题，不要逃避，不要冷处理，希望自己以后这方面能改一下吧。</p><p>研究生阶段的朋友篇，我也挺满意的，收获了一些朋友，以后在广州也有研究生朋友可以一起约起来，希望好好维护一下自己的这些资源吧。</p><p><em>写在最后</em></p><p>感谢清华三年来对我的培养，三年硕士，收获满满，虽有遗憾，不足挂齿，念念不忘，必有回响，愿此去繁花似锦，归来仍是少年。</p><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2022/07/05/%E8%87%B4%E9%80%9D%E5%8E%BB%E7%9A%84%E4%B8%89%E5%B9%B4%E7%A0%94%E7%A9%B6%E7%94%9F%E6%97%B6%E5%85%89/cover.jpeg&quot; class=&quot;&quot; width=&quot;500&quot; height=&quot;500&quot;&gt;
&lt;p&gt;2022年7月4日，星期一，阴雨，7月7日就要入职了，6月29日回家休息了几天，马上就要开始新的生活，结束了7年大学生活，也结束了19年的学生生涯，可以说出生到现在的25年里，有八成的时间都在学校做学生，马上就要拥有新的社会人身份了，感慨万千，还是像本科一样总结一下过去的三年研究生生活吧，对比本科的各种悲剧收尾，研究生还是有很多值得纪念的难忘瞬间的，下面从各个方面总结研究生的三年：学校学院篇、科研工作篇、课外活动篇、朋友篇。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>VIT预训练模型介绍</title>
    <link href="http://vincentho.name/2021/12/14/VIT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/"/>
    <id>http://vincentho.name/2021/12/14/VIT预训练模型介绍/</id>
    <published>2021-12-14T13:12:40.000Z</published>
    <updated>2022-07-05T12:44:37.403Z</updated>
    
    <content type="html"><![CDATA[<p>Transformer 提出后，一大堆基于 transformer 的 NLP 预训练模型被提出，如 BERT、GPT 等，但 transformer 在 CV 领域上的应用却迟迟没能火起来，最近 VIT (vision transformer) 的提出，给 CV community 注入了一剂强心剂，再一次证明了 transformer 是现今最强的特征提取器，按照 NLP 的发展历程，要训练这种 data-hungry 的大规模网络，就必定需要预训练方法，用监督训练的方式肯定是行不通的，需要利用无标注的数据，采取自监督的方法进行预训练。这篇文章将介绍 BEIT 和 MAE 这两种预训练方法</p><blockquote><p>BEIT: BERT Pre-Training of Image Transformers<br>Masked Autoencoders Are Scalable Vision Learners</p></blockquote><span id="more"></span><p><br></p><h3 id="VIT-介绍"><a href="#VIT-介绍" class="headerlink" title="VIT 介绍"></a>VIT 介绍</h3><p>transformer 擅长处理序列数据，因此 NLP 领域可以很自然地利用 transformer 来构造网络，但是 CV 领域处理的是图片视频这些三维的数据，它不具有序列性。要用 transformer 来处理图片数据，就必须得引入序列信息，而 VIT 采取了一种很简单的方法：将图片或特征图（先用 CNN 得到 feature map）切成一块块的 patch，就能构造出一个从左上角到右下角的序列，加入位置编码，引入分类 token，然后再将这个序列输入到 transformer 里面。transformer 的结构对比标准的 transformer 结构也做了一点修改，将 layernorm 的位置提前了。</p><img src="/2021/12/14/VIT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/vit.png" class="" width="700"><p>VIT 整体的训练方式是采取 pre-train 再 finetune 的形式，跟 BERT 一样，VIT 也是有 base、large 和 huge 三种结构，对于这种 data-hungry 的网络，在小数据集（如 cifar10/100）上 train from scratch 肯定很差，因此才需要预训练再微调。VIT 采用的预训练方式是有监督的训练，从上面的网络结构图也能看出，它的预训练任务只能采取分类任务，因此作者采用了三个大分类数据集来做对比，分别是 ImageNet-1k (1.3M)、ImageNet-21k (14M) 和 JFT-18k (303M)，一个数据集比一个数据集大。</p><p>由于网络大，只采取监督训练不能完全训练好网络，因此实验结果总会出现，用 ImageNet-1k 预训练的 VIT-Large 比 VIT-Base 还要差的结果，只有用 JFT 这种超大数据集训练才能训得好，但这样对数据集的要求就太高了，因此需要利用自监督的训练方式来对 VIT 进行预训练。</p><p><br></p><h3 id="BEIT"><a href="#BEIT" class="headerlink" title="BEIT"></a>BEIT</h3><p>BEIT 是参考 BERT 的方式对网络进行预训练的，BERT 是采用 MLM (masked language modeling) 的方式进行预训练，网络结构只用了 encoder，对输入的 sequence 进行随机 mask，然后让网络去预测 mask 掉的 token。</p><p>由于 NLP 的输入的句子是由一个个的 token 组成的，而 token 是从有限的集合中来的，也就是 vocabulary，但是 cv 里，将图片切成一个个 patch 后，这些 patch 不可能从一个有限的 vocabulary 里面得到，如果要按照 BERT 那一套预训练方式，首先需要将 patch 映射到 token，因此作者训练了一个 tokenizer 实现了这个功能，作者把这个叫做 visual token，然后其他的部分和 BERT 保持一致，mask 掉某些 patch，输入到网络，网络预测 masked patch 的 visual token。对于 masking 部分，作者 mask 掉 40% 的 patch，并且不是完全随机 mask，而是提出一种 block-wise 的 masking 方法，详细看论文。</p><p>预训练部分由于采取的是自监督的方式，因此并不需要像原始 VIT 那样需要那么大的监督数据集，作者只采用了 ImageNet-1k 就能取得比较好的结果了。</p><img src="/2021/12/14/VIT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/beit.png" class="" width="700"><p><br></p><h3 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h3><p>MAE 代表 Masked Auto-Encoder，从名字上可以看出，它预训练的方式就是将图片 mask 掉，然后训练一个 auto-encoder 将其复原，这种结构在 cv 里的复原任务里经常能看到，但为什么现在才提出来呢，后面会详细说下 NLP 和 CV 领域的差别。</p><p>整体的结构如下图，首先将图片进行随机 mask，不同 BEIT 的是，MAE mask 的比例高达 70-80%，并且 BEIT 做的是预测 masked token，MAE 做的是恢复 masked patch，并且对于 encoder 的输入，没有输入 masked patch，这是为了保持与 finetune 阶段一致，减少预训练和 finetune 的 gap，其实 bert 采取 8:1:1 的比例 mask 掉 token，也是为了减少这个 gap 的，并且只输入 visible patch，也能减少很多的运算量；然后会将 encoder 的输出加上 mask token，再一同输入到 decoder 进行解码恢复，注意 encoder 和 decoder 都是 VIT 结构，但是 encoder 要比 decoder 大，这是因为 decoder 只用于预训练，finetune 阶段 decoder 将会被去掉，下游任务只会用到 encoder。</p><p>对比 BERT 和 MAE，我们可以发现，其实 BERT 更像是 MAE 的 decoder 部分，MAE 先通过 encoder 得到高级的语义信息，再和 mask token 拼接在一起，输入到 decoder，而 bert 输入是一个个的词，天然就是一种语义信息很高的 token，对比图片的一个个 patch（高冗余）。</p><img src="/2021/12/14/VIT%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/mae.png" class="" width="500" height="500"><p>作者思考过 cv 和 nlp 两个领域在预训练 masked 编码器的区别，主要有三个方面导致 transformer 当初在 cv 领域没火起来。</p><ol><li>CNN 一直是 cv 领域的主流网络，因为图片这种数据适合卷积来操作，而这种 grid 的卷积操作不好加入序列信息，如位置编码或者 mask 信息，这种结构的 gap 直到 VIT 出现才被解决。</li><li>文字和图片的信息密度不同，文字是一种高度语义化的信息，因此 bert 采取 MLM 这种方式，并且只要 mask 15% 就能够很好的充当预训练的功能；但是图片是一种高度冗余的信息，它可以很容易地通过邻近的像素去还原 mask，并不需要很多的高级语义，要解决这种问题，作者提出只要 mask 的比例足够大，也能学习到很多语义信息来充当预训练。</li><li>对于 bert，预测 missing words 是一种高级的语义任务，encoder 的输出就已经有很多高级语义信息了，因此 bert 的 decoder 就只是一个简单的 MLP；而对于 MAE，它是要恢复 pixel，这个相对来说是不需要很多语义信息的，因此 MAE 专门引入了一个 decoder 来做这件事。</li></ol><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Transformer 提出后，一大堆基于 transformer 的 NLP 预训练模型被提出，如 BERT、GPT 等，但 transformer 在 CV 领域上的应用却迟迟没能火起来，最近 VIT (vision transformer) 的提出，给 CV community 注入了一剂强心剂，再一次证明了 transformer 是现今最强的特征提取器，按照 NLP 的发展历程，要训练这种 data-hungry 的大规模网络，就必定需要预训练方法，用监督训练的方式肯定是行不通的，需要利用无标注的数据，采取自监督的方法进行预训练。这篇文章将介绍 BEIT 和 MAE 这两种预训练方法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;BEIT: BERT Pre-Training of Image Transformers&lt;br&gt;Masked Autoencoders Are Scalable Vision Learners&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>BERT的儿子们简介</title>
    <link href="http://vincentho.name/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/"/>
    <id>http://vincentho.name/2021/12/07/BERT的儿子们简介/</id>
    <published>2021-12-07T11:45:40.000Z</published>
    <updated>2022-07-05T12:44:37.252Z</updated>
    
    <content type="html"><![CDATA[<p>Bert 的面世带动了 NLP 预训练模型的蓬勃发展，同时也衍生了很多的 bert 的变种，这里我们介绍一下 bert 的这些变种模型，如 ALBERT，fastbert，tinybert等，看下他们都是做了哪些优化的。</p><span id="more"></span><p><br></p><h3 id="RoBERTa"><a href="#RoBERTa" class="headerlink" title="RoBERTa"></a>RoBERTa</h3><blockquote><p>RoBERTa: A Robustly Optimized BERT Pretraining Approach</p></blockquote><p>roberta 在结构上和 bert 完全一样，只是通过一些其他的方式证明 bert 还没完全训练完，性能还能提升，与 bert 比较，roberta 在预训练的时候做了以下改进</p><p>1：动态 mask：对比 bert 的 mask，稍微好一点</p><ul><li>bert 的训练数据在训练前就全部构造好了，因此对于一个 sample，它的 mask 的位置是固定的，每个 epoch 都是一样</li><li>而 roberta 构造训练数据是在数据输入模型前，这样能保证每个 epoch 的 sample，mask 的位置不同<img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/roberta-1.png" class="" width="500" height="500"></li></ul><p>2： 去掉 NSP 任务，并且更改数据输入格式为全部填充可以跨越多个文档</p><ul><li>结论就是 NSP 任务没什么用，ALBERT 也验证了并换成难度更大的 SOP 任务</li><li>roberta 试验了四种输入格式<ul><li>segment-pair + NSP：就是 bert 的输入格式</li><li>sentence-pair + NSP：输入的是一对句子，前后都是单个句子；对比 segment-pair，这个效果更差，因为两句句子太短了，对比一大段的两段文字，前后关系不好判断。</li><li>full-sentence：如果输入的最大长度为 512，那么就是尽量选择 512 长度的连续句子。如果跨 document 了，就在中间加上一个特殊分隔符。无 NSP。实验使用了这个，因为能够固定 batch size 的大小。</li><li>doc-sentence：输入和 full-sentence 类似，但不能跨两个 document</li></ul></li></ul><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/roberta-2.png" class="" width="500" height="500"><p>3：更多的数据，更大的 batch size，更多的步数，更长的训练时间</p><ul><li>数据：bert：16G，roberta：160G</li><li>batchsize：bert：256，roberta：8k</li></ul><p><br></p><h3 id="ALBERT"><a href="#ALBERT" class="headerlink" title="ALBERT"></a>ALBERT</h3><blockquote><p> ALBERT: A Lite BERT For Self-Supervised Learning Of Language Representations</p></blockquote><p>从论文题目看，albert 是主打 lightweight 的，对比 bert 主要有下面几点改进</p><ol><li>Factorized embedding parameterization：bert 的 embedding 层，每个词向量的大小 E 都和 transformer 隐藏层 H 一样，$E = H = 768$，因此词表占了很大的一个参数量，因此 albert 将 E 和 H 分开，令 $E &lt; H$，通过一个矩阵进行映射即可</li><li>Cross-layer parameter sharing：为了减少网络的参数量，albert 对不同层的参数进行共享，参数共享有三种方式：只共享 feed-forward network 的参数、只共享 attention 的参数、共享全部参数。albert 默认是共享全部参数的</li><li>Inter-sentence coherence loss：去掉 NSP 任务，改做 sentence-order-prediction（SOP）任务，NSP 任务比较简单，模型更多的会通过两个句子的 topic 是否一致来判断，而不是通过句子间的关系来判断，而 SOP 任务直接判断两个句子是正的还是反的，并且两个句子来自同一个文档，topic 保持一致。</li></ol><p>作者实验了以下几种网络参数，通过共享所有层的参数，参数量大幅度下降</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/albert-1.png" class=""><p>其实 Albert 只能做到减少参数量，并不能很好的加快推理速度，因为网络还是那么深，对比 bert-large 和 albert-large，他们唯一不同就在于 embedding 层变小了，但就这一点不同，就有 1.7 倍的加速了；另外我们可以看出共享参数是会掉精度的，这也很好理解</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/albert-2.png" class=""><p>改变 embedding size，对于 bert 和 albert 都有一定影响，128 效果最好</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/albert-3.png" class=""><p>共享不同参数，可以看出 FFN 比较重要，attention 没那么重要，但考虑到压缩量，作者还是选择全部共享</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/albert-4.png" class=""><p>SOP 任务训练可以解决 NSP 任务，但 NSP 任务训练不可以解决 SOP 任务</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/albert-5.png" class=""><p>最后，作者尝试了用更多的数据（roberta的训练数据集），训练更长时间，都能得到提升，并且作者去掉 dropout 也能提升，因为模型还没到过拟合的程度，因此不需要 dropout。</p><p>albert 能做到好的结果，得益于 更大的 H，更多的数据，SOP 任务，dropout 的去除，将这些 trick 应用到 bert 上，bert 也能得到提升。</p><p><br></p><h3 id="BERT-Distillation"><a href="#BERT-Distillation" class="headerlink" title="BERT Distillation"></a>BERT Distillation</h3><blockquote><p>Distilling Task-Specific Knowledge from BERT into Simple Neural Networks.<br>Patient Knowledge Distillation for BERT Model Compression.<br>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.<br>TinyBERT: Distilling BERT for Natural Language Understanding.<br>MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices.<br>MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers.<br>FastBERT: a Self-distilling BERT with Adaptive Inference Time.</p></blockquote><p>上面蒸馏方法的对比如下表，可以看出主要的差别在于</p><ol><li>KD 的阶段是在预训练阶段还是微调阶段</li><li>KD 的位置，从最后的输出 logit 到中间特征层，和 CV 的 KD 一样</li><li>是否用教师网络来初始化学生网络</li></ol><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/distill-table.png" class=""><h4 id="Distilled-BiLSTM"><a href="#Distilled-BiLSTM" class="headerlink" title="Distilled BiLSTM"></a>Distilled BiLSTM</h4><p>教师网络是先将 BERT-large 微调到具体任务，学生网络是 BiLSTM，将教师网络的 logit 输出蒸馏到学生网络的 logit，这里应该是用的教师网络的 [CLS] 的那个logit 输出，距离函数直接用的 MSE，针对不同输入的任务，都是将 lstm 两边的输出拼接然后接 softmax 得到任务的 logit。最终的损失函数为 ground-true label 的 CE loss + 教师网络和学生网络 logit 之间的 MSE（作者发现 MSE 比 CE 好）。</p><p>另外因为 KD 是在 fine-tune 阶段，所以做了 data augmentation。</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/distill-bilstm.png" class="" width="500" height="500"><h4 id="BERT-PKD"><a href="#BERT-PKD" class="headerlink" title="BERT-PKD"></a>BERT-PKD</h4><p>同样是 finetune 阶段的 KD，将 BERT-BASE 在下游任务上进行 finetune 得到教师网络，学生网络同样是 BERT，但是深度比教师网络浅，比如 3 或6 层，因为只是深度减少了，所以可以用教师网络来初始化学生网络，损失函数为下游任务的 ground-true CE loss + 教师网络和学生网络 logit CE loss + 中间层的蒸馏，中间层蒸馏也不是每个 token 都比较，只蒸馏 [CLS]，用的是 MSE loss，中间层的选择有两种，分别是 PKD-last 和 PKD-skip，skip 的结果好一点</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/bert-pkd.png" class="" width="500" height="500"><h4 id="DistilledBert"><a href="#DistilledBert" class="headerlink" title="DistilledBert"></a>DistilledBert</h4><p>前面两个 KD 的工作都是在 finetune 阶段，学生网络从教师网络中学习到的都是 task-specific 的知识，DistilledBert 选择预训练阶段进行蒸馏，也叫做通用蒸馏（general distillation）。</p><ul><li>教师网络是 BERT-base，学生网络为 6 层 bert，采取 PKD-skip 的方式初始化</li><li>训练方式采取 roberta 的方式，去掉 NSP 任务，采取动态 mask，但训练数据和 bert 保持一致，16G</li><li>由于只有 MLM 任务，因此损失函数有 MLM loss，教师网络-学生网络最后一层的交叉熵，除此之外，作者加了一个 cosine embedding loss，比较最后一层 hidden（softmax 层之前）</li></ul><h4 id="Tinybert"><a href="#Tinybert" class="headerlink" title="Tinybert"></a>Tinybert</h4><p>将前面所有工作混在一起，既进行预训练阶段的蒸馏，也进行微调阶段的蒸馏，蒸馏的位置包括输出 logit、中间层特征（attention map，hidden state）、word embedding。</p><p>整体的流程如下，首先有一个教师网络 bert-base，和一个没训练的学生网络，这里不拿教师网络去初始化，因为学生网络的隐藏层和教师网络可能不一样，初始化不了，然后用教师网络进行 general distillation 得到 general tinybert，然后将教师网络在下游任务中进行 finetune，再拿这个 finetune 的教师网络去进行 task-specific 的蒸馏得到 finetune tinybert（有数据增广）。</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/tinybert-1.png" class="" width="500" height="500"><p>损失函数如下，注意 general distillation 没有 logit 的 loss，中间层的蒸馏采用 pkd-skip 的方式对应。</p><ol><li>输出层 logit 采取 CE loss</li><li>中间层 attention map 蒸馏（MSE），用的是未 softmax 之前的 map</li><li>中间层 hidden state 蒸馏（MSE），由于维度不同，会加一个映射矩阵</li><li>embedding 蒸馏（MSE），同样维度不同，也会加一个映射矩阵</li></ol><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/tinybert-2.png" class="" width="700" height="700"><h4 id="miniLM"><a href="#miniLM" class="headerlink" title="miniLM"></a>miniLM</h4><p>这篇论文的方法是最简洁的，也提出了一种新的知识——value-value 矩阵，attention map 是 K 和 V 点乘得到的，而 value-value 矩阵是将 V 矩阵和 V 矩阵的转置进行点乘，然后进行蒸馏；考虑到教师网络和学生网络层数、维度等都不同，所以只蒸馏最后一层，距离度量采取的是 KL 散度；最后引入助教制度，先蒸馏到助教，助教再蒸馏到学生。</p><p>性能的话，还要比 tinybert 和 distilledbert 要好不少，miniLM 只进行 general distillation，简洁效果又好，比 tinybert 蒸馏一大堆性价比高太多了</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/miniLM.png" class="" width="700" height="700"><h4 id="mobileBert"><a href="#mobileBert" class="headerlink" title="mobileBert"></a>mobileBert</h4><p>个人最不喜欢的一篇文章，结构复杂，虽说像 mobilenet 那样引入 bottleneck 的结构，但整体的流程太复杂，不推荐。</p><h4 id="FastBert"><a href="#FastBert" class="headerlink" title="FastBert"></a>FastBert</h4><p>fastbert 参考了 CV 领域里面的 self-distillation 和 adaptive inference 的策略，由于是自蒸馏，因此教师网络就是学生网络，具体流程是：先拿一个预训练好的 bert 模型，在下游任务中进行 finetune 好，然后在每一层 transformer 后加入一个 classifier，这些 classifier 叫做 student classifier，最后一层的 classifier（finetune 好的）叫做 teacher classifier，然后就是自蒸馏的部分，teacher classifier 的输出分别蒸馏给每一个 student classifier，用的是 KL 散度。</p><p>adaptive inference 部分就是对于一个样本，每经过一层 transformer，就经过一个 student classifier，然后输出的 logit，计算不确定性，不确定性用 logit 的 entropy 来表示，如果不确定性低于阈值，就停止往下过网络，反之继续过网络。</p><img src="/2021/12/07/BERT%E7%9A%84%E5%84%BF%E5%AD%90%E4%BB%AC%E7%AE%80%E4%BB%8B/fastbert.png" class="" width="700" height="700">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Bert 的面世带动了 NLP 预训练模型的蓬勃发展，同时也衍生了很多的 bert 的变种，这里我们介绍一下 bert 的这些变种模型，如 ALBERT，fastbert，tinybert等，看下他们都是做了哪些优化的。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>NLP预训练模型概况</title>
    <link href="http://vincentho.name/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/"/>
    <id>http://vincentho.name/2021/12/07/NLP预训练模型概况/</id>
    <published>2021-12-07T11:34:57.000Z</published>
    <updated>2022-07-05T12:44:37.377Z</updated>
    
    <content type="html"><![CDATA[<img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/titan.png" class="" width="700" height="700"><span id="more"></span><p><br><br><em>preview</em><br>预训练模型在 CV 任务里面是非常常见的，通常是用 ImageNet 数据集在一个网络上进行预训练，利用庞大 ImageNet 数据集让网络尽可能学习到更多的通用语义信息，然后下游任务直接用预训练模型进行微调即可，这是 CV 领域非常成熟的一套方法。</p><p>但在 NLP 领域预训练模型迟迟没能面世的原因，可能在于 NLP 的任务多且杂，不同任务的网络设计差异比较大，因此无法做到很好的统一。但这只是我猜测的原因罢了，要说 NLP 的预训练模型，早年的词向量也算是一种预训练模型，把训练好的词向量直接用到下游任务上，但这种预训练模型的效果对比起 CV 领域的预训练模型，效果不太好罢了。直到 transformer 的出现，NLP 的预训练模型才大规模的发展，这篇文章总结一下各科技大公司所提出的 NLP 预训练模型。</p><h3 id="ELMO"><a href="#ELMO" class="headerlink" title="ELMO"></a>ELMO</h3><p>讲 ELMO 前必须先讲下词向量，word2vec 等词向量有一个很严重的问题，就是无法区分多义词，比如 play 这个单词，十几种意思只能融合在一个词向量里面，这样的词向量无法应对所有的语境，虽然后面有一些方法解决多义词的问题，但是都没有很好地解决掉。</p><p>ELMO 是 embedding from language model 的简称，来自《Deep contextualized word representation》论文，它的基本思想是，通过训练一个双向的 LSTM 语言模型，然后得到三种 embedding，分别是最下层的单词 embedding，第一层 LSTM 输出的 embedding，以及第二层 LSTM 输出的 embedding，利用这三种 embedding 就能很好地解决多义词的问题，因为最原始的 embedding 经过语言模型后，会根据不同语境得到不同的语义信息。</p><p>ELMO 训练好后可以很容易的应用到下游任务，整体做法就和词向量作为预训练模型的方法一样，将句子输入到语言模型得到三个 embedding，然后再把这些 embedding 输入到下游任务里面。</p><img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/elmo.jpeg" class="" width="500" height="500"><p><br></p><h3 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h3><p>generative pre-training model，是 OpenAI 2018年提出的模型，利用 transformer 解决各种 NLP 任务，GPT 预训练采用的是单向的语言模型，即根据上文预测下一个可能出现的词，因此 GPT 采用的 transformer 也是单向的 transformer，即将 Encoder 中的 Self-Attention 替换成了 Masked Self-Attention，对于某个 token，只计算与前面 token 的 attention。</p><p>而训练的过程其实非常的简单，就是将句子 n 个词的词向量(第一个为 [start] )加上 Positional Encoding 后输入到 Transfromer 中，n 个输出分别预测该位置的下一个词([start] 预测句子中的第一个词，最后一个词的预测结果不用于语言模型的训练)。由于采用的是 masked self-attention，因此对于某个词的预测，他只能看到前面的词，这样保证了模型的合理性。</p><img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/gpt.png" class="" width="500" height="500"><p>训练好单向的语言模型后，就可以应用到下游任务了，运用少量的带标签数据对模型参数进行微调，上一步中最后一个词的输出我们没有用到，在这一步中就要使用这一个输出来作为下游监督学习的输入，将最后一个词的输出连接到一个 linear 层进行下游任务，不同下游任务的改造如下，因为 GPT 是一个单向的语言模型，整体的过程就好像我让它看完一整个句子，然后问它最后的结果，因此用的也是最后一个 token 的输出来连 linear 层。这一点在后面的 GPT 系列体现更加明显。</p><p>一些题外话：由于 GPT 是一个单向的语言模型，因此它可以做生成任务，即随机给他一段句子，他能写出一段故事来，甚至是给一个新闻标题生成新闻，GPT 问世的时候曾生成过一篇 unicorn 的 fake news，因此现在都拿 unicorn 去表示 GPT。</p><p><br></p><h3 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h3><p>Bidirectional Encoder Representation from Transformer，是 Google 2018 年提出的模型，和 GPT 非常类似，将 GPT 的单向语言模型改成了双向的语言模型，即不用采用 masked self-attention，但在预训练的时候，不能再像 GPT 那样预测下一个词，这时候 BERT 采取的是一种 masked language model(MLM) 的预训练任务，本质上和 word2vec 的 cbow 方法一样，即一个句子随机 mask 一些词，然后利用上下文的词去预测出这个 masked 掉的词，因此有人就形象地这个任务称为完形填空。</p><p>但是，直接将大量的词替换为 [MASK] 标签可能会造成一些问题，模型可能会认为只需要预测 [MASK] 相应的输出就行，其他位置的输出就无所谓。同时Fine-Tuning阶段的输入数据中并没有 [MASK] 标签，也有数据分布不同的问题。为了减轻这样训练带来的影响，BERT采用了如下的方式：</p><ol><li>输入数据中随机选择 15% 的词用于预测，这 15% 的词中，</li><li>80% 的词向量输入时被替换为 [MASK] </li><li>10% 的词的词向量在输入时被替换为其他词的词向量</li><li>另外 10% 保持不动</li></ol><p>BERT 还提出了另外一种预训练方式 NSP(next sentence prediction)，即预测两个句子是否是连着的两句话，与 MLM 同时进行，组成多任务预训练。这种预训练的方式就是往 Transformer 中输入连续的两个句子，左边的句子前面加上一个 [CLS] 标签，两个句子之间使用 [SEP] 标签予以区分，[CLS] 的输出后连一个 linear 层，用来判断两个句子之间是否是连续上下文关系。而其他 masked 的 token 后面也接 linear 层来预测原来被 masked 掉的词。</p><img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/bert-1.png" class="" width="700"><p>为了区分两个句子的前后关系，BERT除了加入了Positional Encoding之外，还两外加入了一个在预训练时需要学习的 Segment Embedding 来区分两个句子。这样一来，BERT的输入就由词向量、位置向量、段向量三个部分相加组成。</p><img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/bert-2.png" class="" width="500" height="500"><p>BERT 的 Fine-Tuning 阶段和 GPT 没有太大区别。将分类预测用的输出向量从 GPT 的最后一个词的输出位置改为了句子开头 [CLS] 的位置了。不同的任务Fine-Tuning的示意图如下：</p><img src="/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/bert-3.png" class="" width="700"><p>总结一下：BERT 借鉴了 ELMO、GPT、CBOW 等方法，本身没有太多的创新，更像是集大成者，但普适性是真的好，在各种任务上都达到了 SOTA 的水平，BERT 和 GPT 给整个 NLP 领域开了个好头，从此之后的预训练模型越做越大，训练的语料越来越多。</p><p><br></p><h3 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h3><p>GPT-2 沿用 GPT 的思路，依旧是单向的语言模型，即上文推断下文，但实现上完全抛弃 fine-tune 阶段，下游任务转为无监督的方式，要实现这个目标，GPT-2 用了一个更大更深的 transformer，堆叠了 48 层，且用了更大的且更高质量的语料库去预训练这个模型。下游任务无监督的方式是指不需要再用特定的任务数据集去微调，直接输入任务的描述以及问题，GPT-2 就会自动生成答案。举个例子，比如机器翻译任务，直接输入“请将下列中文翻译成英文，中文：我爱你，英文：”，然后 GPT-2 就会用它强大的语言模型，预测后面输出的字是 “ I Love You”，这种强大的能力得益于预训练模型的强大，以及语料库的丰富，这就好比如果一个人博览群书，自然就很轻松地就能完成翻译、问答、摘要等任务。</p><p>GPT-2 就好比一个很通用的语言模型，他学习到的知识可能是非常通用的，这才使他能够实现 zero-shot learning（不经过微调直接进行无监督），从 ELMO 到 GPT，再到 BERT，再到 GPT-2、GPT-3，模型规模越发的恐怖，甚至都无法公开因为太大了，如今的发展趋势可能慢慢地从专用模型往通用模型去转变，从少量标签数据到大量高质量无标签数据转变。</p><p><em>references</em></p><ol><li><a href="https://mp.weixin.qq.com/s/IgzOTLsj691mGA5TibLfcQ">从Word Embedding到Bert模型——自然语言处理预训练技术发展史</a></li><li><a href="https://zhuanlan.zhihu.com/p/69290203">Transformer结构及其应用详解—GPT、BERT、MT-DNN、GPT-2</a></li><li><a href="https://github.com/graykode/nlp-tutorial/blob/master/5-2.BERT/BERT.py">bert代码</a></li><li><a href="https://www.bilibili.com/video/BV1Kb4y187G6?spm_id_from=333.999.0.0">bert代码解读</a></li><li><a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=55">李宏毅2021机器学习课程</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2021/12/07/NLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%86%B5/titan.png&quot; class=&quot;&quot; width=&quot;700&quot; height=&quot;700&quot;&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Transformer简单介绍</title>
    <link href="http://vincentho.name/2021/12/07/Transformer%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/"/>
    <id>http://vincentho.name/2021/12/07/Transformer简单介绍/</id>
    <published>2021-12-07T11:30:06.000Z</published>
    <updated>2022-07-05T12:44:37.399Z</updated>
    
    <content type="html"><![CDATA[<p>Transformer 是 Google 在 2017 年发表的 《Attention is all you need》论文中提出的，为了解决机器翻译等 seq2seq 任务中 RNN 不能并行化等问题，transformer 是一个完全由 self-attention 搭建起来的网络，完全抛弃了 CNN 和 RNN 等传统网络结构，从而实现了并行化，到目前为止已经完全取代 RNN 成为自然语言处理领域最好的特征提取器。</p><span id="more"></span><p><br></p><h3 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h3><p>上面提到 transformer 是由 self-attention 搭建起来的网络，这里就先介绍一下 self-attention 机制，NLP 任务的输入往往是一连串的文字，把它看成是一个由多个 token 组成的 sequence，那么 self-attention 想要做的事情就是计算 token 之间的相关性。</p><p>每一个 token 会由三个向量所表征，分别是 Q(query)、K(key) 和 V(value) 向量，当我们需要计算 token A 与其他 token 之间的相似度的时候，就用 token A 的 query 向量去和其他 token 的 key 向量去进行相似度计算，这里的相似度计算采用的是内积（因此 transformer 中的 <strong>Q 向量 和 K 向量的维度必须一致</strong>），内积后进行 softmax 操作得到与各个 token 之间的相似度，然后将相似度与各个 token 的 V 向量进行 weighted sum，最终得到 token A 的输出。其他 token 也是进行同样的操作得到各自的输出。</p><p>上面提到 transformer 可以并行化是因为，我们可以把上述的操作进行矩阵化，把 sequence 里的 token 进行拼接，我们可以得到三个矩阵 Q K V，下图表示的是两个 token，每个 token 的向量都是 3 维，计算出两个 token 的相似度，除以  $\sqrt d_k$ 是为了减小量级，加速收敛，然后进行 weighted sum 得到每个 token 的输出。</p><img src="/2021/12/07/Transformer%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/1.jpeg" class="" width="500" height="500"><p><br></p><h3 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h3><p>上面提到的 self-attention 正是下图的 scaled dot-product attention，Mask 表示的是有目标性地选择 token 去进行 softmax 操作，因为为了方便训练，我们会设置一个超参是 maxlen，表示一个 sequence 的最大长度，少于这个长度的 sequence 会被后面填充特殊 [PAD]，在计算相似度的时候，这些 [PAD] 字符是没有意义的，所以我们要把它 mask 掉，计算真正有意义的 token 之间的相似度。</p><p>而下面右图的 multi-head attention 是 transformer 真正用到，所谓多头注意力机制类似 group convolution，将空间划分成多个子空间，然后再各个子空间里面计算 token 之间的相似度。比如一个 token 是由 512 维的 QKV 向量组成，那么将这些向量划成 8 个头，每个头为 64 份，然后分别对每一份计算 scaled dot-product attention，再把输出结果合并即可，这样做的目的是为了细粒度化，因为特征空间的每一个维度可能都对应着不同的信息，如果对整一个大的空间去进行相似度，可能会不准确，所以将空间切分进行细粒度的相似度计算。</p><img src="/2021/12/07/Transformer%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/2.png" class="" width="500" height="500"><p><br></p><h3 id="positional-encoding"><a href="#positional-encoding" class="headerlink" title="positional encoding"></a>positional encoding</h3><p>上面提到的 self-attention 是可以进行矩阵操作的，因此这也是它可以并行化的原因，但是这同时也失去了时序的信息，我们把一个 sequence 打乱顺序输入，得到的结果会是一样的，因为上面的 self-attention 无法捕捉 token 的位置信息，因此我们需要在词嵌入的基础上加入位置的 embedding。</p><p>transformer 论文提出的位置编码如下，pos 表示第几个 token，i 表示的是 token 的第几个维度</p><img src="/2021/12/07/Transformer%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/3.png" class="" width="500" height="500"><p>作者之所以设置这样的位置编码，是利用了 sin 和 cos 函数的性质，下一个位置的编码向量可以由前面的编码向量线性表示，等价于以一种非常容易学会的方式告诉了网络单词之间的绝对位置，让模型能够轻松学习到相对位置信息。</p><p><br></p><h3 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h3><p>transformer 的整体结构如下，和 seq2seq 模型结构一样，分为 encoder 部分和 decoder 部分，输入的 sequence 首先会对每个 token 进行词嵌入再加入位置编码得到输入的 sequence，然后经过 N=6 个的 encoder 得到输出。然后编码器的输出会输入到每一个的 decoder 里面，而 decoder 同样会有输入，这里详细说下训练和预测两个环节的差异。</p><p>transformer 在预测的时候，decoder 是串行的，比如机器翻译任务，输入中文句子到 encoder 得到输出，然后把 encoder 的输出和一个 [START] 特殊字符同时 输入到 decoder，表示解码任务的开始，然后解码器输出第一个翻译的 token A，然后将 [START] 和 token A 输入到 decoder 进行第二轮的解码，得到第二个翻译的 token B，依此类推，直到输出的 token 为 [END]。</p><p>Transformer 在训练的时候，decoder 是并行的，意味着只进行一轮的解码，假如翻译的句子是“我爱你”，那么翻译的结果应该是“I Love You”，此时 decoder 的输入为 [START] I Love You，decoder 的 ground-true 输出应该是 I Love You [END]，表示我输入 [START] 的时候应该输出 I，输入 I 的时候应该输出 Love。这种做法叫做 teacher-forcing，让训练过程接近预测过程。</p><img src="/2021/12/07/Transformer%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/4.png" class="" width="500" height="500"><h4 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h4><p>编码器共有 N=6 个，每一个的结构都一样，由 multi-head attention 和 feed forward 两部分组成，add &amp; Norm 分别表示残差连接和 LayerNorm，每一个编码器的输入为上一个编码器的输出，输入之后经过矩阵变换分别得到 QKV 三个矩阵，这里采用的是 self-attention，因此输入都是一致的，和后面的解码器区分开来，解码器的 KV 来自于最后一层编码器的输出，Q 来自于解码器 masked 多头注意力的输出。</p><p>layernorm 是对特征空间进行归一化，即对 512 维进行归一化，区别于 batchnorm，是对于每一维的特征在 batch 维度进行归一化。之所以不用 bn，因为 bn 对特征每一个维度进行归一化，显然不同 batch（不同sequence）的某一个特征维度并没有关联，所以 NLP 领域多用 layernorm</p><h4 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h4><p>decoder 的输入有编码器最后一层的输出还有额外的经过位置编码的输入，结构由 maksed 多头注意力模块、encoder-decoder 注意力机制和前向反馈网络组成。</p><p><strong>masked multi-head attention</strong></p><p>这里要注意的是 <strong>masked</strong>，为什么要强调这个 masked 呢？是因为训练过程要模拟预测过程，即我在预测某一个词的时候我是不知道后面的词的，比如输入是 [START] I Love You，对于 Love，我只知道 [START] 和 I，因此在计算相似度的时候，后面的词要全部 mask 掉，包括 pad 的，只计算与前面 token 的相似度后 softmax。</p><p><strong>encoder-decoder attention</strong></p><p>这个区别于 self-attention，是计算输入的 token 和输出的某个 token 之间的 attention，因此 Q 向量来自于 masked 多头注意力的输出，KV 向量来自最后一层 encoder 的输出</p><h4 id="classifier"><a href="#classifier" class="headerlink" title="classifier"></a>classifier</h4><p>decoder 的输出维度为 [batch, sequence_length, d_ff]，然后需要经过一个 linear 层得到 [batch, sequence_length, vocab_size]，因为本质上是一个分类任务，因此 softmax 后与 GT 计算 cross entropy</p><p><em>reference</em></p><ol><li><a href="https://zhuanlan.zhihu.com/p/308301901">https://zhuanlan.zhihu.com/p/308301901</a></li><li><a href="https://zhuanlan.zhihu.com/p/44731789">https://zhuanlan.zhihu.com/p/44731789</a></li><li><a href="https://github.com/graykode/nlp-tutorial/blob/master/5-1.Transformer/Transformer.py">transformer pytorch 实现</a>，注意 mask 的实现</li><li><a href="https://www.bilibili.com/video/BV1dR4y1E7aL?spm_id_from=333.999.0.0">上面代码的解读</a></li><li><a href="https://github.com/DA-southampton/NLP_ability/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Transformer/%E7%AD%94%E6%A1%88%E5%90%88%E8%BE%91.md">一些面试常问的transformer的问题</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Transformer 是 Google 在 2017 年发表的 《Attention is all you need》论文中提出的，为了解决机器翻译等 seq2seq 任务中 RNN 不能并行化等问题，transformer 是一个完全由 self-attention 搭建起来的网络，完全抛弃了 CNN 和 RNN 等传统网络结构，从而实现了并行化，到目前为止已经完全取代 RNN 成为自然语言处理领域最好的特征提取器。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— SMPL, A Skinned Multi-Person Linear Model</title>
    <link href="http://vincentho.name/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/"/>
    <id>http://vincentho.name/2020/09/16/【论文阅读】——-SMPL-A-Skinned-Multi-Person-Linear-Model/</id>
    <published>2020-09-16T15:04:34.000Z</published>
    <updated>2022-07-05T12:44:37.674Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title：SMPL: A Skinned Multi-Person Linear Model<br>Authors：Matthew Loper, et al<br>Conferences：ToG 2015<br>Abstract：作者提出了一个参数化的人体蒙皮模型，通过 23 个关节点的旋转以及 10 个 shape 参数就可以生成人体蒙皮。</p></blockquote><span id="more"></span><p><em>prefix</em></p><p>2D 数据的表示非常单一，一般就用 image 来表示；而3D 数据的表示有多种，比如 multi-view image、point cloud、mesh、voxel，这里我们用到的数据为 mesh 数据，一个 mesh 由多个 vertices 组成，每个 vertices 是一个三维坐标 (x,y,z)，除了有 vertices 外，生成 mesh 的时候还需要有一个 triangle list，一个 3D object 外观上有多个 triangle 拼接而成，而 list 里面存储的就是每个 triangle 所用到 vertices index。这里我们关注的是 3D 人体模型，同样的人体由多个 vertices 组成，而 joint 是一些特殊的 vertices，用来表征人体的一些特殊关节点，如肘、肩等，实质上就是一个 vertice，但这些 joint 有可能在人体 mesh 的 vertice 里面，也可能不在。</p><p>Linear Blending Skinning (LBS) 指的是通过操纵骨骼来使得 mesh 发生形变，LBS 定义骨骼点（joint）和 mesh 的 vertices 之间的关系是线性关系，一个 vertice 的位置会受到其他 joint 共同的加权影响，具体操作是会先计算 joint 的位置，然后根据 joint 的位置，求其他 vertices 的位置，所以可以通过操纵骨骼来改变整个 mesh。</p><p><br></p><h3 id="Model-Formulation"><a href="#Model-Formulation" class="headerlink" title="Model Formulation"></a>Model Formulation</h3><p>SMPL 模型的 mesh 由 $N=6890$ 个 vertices 和 $K = 23$ 个 joints 组成，参数为 $\theta$ 和 $\beta$，分别表示 23 个关节点的旋转以及人体 shape 的参数，后者是一个 10 维的向量，前者向量大小取决于旋转用什么方式来表征，比如旋转向量、旋转矩阵等。</p><p><strong>Notation</strong></p><ul><li>mean template $\bar{T}\in \mathbb{R}^{3N}$，可以理解为初始的一个 mesh，rest pose</li><li>zero pose $\theta^\ast$，初始 mesh 下各个关节点的旋转角度，这里的旋转角度实际上是相对于每个点的父节点的旋转角度，比如肘部的父节点是肩部，所以肘部的旋转值是相对于肩部来确定的</li><li>blend weight $\mathcal{W} \in \mathbb{R}^{N\times K}$，表示的是一个关节点 k 的旋转对于所有 N 个 vertices 的影响</li><li>blend shape function $B_S(\beta) : \mathbb{R}^{|\beta|} \rightarrow \mathbb{R}^{3N}$，输入 shape 参数，输出 vertices offset</li><li>joint prediction function $J(\beta) : \mathbb{R}^{|\beta|} \rightarrow \mathbb{R}^{3K}$，输入 shape 参数，输出 joint 的位置</li><li>pose-dependent blend shape function $B_P(\theta) : \mathbb{R}^{|\theta|} \rightarrow \mathbb{R}^{3N}$，输入 $\theta$，输出 vertices offset</li><li>linear blend skinning function $W(\cdot)$ is applied to rotate the vertices around the estimated joint</li><li>SMPL model $M(\beta,\theta;\Phi):\mathbb{R}^{|\theta| \times |\beta|} \rightarrow \mathbb{R}^{3N}$</li></ul><p><strong>Blend Skinning</strong></p><p>骨骼蒙皮通过骨骼来控制整个 mesh 的变化，$\theta$ 由 K 个关节点的旋转向量组成 $\theta = [w_0, …, w_K]^T$，$w_k \in \mathbb{R}^3$ denotes the axis-angle representation of the relative rotation of part k with respect to its parent in the kinematic tree. $|\theta| = 3 \times 23 + 3 = 72$ 个参数，每个关节点 3 个参数外加整体的 root orientation，首先旋转向量会通过 Rodrigues formula 转换成 $3\times3$ 的旋转矩阵 $exp(w_k)$，标准的 LBS 为以下的函数</p><script type="math/tex; mode=display">W(\bar{T}, J,\theta, \mathcal{W}):\mathbb{R}^{3N\times 3K \times |\theta| \times |\mathcal{W}|} \rightarrow \mathbb{R}^{3N}</script><p>函数会输入 rest pose $\bar{T}$，rest pose 下的 joint location $J$，pose $\theta$，blend weight $\mathcal{W}$，最后输出 posed vertices，对于每一个 vertices 的 transformation 如下，实际做的就是对 rest pose 下的每一个 joint 计算变换，然后再将计算出来的变换应用到每一个 vertice 上。</p><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/1.png" class=""><p>$G<em>k(\theta,J)$ 表示第 k 个关节点的 world transformation，这里的 world 是指世界坐标，所以用到的是齐次坐标系，$\bar{t}_i$ 和 $\bar{t}_i^\prime$ 分别表示 T-pose 下和变换后的第 i 个vertice，也都是齐次坐标系，4 维向量。$A(k)$ 表示的是第 k 个关节点的所有父节点，比如手腕的父节点分别有手肘、肩部等，因此在计算第 k 个关节点的变换的时候，依次乘以父节点的旋转矩阵，最后得到 $G_k(\theta, J)$，$G_k(\theta^\ast,J)$ 表示的是得到 rest pose 所需要的关节点的旋转变换，因此 $G^\prime_k(\theta,J)$ 是减去得到 rest pose 的变换，相当于得到一个相对的变换矩阵，然后变换矩阵乘以 rest pose 下的第 i 个 vertices 就可以得到变换后的第 i 个 vertice，然后乘上 $w</em>{k,i}$ 分量，表征第 k 个关节点对第 i 个 vertice 的影响。</p><p>SMPL 模型对 LBS 进行了修改，具体的流程可以看下图，首先会根据 $\beta$ 调整 T-pose，然后再根据 $\theta$ 调整（看臀部的位置，这是为后面的抬腿动作做准备），最后一步就是 LBS。</p><script type="math/tex; mode=display">M(\beta,\theta) = W(T_P(\beta,\theta), J(\beta), \theta, \mathcal{W})</script><script type="math/tex; mode=display">T_P(\beta, \theta) = \bar{T} + B_S(\beta) + B_P(\theta)</script><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/2.png" class=""><p><strong>Shape blend shapes</strong></p><p>$S = [S<em>1, …, S</em>{|\beta|}] \in \mathbb{R}^{3N\times |\beta|}$，表示 shape 每个参数对 vertices 的影响，S 是通过数据学习出来的</p><script type="math/tex; mode=display">B_S(\beta; S) = \sum_{n=1}^{|\beta|} \beta_n S_n</script><p><strong>Pose blend shapes</strong></p><p>每个 pose 参数都用旋转矩阵表示，所以是 9K，同样的 $P\in \mathbb{R}^{3N \times 9K}$ 矩阵通过数据学习出来</p><script type="math/tex; mode=display">B_P(\theta; P) = \sum_{n=1}^{9K}(R_n(\theta) - R_n(\theta^\ast))P_n</script><p><strong>Joint locations</strong></p><p>这里谈到的 joint 和上面用到的 $J$ 也都是在 rest pose 下的 joint 的 3D location，SMPL 在计算 joint 的时候引入了 $\beta$，更加精确，$\mathcal{J}$ is a matrix that transforms rest vertices into rest joints，同样通过数据学习出来。</p><script type="math/tex; mode=display">J(\beta; \mathcal{J}, \bar{T}, S) = \mathcal{J}(\bar{T} + B_S(\beta;S))</script><p>上面提到需要学习的参数有 $\Phi = {\bar{T}, \mathcal{W}, S, \mathcal{J}, P }$，也都是一些 regressor，或者说是矩阵，这里不介绍模型的训练过程，有兴趣的可以仔细看原论文。</p><p><br></p><h3 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h3><p>作者共提供了三个预训练模型，分别是 male、female 和 neutral，下面以 <code>SMPL_NEUTRAL.pkl</code> 为例子，讲一下模型里面的参数，pkl 文件里面是一个字典，关键的 key 如下</p><ul><li><code>J_regressor</code>: (24, 6890)，从 rest pose 中回归出 joint，上面的 $\mathcal{J}$ 矩阵</li><li><code>f</code>: (13776, 3)，faces，上面我们说到 mesh 除了有 vertices 组成，还有一个 triangle list，这里就是这个 list，可以看出人体共有 13776 个 triangle，每个 triangle 由三个 vertices index 组成，所以 faces 最大的数字就是 6889，因为共 6890 个点。</li><li><code>kintree_table</code>: (2, 24)，一般取第一行，这就是上面提到的每个点的父节点</li><li><code>weights</code>: (6890, 24)，blend weight，上面的 $\mathcal{W}$ 矩阵</li><li><code>posedirs</code>: (6890, 3, 207)，上面的 $P$ 矩阵</li><li><code>shapedirs</code>: (6890, 3, 10)，上面的 $S$ 矩阵</li><li><code>v_template</code>: (6890, 3)，上面的 $\bar{T}$</li></ul><p>smplx 的库文件里面包含三个模型，分别是 SMPL、SMPLH 和 SMPLX，这里只分析最基础的 SMPL 的代码里面的 lbs 函数</p><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/3.png" class=""><ol><li>计算 shape blend shape offset</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">blend_shapes</span>(<span class="params">betas, shape_disps</span>):</span><br><span class="line">    blend_shape = torch.einsum(<span class="string">&#x27;bl,mkl-&gt;bmk&#x27;</span>, [betas, shape_disps])</span><br><span class="line">    <span class="keyword">return</span> blend_shape</span><br><span class="line"></span><br><span class="line">v_shaped = v_template + blend_shapes(betas, shapedirs)</span><br></pre></td></tr></table></figure><ol><li>计算 rest pose 下的 joint</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vertices2joints</span>(<span class="params">J_regressor, vertices</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.einsum(<span class="string">&#x27;bik,ji-&gt;bjk&#x27;</span>, [vertices, J_regressor])</span><br><span class="line"></span><br><span class="line">J = vertices2joints(J_regressor, v_shaped)</span><br></pre></td></tr></table></figure><ol><li>计算 pose blend shape offset，如果输入的 pose 是旋转向量，那先需要转成旋转矩阵，去掉第一个点，因为是 root，至于为什么旋转矩阵要再减去一个 identity matrix，暂时不清楚</li></ol><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/4.png" class=""><ol><li>计算旋转后的关节点，输入有旋转矩阵，rest pose 下的 joint，每个 joint 的parent<ul><li>rel_joints: relative joints，指的是每个关节点其父节点指向自己的向量，维度是 (b, 24, 3)</li><li>transforms_mat：变换矩阵，上面提到的未连乘起来的 $G$，旋转矩阵的维度是 (b, 24, 3, 3)，和 relative joint 一起拼成 (b, 24, 4, 4) 的齐次变换矩阵</li><li>transform_chain：这里实现的应该是每个节点只有一个 parent 节点，所以 transform_chain 实际就是将 transform_mat 中的每个关节点的变换矩阵乘上其父节点的变换矩阵</li><li>posed_joints：不是很懂为什么 transform_mat 相乘后会将 rel_joints 直接也进行变换，但可能就是会得到变换后的点吧</li><li>rel_transform：不是很懂</li></ul></li></ol><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/5.png" class=""><img src="/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-SMPL-A-Skinned-Multi-Person-Linear-Model/6.png" class=""><ol><li>最后一步就是 skinning，<ul><li>首先将 blend weight 扩展成维度 (b, 6890, 24)</li><li>A 矩阵就是上面函数得到的 rel_transform 变换矩阵，blend weight 乘以变换矩阵得到 T</li><li>vposed_homo 就是将 vertices 转成齐次坐标，然后和 T 矩阵相乘得到最后变换后的 vertices，取前三个回到正常坐标。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># W is N x V x (J + 1)</span></span><br><span class="line">W = lbs_weights.unsqueeze(dim=<span class="number">0</span>).expand([batch_size, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line"><span class="comment"># (N x V x (J + 1)) x (N x (J + 1) x 16)</span></span><br><span class="line">num_joints = J_regressor.shape[<span class="number">0</span>]</span><br><span class="line">T = torch.matmul(W, A.view(batch_size, num_joints, <span class="number">16</span>)) .view(batch_size, -<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">homogen_coord = torch.ones([batch_size, v_posed.shape[<span class="number">1</span>], <span class="number">1</span>], dtype=dtype, device=device)</span><br><span class="line">v_posed_homo = torch.cat([v_posed, homogen_coord], dim=<span class="number">2</span>)</span><br><span class="line">v_homo = torch.matmul(T, torch.unsqueeze(v_posed_homo, dim=-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">verts = v_homo[:, :, :<span class="number">3</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title：SMPL: A Skinned Multi-Person Linear Model&lt;br&gt;Authors：Matthew Loper, et al&lt;br&gt;Conferences：ToG 2015&lt;br&gt;Abstract：作者提出了一个参数化的人体蒙皮模型，通过 23 个关节点的旋转以及 10 个 shape 参数就可以生成人体蒙皮。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Distribution-Aware Coordinate Representation for Human Pose Estimation</title>
    <link href="http://vincentho.name/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/"/>
    <id>http://vincentho.name/2020/09/15/【论文阅读】——-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/</id>
    <published>2020-09-15T08:10:05.000Z</published>
    <updated>2022-07-05T12:44:37.580Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title: Distribution-Aware Coordinate Representation for Human Pose Estimation<br>Authors: Feng Zhang, Xiatian Zhu, et al<br>Conferences: CVPR 2020<br>Abstract: 作者发现姿态检测任务中，除了网络结构的设计之外，label representation 也很重要，即如何在 keypoint coordinate 和 heatmap 之间相互转换，作者提出了一种新的转换方式，能无缝地与各种姿态检测网络相结合，并恒定地提升网络的性能。</p></blockquote><span id="more"></span><p><em>prefix</em></p><p>姿态检测任务不是一个简单的任务，它的难点在于关节点的遮挡、复杂的背景等，过去的很多工作都在设计更深更强的网络结构，而忽略了最本质的 label representation 的部分，姿态检测的 label 分为两类，一种是直接回归坐标，第二种是热力图回归，即先将坐标点转化成热力图上响应最大的点，然后网络输出一个热力图。第二种方法成为了现今姿态检测的主流方法，但回归热力图带来的问题就是计算开销大，所以常规的做法会先有 resolution reduction 后 resolution recovery，如下图，首先会将 bbox 下采样到一个 predefined 的分辨率，热力图也设置成一个预先定义好的分辨率，网络输出的热力图最后会上采样会原来的 image space。</p><p>作者把 coordinate 到 heatmap 的过程定义为 coordinate encoding，heatmap 到coordinate 到过程定义为 coordinate decoding，值得注意的是，encoding 的过程有 resolution reduction，所以会引入量化误差，为了解决这一问题，现在一般的做法是在 decoding 的时候，会有一个 0.25 像素的偏移来弥补这个误差，这个做法能够明显提升最后的结果。</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/1.png" class=""><p><br></p><h2 id="DARK"><a href="#DARK" class="headerlink" title="DARK"></a>DARK</h2><p>作者提出的 DARK 分为 encoding 和 decoding 部分</p><h3 id="Coordinate-Decoding"><a href="#Coordinate-Decoding" class="headerlink" title="Coordinate Decoding"></a>Coordinate Decoding</h3><p>标准的 coordinate decoding 做法是从 heatmap 中挑出响应值最大和次大的两个点 $m$ 和 $s$，最后的点会是最大点向次大点偏移 0.25 个像素，最后再恢复成原图像 space。这种 sub-pixel shifting 是用来补偿 resolution reduction 带来的量化误差，热力图上响应值最大的点未必对应原空间上最大的点，可能只是一个粗略的坐标。</p><script type="math/tex; mode=display">p = m + 0.25 \frac{s-m}{||s-m||_2}</script><script type="math/tex; mode=display">\hat{p} = \lambda p</script><p>这种做法是 hand-crafted 的，并且没有太多的理论依据，作者提出一种基于分布的 decoding 方法，来获得更加准确的 sub-pixel，首先假设输出的 heatmap 同样是服从二维高斯分布</p><script type="math/tex; mode=display">G(x;\mu,\Sigma)=\frac{1}{2\pi|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><p>取 log 后得</p><script type="math/tex; mode=display">P(x;\mu,\Sigma)=ln(G)=-ln(2\pi)-\frac{1}{2}ln(|\Sigma|)-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)</script><p>二元高斯分布的 $\mu$ 是中心，同样也是响应值最高的地方，因此对其求一阶导数会等于 0。</p><script type="math/tex; mode=display">D^\prime(x)|_{x=\mu}=-\Sigma^{-1}(x-\mu)|_{x=\mu}=0</script><p>但由于实际上得到的 heatmap 是离散值，假设最大响应点为 $m$，我们用泰勒展开，用 $m$ 点去估计真正最大的点 $\mu$</p><script type="math/tex; mode=display">P(\mu)=P(m)+D^\prime(m)(\mu-m)+\frac{1}{2}(\mu-m)^TD^{\prime \prime}(m)(\mu-m)</script><p>其中二阶导数（Hessian）为</p><script type="math/tex; mode=display">D^{\prime \prime}(m)=D^{\prime \prime}(x)|_{x=m}=-\Sigma^{-1}</script><p>联合几条式子最后得到最大响应值 $\mu$ 为</p><script type="math/tex; mode=display">\mu = m - (D^{\prime \prime}(m))^{-1}D^{\prime}(m)</script><p>对比现在的标准做法人为像第二大的点偏移 0.25 个像素，作者提出的做法充分利用了热力图的分布信息，但该方法是基于网络输出的分布是高斯分布的前提，但实际上输出的热力图不是完全的高斯分布，如下图，输出的热力图会出现在关节点附近好几个峰值。</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/2.png" class=""><p>因此作者在这里对输出的热力图做了一个平滑（modulation）操作来 smooth out 其他的峰值，具体的操作是用一个高斯核 K 来进行卷积，然后再调整热力图的峰值为原热力图的峰值</p><script type="math/tex; mode=display">h^\prime = K \otimes h</script><script type="math/tex; mode=display">h^\prime = \frac{h^\prime - min(h^\prime)}{max(h^\prime) - min(h^\prime)} \ast max(h)</script><p>总结一下，作者提出的 decoding 分为三步</p><ol><li>heatmap distribution modulation</li><li>Distribution-aware joint localisation by Taylor expansion</li><li>resolution recovery to the original coordinate space</li></ol><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/3.png" class=""><h3 id="Coordinate-Encoding"><a href="#Coordinate-Encoding" class="headerlink" title="Coordinate Encoding"></a>Coordinate Encoding</h3><p>假设真实的坐标点为 $g=(u,v)$，resolution reduction 后的坐标点为</p><script type="math/tex; mode=display">g^\prime=(u^\prime, v^\prime) = \frac{g}{\lambda}=(\frac{u}{\lambda}, \frac{v}{\lambda})</script><p>然后会将 $g^\prime$ 进行量化，比如 floor、ceil、round 等操作得到 $g^{\prime\prime}$，现在 encoding 的方法就是在 $g^{\prime\prime}$ 上进行 GT heatmap 的生成，但这肯定会引入一个量化误差在里面，作者提出用 $g^\prime$ 去生成 heatmap 能够更加准确一点。</p><p><br></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Evaluating-Coordinate-Representation"><a href="#Evaluating-Coordinate-Representation" class="headerlink" title="Evaluating Coordinate Representation"></a>Evaluating Coordinate Representation</h3><h4 id="Coordinate-decoding"><a href="#Coordinate-decoding" class="headerlink" title="Coordinate decoding"></a>Coordinate decoding</h4><p>作者对比了 0.25 hand-crafted shift 和 DARK，用的网络是 HRNet-w32，输入维度是 128x96，结果表明以前的那种 0.25 shift 的方法能够极大提升性能，但竟然没有被研究</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/4.png" class=""><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/5.png" class=""><h4 id="Coordinate-encoding"><a href="#Coordinate-encoding" class="headerlink" title="Coordinate encoding"></a>Coordinate encoding</h4><p>Unbiased encoding 能恒定提升性能，无论 decoding 方式如何</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/6.png" class=""><h4 id="input-resolution"><a href="#input-resolution" class="headerlink" title="input resolution"></a>input resolution</h4><p>降低分辨率性能掉点严重，但 DARK 在分辨率低的情况下提点比较多</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/7.png" class=""><h4 id="generality"><a href="#generality" class="headerlink" title="generality"></a>generality</h4><p>测试了不同的网络，都能有恒定的提点</p><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/8.png" class=""><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/9.png" class=""><img src="/2020/09/15/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Distribution-Aware-Coordinate-Representation-for-Human-Pose-Estimation/10.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title: Distribution-Aware Coordinate Representation for Human Pose Estimation&lt;br&gt;Authors: Feng Zhang, Xiatian Zhu, et al&lt;br&gt;Conferences: CVPR 2020&lt;br&gt;Abstract: 作者发现姿态检测任务中，除了网络结构的设计之外，label representation 也很重要，即如何在 keypoint coordinate 和 heatmap 之间相互转换，作者提出了一种新的转换方式，能无缝地与各种姿态检测网络相结合，并恒定地提升网络的性能。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>3D Human Pose and Shape Reconstruction Review</title>
    <link href="http://vincentho.name/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/"/>
    <id>http://vincentho.name/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/</id>
    <published>2020-09-09T07:04:27.000Z</published>
    <updated>2022-07-05T12:44:37.246Z</updated>
    
    <content type="html"><![CDATA[<p>该文章总结了一些三维人体姿态估计和重构的文章，分别为：</p><ul><li>HMR：End-to-end Recovery of Human Shape and Pose</li><li>SPIN：Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop</li><li>VIBE：Video Inference for Human Body Pose and Shape Estimation</li></ul><span id="more"></span><h2 id="End-to-end-Recovery-of-Human-Shape-and-Pose"><a href="#End-to-end-Recovery-of-Human-Shape-and-Pose" class="headerlink" title="End-to-end Recovery of Human Shape and Pose"></a>End-to-end Recovery of Human Shape and Pose</h2><blockquote><p>Authors: Angjoo Kanazawa<br>Conference: CVPR 2018</p></blockquote><p>该模型的输入为一张图片，或者说是一个 bounding box，bbox 中心为人，输出是重构的三维人体。图片首先经过一个 encoder 提取特征，encoder 用的是在分类任务上预训练好的 ResNet50，特征输入到 regressor 里面经过几轮的迭代最后预测一系列参数，包括 SMPL 模型的参数 $\theta$ 、$\beta$ 以及 weak-perspective camera model 的参数 scale、rotation、translation。</p><p>输入的图片均有二维关节点的 annotation，从 regressor 得到的参数中生成三维人体 mesh（$M(\theta,\beta)\in R^{3\times N}$，N=6890），然后从 mesh 中通过线性回归得到三维关节点 $X(\theta, \beta)\in R^{3 \times P}$，P 为关节点个数，相机参数 $s\in R, t\in R^2$，从 3 维关节点经过投影生成 2 维的关节点，R 为 global orient，$\Pi$ 为 orthographic projection。</p><script type="math/tex; mode=display">\hat{x}=s \Pi(RX(\theta, \beta))+t</script><p>由于每张图片都有 2 维关节点，通过这种方式，约束生成的 3 维关节点经过投影后与 2 维关节点相似，从而训练网络。由于 SMPL 的关节点和 2 维不同数据集的关节点数有一些不同，这里作者做的是将不同数据集融合，保证 SMPL 的点在 2 维关节点的 annotation 中有。</p><script type="math/tex; mode=display">L_{reproj}=\sum_i ||v_i(x_i-\hat{x}_i)||_1</script><p>除了每张图片都有 2D supervision 外，有一些图片会有 3D 的 annotation，一般 3D 的 annotation 会以 3D keypoint 的形式给出，用 MoSh 工具可以从 3D keypoint 中得到 SMPL 的参数 $\theta$ 和 $\beta$，3D supervision 的 loss 如下，joint loss 加上参数 loss</p><script type="math/tex; mode=display">L_{3D} = ||X_i-\hat{X}_i||_2^2 + ||[\beta_i, \theta_i] - [\hat{\beta}_i, \hat{\theta}_i]||_2^2</script><p>除了一般的 reprojection loss 外，以前的文章都会加入一些人为 的先验，来约束 SMPL 的 $\theta$ 参数来避免一些不自然的动作或者关节点扭动，这里作者采取一种 data-driven 的先验方式，通过训练一个判别器，让网络自己去判断回归出来的 SMPL 参数是否像正常人，首先需要一个 3D 人体的数据库（每个人体的 SMPL 参数都有），然后判别器的网络结构方面，采取的是公用前面的 feature extraction，后面每个关节点逐一判别。</p><p>训练网络总的 loss 如下</p><script type="math/tex; mode=display">L=\lambda(L_{reproj}+1L_{3D})+L_{adv}</script><img src="/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/1.png" class=""><p>训练用到的 2D 数据集有：LSP、LSP-extended、MPII、MS COCO，3D 数据集有：Human3.6M、MPI-INF-3DHP。由于 SMPL 的 23 个关节点和用到的数据集不是很 match，因此用一个 regressor 从生成的 mesh 中回归出 Human3.6M 的14 个点，同样的方法加上 MS COCO 脸上的 5 个点，共 19 个点用于 reprojection loss。</p><p><br></p><h2 id="Learning-to-Reconstruct-3D-Human-Pose-and-Shape-via-Model-fitting-in-the-Loop"><a href="#Learning-to-Reconstruct-3D-Human-Pose-and-Shape-via-Model-fitting-in-the-Loop" class="headerlink" title="Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop"></a>Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop</h2><blockquote><p>Authors: Nikos Kolotouros<br>Conference: ICCV 2019</p></blockquote><p>作者结合了 regression-based 和 optimization-based 两种方法，整体的思路就是先用 HMR 的网络回归出来一个初步的人体模型（下图右），然后再用这个人体去初始化 smplify 模块对人体模型进行优化，并用优化后的人体模型作为 GT 去监督回归网络的训练。</p><img src="/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/2.png" class=""><p>回归网络和 HMR 几乎一样，唯一不同是 HMR 用欧拉角来表征每个关节点的旋转，而 SPIN 用一个 6 维的向量来表征三维旋转。得到的初步三维人体模型再用 smplify 进一步优化。</p><blockquote><p>SMPLify tries to fit the SMPL model to a set of 2D keypoints using an optimization-based approach.</p></blockquote><p>优化的目标函数包含 reprojection loss 还有一些 pose 和 shape 的 prior，比如惩罚肘部和膝盖不自然的旋转，实现上 smplify 分为两步，第一步是固定 initial pose 和 shape，优化 camera translation 和 body orientation，简单说就是调整人体的整体转向；第二步是优化 pose 和 shape。通过 iterative fitting，得到优化后的人体模型 </p><p>SPIN 和上一篇 HMR 不同的点在于，它没有直接用 reprojection loss 来训练回归网络，而是用优化后的人体模型参数来作为回归网络输出的 GT，smplify 后的 SMPL 参数为 $\Theta<em>{opt}={\theta</em>{opt}, \beta<em>{opt} }$，回归网络输出的 SMPL 参数为 $\Theta</em>{reg}={\theta<em>{reg}, \beta</em>{reg} }$；同理 smplify 后的 mesh 为 $M_{opt}$，损失函数包括</p><script type="math/tex; mode=display">L_{3D}=||\Theta_{reg}-\Theta_{opt}||</script><script type="math/tex; mode=display">L_M=||M_{reg} - M_{opt}||</script><p>SPIN 的一大特点在于 self-improving，A good initial network estimate $\Theta<em>{reg}$ will lead the optimization to a better fit $\Theta</em>{opt}$, while a good fit from the iterative routine will provide even better supervision to the network. 对比上一篇的 HMR，SPIN 完全不需要用到 3D 的数据进行训练，并且对比 HMR 训练判别器告诉回归网络生成的 pose 是否正常，SPIN explicitly 用 smplify 提供更加有效的 pose 信息作为 supervision。</p><p>训练集有用到 Human3.6M、MPI-INF-3DHP、LSP 并且混合了其他 2D 数据集如 MPII 和 COCO，2D annotation 方面混合所有数据集的关节点，总数为 24 个点，对于某一张图片上没有标注的点，标记 visibility 为 0，表示不可见。</p><p><br></p><h2 id="VIBE-Video-Inference-for-Human-Body-Pose-and-Shape-Estimation"><a href="#VIBE-Video-Inference-for-Human-Body-Pose-and-Shape-Estimation" class="headerlink" title="VIBE: Video Inference for Human Body Pose and Shape Estimation"></a>VIBE: Video Inference for Human Body Pose and Shape Estimation</h2><blockquote><p>Authors: Muhammed Kocabas<br>Conference: CVPR 2020</p></blockquote><p>整体流程如下，给定一个 T 帧的视频 $V={I<em>t }</em>{t=1}^T$，temporal generator 对输入的每一帧图片进行 CNN 提取信息，GRU 处理时序信息，最后 regressor 回归出 SMPL 的参数，对于 $\beta$ 参数，取 T 帧的平均值作为整体的 shape，generator 最后的输出 $\hat\Theta = [(\hat\theta<em>1,…,\hat\theta_T), \hat\beta]$，与 AMASS（一个 3D 人体模型的库）的真实人体 $\Theta</em>{real}$ 输出到判别器进行动作的判定。</p><img src="/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/3.png" class=""><p><strong>Temporal Generator</strong></p><p>整体的网络结构和 SPIN 基本一样，只是在 CNN 和 Regressor 之间插入了一个 GRU 的模块，SPIN 是单帧处理的，这里加入了 temporal 的信息，因为前面帧的信息对后面帧的处理有帮助，同样用的 6D 旋转表示，生成器的损失项如下，看不同的数据有哪些 annotation 来决定有哪些损失项，2D 损失项是必定有的，reprojected 2D keypoint 和之前的方法一样</p><script type="math/tex; mode=display">L_G=L_{3D} + L_{2D} + L_{SMPL} + L_{adv}</script><script type="math/tex; mode=display">L_{3D} = \sum_{i=1}^T||X_t - \hat{X}_t||_2</script><script type="math/tex; mode=display">L_{2D} = \sum_{i=1}^T||x_t - \hat{x}_t||_2</script><script type="math/tex; mode=display">L_{SMPL} = \sum_{i=1}^T||\theta_t - \hat{\theta}_t||_2 + ||\beta-\hat\beta||_2</script><p><strong>Motion Discriminator</strong></p><p>这里的判别器和 HMR 不同，同样加入了时序的信息，而不是一个单帧动作的判别器，而是一个序列动作的判别器，如下图所示，generator 生成的序列的 SMPL 参数会经过 GRU，然后再经过一个 self-attention 模块最后输入到一个线性层判定动作是否 valid</p><img src="/2020/09/09/3D-Human-Pose-and-Shape-Reconstruction-Review/4.png" class=""><p>训练数据和前两个论文的不同，由于 VIBE 不是单帧处理，而是处理视频数据，因此 2D 数据上用到的是 PoseTrack 和 PennAction，对于 3D keypoint 数据，用到的还是 MPI-INF-3DHP 和 Human3.6M，而 3DPW 和 Human3.6M 提供的 SMPL annotation 也同样用来训练，AMASS 用来训练判别器。</p><p><em>In Conclusion</em></p><p>三篇文章都是用回归的方式去学习 SMPL 的参数，也有加入对抗学习来作为先验，VIBE 考虑到了 temporal 的信息，但依旧有很多值得改进的地方。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.pdf">HMR paper</a></li><li><a href="https://arxiv.org/pdf/1909.12828.pdf">SPIN paper</a></li><li><a href="https://github.com/nkolot/SPIN">SPIN Github</a></li><li><a href="https://arxiv.org/abs/1912.05656">VIBE paper</a></li><li><a href="https://github.com/mkocabas/VIBE">VIBE Github</a></li></ul><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;该文章总结了一些三维人体姿态估计和重构的文章，分别为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HMR：End-to-end Recovery of Human Shape and Pose&lt;/li&gt;
&lt;li&gt;SPIN：Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop&lt;/li&gt;
&lt;li&gt;VIBE：Video Inference for Human Body Pose and Shape Estimation&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】——MotioNet, 3D Human Motion Reconstruction from Monocular Video with Skeleton Consistency</title>
    <link href="http://vincentho.name/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/"/>
    <id>http://vincentho.name/2020/08/30/【论文阅读】——MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/</id>
    <published>2020-08-30T12:04:11.000Z</published>
    <updated>2022-07-05T12:44:37.725Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title: MotioNet: 3D Human Motion Reconstruction from Monocular Video with Skeleton Consistency<br>Author: Mingyi Shi, et al<br>Conference: ToG, 2020(transaction of graphics)<br>Abstract: 作者提出了一种 data-driven 的 3 维人体运动重构模型，该模型很好地解决了脚贴地、绝对位移等问题。</p></blockquote><span id="more"></span><p><em>prefix</em></p><p>3D 人体重构方面主要分为两类，一种是预测 pose，另一种是预测 shape。首先 3D pose estimation 的任务是预测 3D 的关节点，它只能作为 human motion reconstruction 的一个子任务，因为 3D 的关节点并没有关节旋转的信息，比方说，相同的一套 3D 关节点可以对应着无数个真正的姿势，因为关节点的内旋不会导致关节点物理位置的移动，并且由于预测上误差的存在，会导致骨骼的长短发生抖动。</p><p>3D 人体重构一般分为两种方法，一种是从 3D joint position 中预测出关节点的旋转；另外一种是 model-based，比如基于著名的 SMPL 人体蒙皮模型，用网络去预测 SMPL 模型的参数。</p><p>本文基于的方法是第一种方法，从 2D joint position 中预测关节点旋转、root 移动、骨骼长度、脚部是否接触地面，不基于任何人体模型，完全 data-driven 的。</p><p><br></p><h4 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h4><p>这里只讲一下整个网络的推理过程，下面的是网络结构，2D 的关节点作为输入，作者用的是 openpose 的结果，并且会将关节点的 confidence 组成向量输入到网络，注意网络的输入是一串时间 T 内的 keypoint。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/1.png" class=""><p>然后分为两个 encoder，如下图，$E_Q$ 采取的是 temporal 的卷积，然后分成三条 branch，分别预测每一帧的 joint rotations、global root position 和 foot contact labels；而 $E_S$ 首先会将 T 个时间的输入整合到一起再采取普通的卷积操作，输出 bone length，因为对于一个人来说，骨骼长度是固定的，并不需要时间的信息，也不会每一帧会有不同的骨骼长度，所以也不需要 temporal 卷积。输出的 bone length 相当于预测了 SMPL 里面的 shape 参数，表征一个人的高矮胖瘦，然后会用预测的 bone 生成一个 T-pose。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/2.png" class=""><p>FK(forward kinematics) 模块的输入是 T-pose、joint rotation、root position，$\tilde{s}_{init} \in R^{3J}$ 相当于这个人的初始 pose，J 为关节点数，然后每一帧，将 T-pose 根据 joint rotation $\tilde{q}^t \in R^{4J}$ 进行旋转，关节旋转用四元数表示。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/3.png" class=""><p>对于每一帧，J 个关节点遵循从 root 到 leaf 的规则，$\tilde{P}<em>n^t=\tilde{P}^t</em>{parent(n)}+R^t_n\tilde{s}_n$，$\tilde{P}_n^t \in R^3$ 是第 n 个关节点在时间 t 的位置，关节 n 的 parent 指的是骨骼关系里的 parent，比如手肘是手腕的 parent， $R_n^t$ 是第 n 个关节点的旋转矩阵，$\tilde{s}_n \in R^3$ 是第 n 个关节点相对其 parent 的offset，手腕的位置等于手肘的位置加上旋转乘以手腕相对手肘的位置偏移</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/4.png" class=""><p>最后再加上根节点的移动</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94MotioNet-3D-Human-Motion-Reconstruction-from-Monocular-Video-with-Skeleton-Consistency/5.png" class=""><p>上面是整个推理流程，在训练阶段，从网络图看出是有一个判别器的，主要用来判别动作是否真实，但它并不是直接拿 joint rotation 输入到判别器，而是拿相邻 rotation 的差值，相当于求了一个差分。其他的 loss 包括 joint rotation loss、bone length loss、root position loss、foot contact loss</p><p><br></p><p>模型结果可以看下论文主页和油管视频</p><ul><li><a href="https://rubbly.cn/publications/motioNet/">https://rubbly.cn/publications/motioNet/</a></li><li><a href="https://www.youtube.com/watch?time_continue=2&amp;v=8YubchlzvFA&amp;feature=emb_logo">https://www.youtube.com/watch?time_continue=2&amp;v=8YubchlzvFA&amp;feature=emb_logo</a></li></ul><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title: MotioNet: 3D Human Motion Reconstruction from Monocular Video with Skeleton Consistency&lt;br&gt;Author: Mingyi Shi, et al&lt;br&gt;Conference: ToG, 2020(transaction of graphics)&lt;br&gt;Abstract: 作者提出了一种 data-driven 的 3 维人体运动重构模型，该模型很好地解决了脚贴地、绝对位移等问题。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】——OpenPose, Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</title>
    <link href="http://vincentho.name/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/"/>
    <id>http://vincentho.name/2020/08/30/【论文阅读】——OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/</id>
    <published>2020-08-30T12:01:07.000Z</published>
    <updated>2022-07-05T12:44:37.729Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title: OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields<br>Author: Zhe Cao<br>Conference: CVPR 2017（后扩展为期刊）<br>Abstract: 作者提出了一种实时的 2D 关节点检测的算法，并将关节点扩展为手部、脚部、脸部共 135 个点。</p></blockquote><span id="more"></span><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>openpose 是一种 bottom-up 的方法，所谓的 bottom-up，就是从一张图片中先找出所有的关节点，然后再对关节点进行重组，这种方法不受图片中人数的影响，runtime 比较固定，因此可以做到实时，openpose 整体的流程如下。整张图片作为输入，经过神经网络会输出两种图，一种是 heatmap（part confidence maps，openpose里面将 keypoint 称为 part），另一种是骨骼连接图（part affinity fields，也就是连接不同关节点之间的骨骼），然后再对得到的关节点进行 match 和 parse。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/1.png" class=""><h4 id="Confidence-Maps"><a href="#Confidence-Maps" class="headerlink" title="Confidence Maps"></a>Confidence Maps</h4><p>在 top-down 方法里面，ground-true 的关节点的热力图是以关节点为原点的一个二维高斯分布，热力图最大值的点即为关节点；而对于 bottom-up 的方法，一张图片会有多个人，因此对于某一个关节点，如脖子，热力图上会有多个 peak，是多个高斯分布的叠加，这里不同高斯分布采取的是取最大值的做法，防止关节点隔得太近，所以不能取平均，$S^{\ast}_j $ 表示的是第 j-th 个关节点的 GT 热力图</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/2.png" class=""><h4 id="Part-Affinity-Fields-for-Part-Association"><a href="#Part-Affinity-Fields-for-Part-Association" class="headerlink" title="Part Affinity Fields for Part Association"></a>Part Affinity Fields for Part Association</h4><p>假设一个人体有 17 个关节点，那么 17 个点，就会有 16 根连线，这里的一根连线对应一个 part affinity field，PAF 是一个 $w\times h \times 2$ 的矩阵，每个 pixel 对应一个 2D 向量，指示连线的方向。对于 limb c 上的点，PAF 为一个指示单位向量。至于如何找到 limb c 上的点，作者连接两个关节点成一条线，距离该线在一定范围内的点即为 limb c 上的点。一张图会有 k 个人，所以会有 k 个 limb c，因此最终对于 limb c 的 GT PAF $L^\ast _c$ 是单独一个人 PAF 的平均。 </p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/3.png" class=""><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/4.png" class=""><p>测试的时候，会预测出一堆的关节点，以及一堆的 limb，就比如图1的例子，两个人，预测出两个肩膀点和两个手肘点，这里可以自由组合出 4 个 limb，然后预测的 PAF 会有两条 limb，如果会用组合的 4 个 limb 去对预测的两条 limb 做积分，来算一个能量值，若组合出来的某一条 limb 的方向和预测的方向几乎一致，那么这个能量值就会很高，反之很低，然后就会用这个能量值作为 keypoint parsing 的依据</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/5.png" class=""><h4 id="network-architecture"><a href="#network-architecture" class="headerlink" title="network architecture"></a>network architecture</h4><p>在原 openpose 论文里面（cvpr会议），网络结构是采取 simultaneous 的形式，分两条支路分别预测 part confidence 和 part affinity field，但后面改成期刊后，采取了 serial detection and association，先预测 limb 再预测 part。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/6.png" class=""><p>首先图像经过一个 VGG-19 作为特征提取器，得到特征图 F，特征图后有先经过 $T_P$ 个 stage 的 limb 预测，每个 stage 的预测上一个 stage 的预测结果以及特侦图 F 作为输入</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/7.png" class=""><p>$T_P$ 个 stage 的 part affinity field 后是 $T_C$ 个 stage 的 part confidence maps，预测关节点的时候会将预测的 PAF 作为输入</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/8.png" class=""><p>网路训练引入了 intermediate supervision，每个 stage 的输出都用来进行监督</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/9.png" class=""><h4 id="Multi-person-Parsing-using-PAFs"><a href="#Multi-person-Parsing-using-PAFs" class="headerlink" title="Multi-person Parsing using PAFs"></a>Multi-person Parsing using PAFs</h4><p>我们网络预测得到 candidate parts 和 candidate limbs，组合过程采取启发式的方法，对于一条 limb c，连接它的两个关节点分别是 $j<em>1$ 和 $j_2$，检测到的两种关节点数量为 $D</em>{j<em>1}$ 和 $D</em>{j_2}$，这两个数量不一定相等，因为存在遮挡或者半身情况，然后建立一个二分图，边的权重为上面提到的能量值，然后对于一条 limb c，我们需要找出一个使得边权重最大的二分图，然后这就是最可能的 limb。</p><p>对于整个 body，分别找出每条 limb 的组合，再拼接起来即为最终结果。</p><h4 id="foot-detection"><a href="#foot-detection" class="headerlink" title="foot detection"></a>foot detection</h4><p>openpose 将 coco 的 17 个点扩展成 25 个点，其中增加了 6 个脚部的点，脚部的数据集是部分 coco 数据集中标注出来的，共 1.5k 张。叫上脚部检测后，解决了遮挡的问题，左图的 b 和 c。</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/10.png" class=""><p>除此之外，openpose 还训练了手部和脸部关节点的检测器，整体效果如下</p><img src="/2020/08/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94OpenPose-Realtime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/11.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title: OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields&lt;br&gt;Author: Zhe Cao&lt;br&gt;Conference: CVPR 2017（后扩展为期刊）&lt;br&gt;Abstract: 作者提出了一种实时的 2D 关节点检测的算法，并将关节点扩展为手部、脚部、脸部共 135 个点。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Knowledge Distillation Meets Self-Supervision</title>
    <link href="http://vincentho.name/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/"/>
    <id>http://vincentho.name/2020/08/06/【论文阅读】——-Knowledge-Distillation-Meets-Self-Supervision/</id>
    <published>2020-08-06T12:02:40.000Z</published>
    <updated>2022-07-05T12:44:37.636Z</updated>
    
    <content type="html"><![CDATA[<p><br></p><blockquote><p>Title: Knowledge Distillation Meets Self-Supervision<br>Conference: ECCV 2020<br>Authors: Guodong Xu, Ziwei Liu, et al<br>Abstract: 作者提出用自监督的方式去提取一些更加 general 的知识，并将它用来知识蒸馏，能大幅度提升不同网络架构之间的蒸馏效果。</p></blockquote><span id="more"></span> <p><em>prefix</em></p><p>很多知识蒸馏的文章都将重点放到了如何提取网络中间层的特征，比如提取注意力图、相关性矩阵、分布统计等，但是这些方法提取到的知识都是与网络所处理的任务相关的（task-specific），并且这些知识是与网络的架构相关的（architecture-relative），所以会导致不同网络结构的知识蒸馏效果不佳。</p><p>而自监督这种训练方式，能够充分地利用数据本身去学习网络，常见的自监督任务有</p><ul><li>exemplar：每一个样本是一个类别，训练网络进行分类任务</li><li>rotation：把图片进行旋转，旋转的角度有4个，然后进行四分类</li><li>jigsaw：将图片分成四块，然后随机打乱顺序，共有24种顺序，进行24分类问题</li><li>contrastive learning：将图片进行数据增广，然后让网络判别出原图和增广后的图是positive，与其他图是negative</li></ul><p>针对知识蒸馏任务，作者认为需要更加通用的知识，因此将自监督作为辅助任务来获得更加general的knowledge</p><p><br></p><h2 id="Self-Supervision-Knowledge-Distillation-SSKD"><a href="#Self-Supervision-Knowledge-Distillation-SSKD" class="headerlink" title="Self-Supervision Knowledge Distillation(SSKD)"></a>Self-Supervision Knowledge Distillation(SSKD)</h2><h3 id="Contrastive-Learning-as-Self-supervision"><a href="#Contrastive-Learning-as-Self-supervision" class="headerlink" title="Contrastive Learning as Self-supervision"></a>Contrastive Learning as Self-supervision</h3><p>给定有 N 个样本 ${x<em>i}</em>{i=1:N}$ ，有一个 transformation $T$ 集合，任意一个 transformation $t(\cdot) \in T$ 作用到每一个样本上得到 ${\tilde{x}<em>i}</em>{i=1:N}$ 。</p><p>contrastive learning 的核心是要最大化 positive pair $(\tilde{x}<em>i, x_i)$ 的相似性，和最小化 negative pairs $(\tilde{x}_i, x_k)</em>{k\neq i}$ 的相似性，相似性的定义为 cosine 相似性如下</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/1.png" class=""><p>contrastive prediction loss 如下</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/2.png" class=""><h3 id="SSKD-Framework"><a href="#SSKD-Framework" class="headerlink" title="SSKD Framework"></a>SSKD Framework</h3><p>教师网络和学生网络都由三个部分组成</p><ul><li>backbone $f(\cdot)$</li><li>classifier $p(\cdot)$</li><li>自监督模块 SS $c(\cdot,\cdot)$</li></ul><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/3.png" class=""><p><strong>Training the teacher network</strong></p><ul><li>第一阶段：标准训练，用正常的数据集去训练 $f(\cdot)$ 和 $p(\cdot)$</li><li>第二阶段：固定住 backbone，然后训练 SS 模块，它是一个两层的 MLP，contrastive learning 用到 4 种 transformations，分别为 color dropping、rotation、clipping + resizing、color jittering。</li></ul><p><strong>Training the student network</strong></p><p>四个 loss 组成</p><ul><li>cross entropy</li><li>kd loss，教师的输出和学生的输出</li></ul><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/4.png" class=""><ul><li>SS loss，约束两个相似性矩阵，采取 KL 散度的形式</li></ul><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/5.png" class=""><ul><li>在增广的数据上也进行约束</li></ul><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/6.png" class=""><p>由于教师网络的自监督模块只由 2 层 MLP 构成，并且训练过程 backbone 固定，所以很有可能会生成不正确的预测，即认为 $(x<em>k,\tilde{x}_i)</em>{k\neq i}$ 为 positive pair，为了避免这种情况，softmax 之后排序，若正确的在 top-k 个，则认为是 positive pair</p><p><br></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p><strong>Ablation study</strong></p><p>感觉是数据增广的用处要比 SS 的大…</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/7.png" class=""><p><strong>k值的影响</strong></p><p>既要保留一点的错误，也不能容忍全部错误</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/8.png" class=""><p><strong>不同自监督任务对比</strong></p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/9.png" class=""><p><strong>cifar100上的结果</strong></p><p>可以看出不同架构的知识蒸馏提升很大</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/10.png" class=""><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/11.png" class=""><p><strong>further study</strong></p><p>在 few-shot 和 noisy label 的情况下，SSKD 也能很好地提取知识</p><img src="/2020/08/06/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Knowledge-Distillation-Meets-Self-Supervision/12.png" class="">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Title: Knowledge Distillation Meets Self-Supervision&lt;br&gt;Conference: ECCV 2020&lt;br&gt;Authors: Guodong Xu, Ziwei Liu, et al&lt;br&gt;Abstract: 作者提出用自监督的方式去提取一些更加 general 的知识，并将它用来知识蒸馏，能大幅度提升不同网络架构之间的蒸馏效果。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Regularizing Class-wise Predictions via Self-knowledge Distillation</title>
    <link href="http://vincentho.name/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/"/>
    <id>http://vincentho.name/2020/06/24/【论文阅读】——-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/</id>
    <published>2020-06-24T08:18:09.000Z</published>
    <updated>2022-07-05T12:44:37.653Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title : Regularizing Class-wise Predictions via Self-knowledge Distillation<br>Authors : Sukmin Yun, Jongjin Park, et al<br>Conference : CVPR 2020<br>Abstract : 作者提出了一个简单的自蒸馏策略，通过约束相同类别的样本要输出尽可能相似的结果，得到不错的提升。</p></blockquote><span id="more"></span><p><br></p><h2 id="Class-wise-Self-knowledge-Distillation-CS-KD"><a href="#Class-wise-Self-knowledge-Distillation-CS-KD" class="headerlink" title="Class-wise Self-knowledge Distillation (CS-KD)"></a>Class-wise Self-knowledge Distillation (CS-KD)</h2><p>在之前的文章里面也有提到，蒸馏更像是对网络的一个正则项，这里的 CS-KD 同样也是作为一个正则的方法，通过约束相同类别的样本之间的输出，从而减少类别内样本输出的方差</p><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/1.png" class="" width="500" height="500"><p>上图同样为鸟类别的两张图片，同时输入到一个网络，然后约束他们的输出概率要尽可能地类似，这里相当如引入了一个虚拟教师网络，而这个教师网络就是学生网络本身，并且和一般的 KD 不同点在于，两个网络的输入不同，下面是自蒸馏损失，$\tilde{\theta}$ 是 $\theta$ 的一个 copy，$x^\prime$ 和 $x$ 具有相同标签。</p><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/2.png" class=""><p>整体的训练流程如下，对于每一个 batch 的图片，会抽样出另一个 batch，并且拥有相同的标签</p><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/3.png" class=""><p><br></p><h2 id="Effects-of-class-wise-regularization"><a href="#Effects-of-class-wise-regularization" class="headerlink" title="Effects of class-wise regularization"></a>Effects of class-wise regularization</h2><p>作者提出的 CS-KD 能够实现两个目标</p><ul><li>避免 over-confident 的预测，因为它拿其他样本的输出作为软标签，这比 label smoothing regularization 构造的人工软标签要更加真实。对于误分类的样本，用 CS-KD 训练的网络，会在正确类别上有更加高的概率</li></ul><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/4.png" class=""><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/5.png" class=""><ul><li>减少类别内输出概率的方差，这也是损失函数最直接的目标</li></ul><p><br></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h4 id="对比其他的正则化方法"><a href="#对比其他的正则化方法" class="headerlink" title="对比其他的正则化方法"></a>对比其他的正则化方法</h4><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/6.png" class=""><h4 id="对比其他自蒸馏的方法"><a href="#对比其他自蒸馏的方法" class="headerlink" title="对比其他自蒸馏的方法"></a>对比其他自蒸馏的方法</h4><ul><li>DDGSD : data-distortion guided self-distillation 是一种一致性正则，约束不同数据增广版本的图片输出一致</li><li>BYOT : be your own teacher 用深层特征指导浅层特征</li></ul><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/7.png" class=""><h4 id="和其他方法融合"><a href="#和其他方法融合" class="headerlink" title="和其他方法融合"></a>和其他方法融合</h4><p>这里做了和 mixup 还有 kd 融合的结果，均是可以与其他方法相容的</p><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/8.png" class=""><img src="/2020/06/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Regularizing-Class-wise-Predictions-via-Self-knowledge-Distillation/9.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title : Regularizing Class-wise Predictions via Self-knowledge Distillation&lt;br&gt;Authors : Sukmin Yun, Jongjin Park, et al&lt;br&gt;Conference : CVPR 2020&lt;br&gt;Abstract : 作者提出了一个简单的自蒸馏策略，通过约束相同类别的样本要输出尽可能相似的结果，得到不错的提升。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Revisiting Knowledge Distillation via Label Smoothing Regularization</title>
    <link href="http://vincentho.name/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/"/>
    <id>http://vincentho.name/2020/06/22/【论文阅读】——-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/</id>
    <published>2020-06-22T02:01:02.000Z</published>
    <updated>2022-07-05T12:44:37.664Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title : Revisiting Knowledge Distillation via Label Smoothing Regularization<br>Authors : Li Yuan, et al<br>Conference : CVPR 2020<br>Abstract : 作者做了两组 demo 实验，一是用学生网络蒸馏教师网络，二是用未完全训练的教师网络（性能比学生网络还差）去蒸馏学生网络，两组实验的结果均有效。从这两组反常的实验中，作者提出了知识蒸馏的另一个解释：label smoothing regularization，并提出了两个 teacher-free 的知识蒸馏方法，实验表明均有效。</p></blockquote><span id="more"></span><p><br></p><h2 id="Exploratory-Experiments-and-Counterintuitive-Observations"><a href="#Exploratory-Experiments-and-Counterintuitive-Observations" class="headerlink" title="Exploratory Experiments and Counterintuitive Observations"></a>Exploratory Experiments and Counterintuitive Observations</h2><p>我们一般对知识蒸馏的印象是：通过一个复杂的教师网络，把教师网络的输出对学生网络进行指导，从而提升学生网络的性能。而对分类任务中，知识蒸馏的有效性解释一般为软标签中蕴含了类别之间的相关性信息，这是软标签对比于硬标签的优势。</p><p>这里作者探索了两种特殊的知识蒸馏设定</p><ul><li>学生网络指导教师网络，叫做 reversed knowledge distillation (Re-KD)</li><li>poorly-trained 的教师网络指导学生网络，这里的 poorly-trained 指的是教师网络只训练了几个迭代，结果远比学生网络差，叫做 defective knowledge distillation (De-KD)</li></ul><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/1.png" class=""><p>按照我们对知识蒸馏的理解，上面这两种知识蒸馏都不会有效，可是作者进行了大量的实验证明，这两种蒸馏均是有效果的，这驱使作者去思考知识蒸馏背后的解释。</p><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/2.png" class=""><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/3.png" class=""><p><br></p><h2 id="Knowledge-Distillation-and-Label-Smoothing-Regularization"><a href="#Knowledge-Distillation-and-Label-Smoothing-Regularization" class="headerlink" title="Knowledge Distillation and Label Smoothing Regularization"></a>Knowledge Distillation and Label Smoothing Regularization</h2><p>上面的实验结果也反映了，知识蒸馏有效性的解释不止在于软标签中蕴含的类别相似性信息，因为学生网络或者 poorly-trained 的教师网络他们的软标签里面相似性信息肯定不足，并且甚至很多软标签本身分类就是错误的，这样的软标签竟然有用，作者给出的解释是，这里的软标签就类似于一种标签平滑的正则，下面先回顾一下 label smoothing regularization (LSR)。</p><p>在 LSR 里面，标签并不是一个 one-hot 的硬标签，而是经过一定的平滑，没有 LSR 的时候，网络的损失函数如下，其中 $q(k)$ 就是 one-hot 的硬标签。</p><script type="math/tex; mode=display">H(q,p)=-\sum_{k=1}^Kq(k)log(p(k))</script><p>而 LSR 是把 $q(k)$ 进行平滑，加入了一个均匀分布的 $u(k)=1/K$， 使得</p><script type="math/tex; mode=display">q^{\prime}(k)=(1-\alpha)q(k)+\alpha u(k)</script><p>此时的损失函数变为</p><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/4.png" class=""><p>由于 $H(u)$ 是一个常数</p><script type="math/tex; mode=display">L_{LS}=(1-\alpha)H(q,p)+\alpha D_{KL}(u,p)</script><p>而知识蒸馏的设定里面，学生网络的损失函数同样包含两项，$\tau$ 是温度 temperature</p><script type="math/tex; mode=display">L_{KD}=(1-\alpha)H(q,p)+\alpha D_{KL}(p_{\tau}^t, p_\tau)</script><p>对比 $L<em>{LS}$ 和 $L</em>{KD}$，唯一不同在于 $u$ 和 $p_\tau ^t$，我们可以将 KD 看成是一个特殊的 LSR，特殊点在于用于平滑的分布是一个学习出来的教师网络，而不是一个预先设定好的分布；或者我们可以将 LSR 看成一个特殊的知识蒸馏，$u$ 是一个虚拟的教师网络，对于每个类别都给出相同的概率。</p><p>从下面的可视化图看出，当增大温度，网络的输出就更加趋向于一个均匀分布，KD 也就越加取向 LSR</p><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/5.png" class=""><p>因此 Re-KD 和 De-KD 可以解释为这些 poorly-trained 的网络输出的软标签在高温度下能给学生网络提供一个正则的作用，因此上面的实验结果有效更多是在高温度的设定下进行的，作者在附录中也给出了参数，温度设为 20.</p><p><br></p><h2 id="Teacher-free-Knowledge-Distillation-Tf-KD"><a href="#Teacher-free-Knowledge-Distillation-Tf-KD" class="headerlink" title="Teacher-free Knowledge Distillation (Tf-KD)"></a>Teacher-free Knowledge Distillation (Tf-KD)</h2><p>基于上面的结论，软标签更多的作用在于正则项，而不是类别相似性，因此我们可以压根不需要教师网络来提供这样的一个正则项，作者提出了两种 Tf-KD，第一种为 $Tf-KD_{self}$，这个更多像 born again network，先训练一个网络，再用该网络作为教师网络，重新训练一个学术网络。</p><p>第二种为 $Tf-KD_{reg}$，通过自己设定了一个教师网络的输出，使得网络在正确类别上有着相当高的概率，这里的 $a$ 通常设置为 0.9 以上</p><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/6.png" class=""><p>同样的，两种设定下的温度系数都是 $\tau \ge 20$，使得软标签更像 LSR</p><p><br></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/7.png" class=""><img src="/2020/06/22/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Revisiting-Knowledge-Distillation-via-Label-Smoothing-Regularization/8.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title : Revisiting Knowledge Distillation via Label Smoothing Regularization&lt;br&gt;Authors : Li Yuan, et al&lt;br&gt;Conference : CVPR 2020&lt;br&gt;Abstract : 作者做了两组 demo 实验，一是用学生网络蒸馏教师网络，二是用未完全训练的教师网络（性能比学生网络还差）去蒸馏学生网络，两组实验的结果均有效。从这两组反常的实验中，作者提出了知识蒸馏的另一个解释：label smoothing regularization，并提出了两个 teacher-free 的知识蒸馏方法，实验表明均有效。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Incremental Learning with Knowledge Distillation</title>
    <link href="http://vincentho.name/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/"/>
    <id>http://vincentho.name/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/</id>
    <published>2019-11-30T04:20:39.000Z</published>
    <updated>2022-07-05T12:44:37.327Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍增量学习 (incremental learning) 和知识蒸馏相结合的文章</p><ul><li>Large Scale Incremental Learning</li><li>End-to-End Incremental Learning</li><li>iCaRL: Incremental Classiﬁer and Representation Learning</li></ul><span id="more"></span><p><em>preview</em></p><p>增量学习：传统的学习策略是，给定一堆数据集，然后训练一个模型，数据集限定了模型需要学习的东西；但人类的学习策略是渐进的，我们可能会先从一批数据中学习出一些知识，然后再从另外一批数据中学习另外的知识并且不会忘记之前的知识。但是到了深度学习模型，假如我们先让模型学习一个数据集 A，再让模型学习数据集 B（这时候数据集 A 已经不可获取），这时候模型就会彻底忘记数据集 A 中学到的知识，这个称为灾难性遗忘 (catastrophic forgetting)，是增量学习中所要解决的问题。增量学习是一种渐进式的学习策略，后面学习的时候，前面学习用到的数据集不可获取，这是增量学习的基本背景，如何能够在新数据集下引入旧数据集，或者如何能够保存旧数据集下学习到的知识，成为关键。</p><p>增量学习又分为数据增量、特征增量和类别增量。数据增量比较好理解，就是增加了额外的数据继续训练；特征增量指在特征数量增多；类别增量指类别数量增多，比如初代模型 $M_0$ 学习到 10 个类别，第二批数据为另外的 10 个类，我们要求第二代模型 $M_1$ 要学习到 20 个类别，既要记住之前学习的 10 个类别，也要学会新的 10 个类别。</p><p>我们重点关注的是类别增量，因为标准数据集 CIFAR-100 和 ImageNet 天然就是一个类别增量的数据集，我们可以 10 类一个单位的增加。类增量的算法围绕如何在新数据集学习下引入旧数据的信息，其主要有三类：</p><ul><li>不采用旧数据</li><li>用合成数据，训练一个生成模型去生成一些旧数据，然后混合新数据一起训练。</li><li>用少量的旧数据作为 exemplar，从旧数据中挑选出一些代表数据 exemplar，然后混合新数据一起训练。</li></ul><p>在研究一个增量学习算法时，我们要时刻关注这四个方面：旧数据，新数据，旧模型，新模型。旧数据如何引入到新模型？旧模型的参数如何辅助新模型训练？旧模型和新模型之间是否存在共用参数？</p><p>下面我们看看这 3 篇论文如何解决上面提到的这些问题。</p><p><br></p><h1 id="Large-Scale-Incremental-Learning"><a href="#Large-Scale-Incremental-Learning" class="headerlink" title="Large Scale Incremental Learning"></a>Large Scale Incremental Learning</h1><blockquote><p>Conference: CVPR2019<br>Authors: Yue Wu, Yinpeng Chen, et al</p></blockquote><h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><p>整体的流程如下，首先我们先看数据方面，可以看出该方法属于上面提到的第三类方法，即保存少部分的旧数据作为 exemplar，然后混合新数据一起训练，数据集分为训练集和验证集，训练的过程作者分为两个阶段，第一阶段新旧数据一起训练，第二阶段为 bias correction，用验证集去训练。</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/1.png" class="" width="500" height="500"><h3 id="Stage-I-baseline-method"><a href="#Stage-I-baseline-method" class="headerlink" title="Stage I: baseline method"></a>Stage I: baseline method</h3><p>我们先看下第一阶段的训练过程，如下图，可以看出新模型和旧模型并不是共享某些层的，新模型需要重新训练，但他们的结构基本相同，除了最后的 FC 层的类别数量，旧模型输出为 n 类的概率值，新模型输出的是 n+m 类的概率值</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/2.png" class="" width="500" height="500"><p>回答上面提到的问题，旧模型和旧数据如何利用？</p><ul><li>新数据为 $X^m={(x_i, y_i), 1\le i\le M, y_i \in [n+1, …,n+m]}$</li><li>旧数据 exemplar 为 $\hat{X}^n={(\hat{x}_j, \hat{y}_j), 1\le j\le N_s, \hat{y}_j \in [1, …,n]}$</li><li>新模型的输出 $o^{n+m}(x)=[o<em>1(x), …,x_n(x), o</em>{n+1}(x),…,o_{n+m}(x)]$</li><li>旧模型的输出 $\hat{o}^n(x)=[\hat{o}_1(x), …,\hat{o}_n(x)]$\</li></ul><p>我们把旧模型作为 teacher 模型，进行知识蒸馏，注意这里蒸馏的时候只在前面 n 个类别上进行，并且用到的是全部数据，即新数据和旧数据，有人可能会问为什么新数据也要进行蒸馏，旧模型是在旧类别上训练的，但是将新数据输入到旧模型里面，我们依旧能得到新数据在就类别上的预测概率值，可以知道新图片在旧类别上的概率分布，这对于新模型 FC 层前 n 个神经元的训练还是有所帮助的。</p><p>利用蒸馏，我们可以一定程度上缓解灾难性遗忘，把旧数据在旧模型输出的 logit 迁移到新模型 FC 层的前 n 个神经元上</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/3.png" class="" width="500" height="500"><p>除了蒸馏损失，分类损失也是必须的，因为我们现在有新数据还有旧数据的 exemplar，所以直接将它在新模型上训练，这里训练的是 FC 层的所有神经元。</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/4.png" class="" width="500" height="500"><p>我们看一下新模型 FC 层的 n+m 个神经元分别受到哪些监督信息</p><ul><li>前 n 个神经元：新旧数据在旧模型输出 logit 的知识蒸馏，旧数据 exemplar 的 ground-true 信息</li><li>后 m 个神经元：新数据的 ground-true 信息</li></ul><p>增量学习需要解决的就是如何使得新模型的前 n 个神经元能够保存旧类的分类能力，这里采取的是蒸馏的方法。</p><p>上面的方法是把蒸馏用到增量学习的 baseline 方法，但由于新旧类数据量不均衡，新类的数据要远多于旧类的 exemplar，这会导致 FC 层会更多的偏向于后面 m 个神经元，因为后面 m 个神经元受到的监督信息更多，虽然前面 n 个神经元我们已经尽力去补充监督信息，但依旧无法缓解 bias 的问题，从下图可以看出，当在做最后一次增量学习的时候（100 类别，每次增加 20 类），预测的类别多数都在 81-100 类。</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/5.png" class="" width="300" height="300"><p>作者猜测这是由于数据不均衡所导致的，因此做了个小实验，先用上面的这个 baseline 方法训练一个新模型（这个模型 FC 层存在 bias 问题），然后再用全部的新旧数据（该数据不存在类别不均衡问题）去 fine-tune 最后的 FC 层，发现 bias 问题被解决，分类准确率也提升了。但是现实情况，我们肯定是不可能获取得到全部的旧数据的，因此作者提出一种 bias correction (biC) 的方法去调整 FC 层。</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/6.png" class="" width="300" height="300"><h3 id="Stage-II-bias-correction"><a href="#Stage-II-bias-correction" class="headerlink" title="Stage II: bias correction"></a>Stage II: bias correction</h3><p>首先需要把数据集划分为训练集和验证集，注意验证集新旧类别必须均衡，可以看上面的总流程图，由于验证集很小，新旧类别的数据都很少，所以作者在 FC 层后加了一个线性模型来矫正 bias，对于 FC 层前 n 个输出，保持原值，对于后 m 个输出，进行矫正</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/12.png" class="" width="400" height="400"><p> 当进行 bias correction 的时候，前面的特征提取层和 FC 层都是固定的，只训练线性模型，loss 函数如下</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/13.png" class="" width="400" height="400"><p><br></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>实验设置基本和 EEIL 和 iCaRL 一样（下面讨论这两篇文章），作者分别在大数据集 ImageNet 和小数据集 CIFAR-100 上测试了结果，实验表明 bias correction 这种方法都比 EEIL 和 iCaRL 要好，但是在大数据集上的提升会更加明显</p><h3 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h3><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/7.png" class="" width="700" height="700"><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/8.png" class="" width="300" height="300"><h3 id="CIFAR-100"><a href="#CIFAR-100" class="headerlink" title="CIFAR-100"></a>CIFAR-100</h3><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/9.png" class="" width="700" height="700"><p><br></p><h1 id="End-to-End-Incremental-Learning"><a href="#End-to-End-Incremental-Learning" class="headerlink" title="End-to-End Incremental Learning"></a>End-to-End Incremental Learning</h1><blockquote><p>Conference: ECCV2018<br>Authors: Francisco M. Castro, et al</p></blockquote><p>EEIL 同样是基于 exemplar 的方法，在上面的文章，我们侧重说了蒸馏如何用到增量学习上，这篇文章的蒸馏思路和上篇基本类似，这里我们侧重说下 exemplar 的选取。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>流程图如下，训练分为四步：</p><ul><li>构造训练集</li><li>蒸馏训练</li><li>balanced fine-tune</li><li>构造 exemplar set</li></ul><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/10.png" class="" width="600" height="600"><h3 id="exemplar"><a href="#exemplar" class="headerlink" title="exemplar"></a>exemplar</h3><p>作者提出了两种策略，分别为固定总的 memory size 和 固定每个类别的 memory size，前者随着增量学习的进行，每个旧类的样本数量会减少，后者随着增量学习的进行，内存会增大。</p><p>训练前，先将新数据和旧数据进行融合，构造出训练集，训练完后，将新数据加入到 memory，如何挑取加入到 memory 的样本，作者提出了两种方法</p><ul><li>随机策略</li><li>herding selection：计算该类别样本的均值，计算每个样本距离均值的距离，选出最靠近均值的样本</li></ul><p>新数据的加入必然会导致旧数据样本数量的减少，因为旧数据也是通过 herding 的方式加入到内存的，在移除旧数据的时候，同样采取该策略，移除距离均值最大的样本。</p><h3 id="training-process"><a href="#training-process" class="headerlink" title="training process"></a>training process</h3><p>训练过程，旧模型输出的是 n 个类别的 logit，作为 teacher 模型，新模型输出的是 n+m 个类别的 logit，同样分为两个 loss</p><ul><li>cross entropy loss：新旧数据同时用上来训练新模型</li><li>distillation loss：和上一篇文章唯一不同的是，这里它只用了旧数据，旧数据在旧模型输出的 logit 作为软标签，指导新模型 FC 层的前 n 个神经元。而上篇文章是将新旧数据都输入到旧模型来作为软标签。</li></ul><h3 id="balanced-fine-tuning"><a href="#balanced-fine-tuning" class="headerlink" title="balanced fine-tuning"></a>balanced fine-tuning</h3><p>为了解决类别不均衡带来的问题，跟上篇文章一样，新旧类选取相同数量的样本作为验证集进行 fine-tune，这里会用更小的学习率</p><p><br></p><h1 id="iCaRL-Incremental-Classiﬁer-and-Representation-Learning"><a href="#iCaRL-Incremental-Classiﬁer-and-Representation-Learning" class="headerlink" title="iCaRL: Incremental Classiﬁer and Representation Learning"></a>iCaRL: Incremental Classiﬁer and Representation Learning</h1><p>总结前两篇文章，发现增量学习的知识蒸馏的基本围绕以下 4 个损失来设计，分类损失均为数据在新模型下输出 logit 和标签之前的损失，蒸馏损失均为数据在新旧模型输出 logit 之间的损失。</p><ul><li>新数据的分类损失</li><li>新数据的蒸馏损失</li><li>旧数据的分类损失</li><li>旧数据的蒸馏损失</li></ul><p>第一篇文章为 4 个损失均有，EEIL 为第1、3、4 个损失的结合；而 iCaRL 为第1、2、4 个损失的组合。</p><p>除此之外，iCaRL 在分类上采取的是最近邻分类策略，算出每个类别的平均特征图，计算最近的一个，则为分类结果。</p><img src="/2019/11/30/Incremental-Learning-with-Knowledge-Distillation/11.png" class="" width="500" height="500"><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍增量学习 (incremental learning) 和知识蒸馏相结合的文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large Scale Incremental Learning&lt;/li&gt;
&lt;li&gt;End-to-End Incremental Learning&lt;/li&gt;
&lt;li&gt;iCaRL: Incremental Classiﬁer and Representation Learning&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】——Be Your Own Teacher, Improve the Performance of Convolutional Neural Networks via Self Distillation</title>
    <link href="http://vincentho.name/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/"/>
    <id>http://vincentho.name/2019/11/08/【论文阅读】——Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/</id>
    <published>2019-11-08T12:03:12.000Z</published>
    <updated>2022-07-05T12:44:37.704Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title：Be Your Own Teacher, Improve the Performance of Convolutional Neural Networks via Self Distillation<br>Author：Linfeng Zhang, et al.<br>Session：ICCV, 2019<br>Abstract：作者提出一种新的 self-distillation 的策略，用网络深层的特征和预测结果去监督浅层网络的学习。</p></blockquote><span id="more"></span><p><br></p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>作者的方法比较直观简单，如下框图，作者共提出了三种监督信息，全都是从网络深层传至网络浅层，网络共分为四块，每一块得到一个特征图，特征图后接全连接网络和 softmax 得到预测结果，作者称其为浅层 classifier 和深层 classifier。三种监督信息分别是</p><ul><li>特征监督，深层的特征图对比浅层特征图。</li><li>标签监督，网络最后 softmax 输出的软标签对比前面 3 个浅层分类器得到的软标签。</li><li>真实数据监督，one-hot 对比各个分类器的输出。</li></ul><p>整体的 loss 如下，C 为分类器的个数，即将网络切分的个数。</p><script type="math/tex; mode=display">loss = \sum_{i=1}^C (1-\alpha)\cdot CrossEntropy(q^i,y)+\alpha \cdot KL(q^i,q^C)+\lambda \cdot ||f_i-F_C||_2^2</script><img src="/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/1.png" class=""><p><br></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>作者展示了四个分类器的结果，以及集成的效果，对比 baseline 和 classifier 4/4，可见自蒸馏的效果。</p><img src="/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/2.png" class=""><p>对比其他特征蒸馏的方法，也是一致的提升。</p><img src="/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/3.png" class=""><p><br></p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>作者的另外一篇文章， SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models，两者用的是同一个框架和训练思路，但是出发点不同，这篇文章的出发点在于自蒸馏，而 SCAN 出发点在于 adaptive computation，即自适应地去选择需要经过的网络层，如果浅层分类的结果还令人满意，就不再经过后面的网络，从而实现加速。网络结构基本一样，除了加入了注意力模块。</p><img src="/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/4.png" class=""><p>accuracy 和 acceleration的 tradeoff 如下。</p><img src="/2019/11/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94Be-Your-Own-Teacher-Improve-the-Performance-of-Convolutional-Neural-Networks-via-Self-Distillation/5.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title：Be Your Own Teacher, Improve the Performance of Convolutional Neural Networks via Self Distillation&lt;br&gt;Author：Linfeng Zhang, et al.&lt;br&gt;Session：ICCV, 2019&lt;br&gt;Abstract：作者提出一种新的 self-distillation 的策略，用网络深层的特征和预测结果去监督浅层网络的学习。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Discussion on the efficacy of teacher networks in knowledge distillation</title>
    <link href="http://vincentho.name/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/"/>
    <id>http://vincentho.name/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/</id>
    <published>2019-11-04T13:20:24.000Z</published>
    <updated>2022-07-05T12:44:37.286Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍几篇最近看到的论文，这些论文都共同讨论了教师网络的有效性，当我们在进行知识蒸馏的时候，都会想到的一个问题是：应该选择什么样的教师网络去进行知识迁移？是否越深准确率越高的大网络就一定有利于知识蒸馏呢？答案不是肯定的。这几篇文章从实验的角度给我们展示了在不同教师网络设定下的知识蒸馏的结果，并且提出改进。</p><p>本文讨论的论文如下：</p><ul><li>Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher</li><li>On the Efﬁcacy of Knowledge Distillation</li><li>Distilling Knowledge From a Deep Pose Regressor Network</li></ul><span id="more"></span><p><br></p><h2 id="Improved-Knowledge-Distillation-via-Teacher-Assistant-Bridging-the-Gap-Between-Student-and-Teacher"><a href="#Improved-Knowledge-Distillation-via-Teacher-Assistant-Bridging-the-Gap-Between-Student-and-Teacher" class="headerlink" title="Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher"></a>Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher</h2><p>这是 DeepMind 今年放在 arxiv 上的一篇文章，作者通过一些小实验发现，在进行知识蒸馏的时候，增加教师网络的模型大小反而会使得知识蒸馏的效果变差，结果如下，学生网络是一个 2 层的 CNN，而教师网络分别是 4-10 层的 CNN，从结果可以看出，继续增加教师网络深度，并不一定能提高知识蒸馏的性能。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/1.png" class="" width="500" height="500"><p>从这个 toy experiment 可以看出，教师网络和学生网络之间的 Gap 确实是影响知识蒸馏的一个重要因素，当 Gap 变大的时候，从图中可以得出以下几个结论</p><ul><li>教师网络的性能不断提高，证明不是过拟合导致的知识蒸馏性能下降。</li><li>教师网络的 capacity 不断增大，而学生网络的 capacity 不变，当 gap 增大到一定程度，学生网络的 capacity 不足以支撑其模仿教师网络。</li><li>教师网络的性能不断提高，对于训练样本置信度增高，使得教师网络提供的软标签变“硬”，这也使得知识蒸馏性能下降。</li></ul><p>为了进一步证明 gap 确实影响知识蒸馏，作者做了一个小对比实验，固定教师网络为 10 层 CNN，改变学生网络的层数，结果如下，确实当 gap 大于某个阈值或者小于某个阈值的时候，知识蒸馏的效果都不是最优。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/2.png" class="" width="500" height="500"><p>基于这个观察，作者很自然地提出在大网络和小网络之间增加一个中等大小的网络（teacher assistant，TA），先用教师网络蒸馏 TA，再用 TA 蒸馏学生网络。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/3.png" class="" width="500" height="500"><p>当加入 TA 后，学生网络的蒸馏效果明显比直接蒸馏教师网络要好，NOKD = 没有 KD，BLKD = baseline KD，TAKD 是作者提出的方法。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/4.png" class="" width="500" height="500"><p>一个很自然的问题是，为什么要用蒸馏的 TA，而不直接训练一个 TA 呢？结果显示蒸馏的 TA 效果更好，从右图可以看出，蒸馏的 TA (KD-TA) 比直接训练的 TA (FS-TA) 要好。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/5.png" class="" width="500" height="500"><p>作者同时尝试了多阶段的 TA，即蒸馏一个 TA，再用该 TA 蒸馏下一个 TA，以此类推，结果如下，越多个阶段效果越好，但是越费时间和空间，这里的结果和上面 Table 1 的结果有一点矛盾，可以看出 10 -&gt; 2 实际就是 BLKD，但是这里显示的结果是 42.56，Table 1 显示的结果是 44.57，而 44.57 是 10 -&gt; 6 -&gt; 2 的结果，不知道是笔误还是什么。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/6.png" class="" width="700" height="700"><p>作者同时也对比了其他蒸馏方法，BSS 为基于对抗样本的蒸馏，MUTUAL 为 deep mutual learning，虽然结果显示作者的方法结果最好，但是这些方法差异较大，没有太多比较的必要，FITNET, AT, FSP 都是特征蒸馏方法，而 TAKD 为软标签蒸馏，但是可以看出作者提出的 TAKD 还是普遍好于其他的方法。同样的，这里也有一个和 Table 1 矛盾的地方，ResNet8 的 NOKD 在 Table 1 为 88.52，这里就变成了 86.02。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/7.png" class=""><p>这篇文章提出了一个影响知识蒸馏的因素：gap，学生网络的表达能力或者 capacity 有限，而如果教师网络太过强，就会提供一些超过学生网络能够学习范围的知识，就会导致反作用，因此如何找到恰当大小的教师网络是一个比较难的问题，作者采用的 TA 的方式，层层蒸馏，下一层吸收上一层的知识，再传递给下一层，确实是一个很好的办法，这解决了我们不知道选什么大小的教师网络的问题。</p><p><br></p><h2 id="On-the-Efﬁcacy-of-Knowledge-Distillation"><a href="#On-the-Efﬁcacy-of-Knowledge-Distillation" class="headerlink" title="On the Efﬁcacy of Knowledge Distillation"></a>On the Efﬁcacy of Knowledge Distillation</h2><blockquote><p>Authors: Jang Hyun Cho,  Bharath Hariharan<br>Conference: ICCV 2019</p></blockquote><p>跟上面的文章一样，作者也认为 bigger models are not better teachers，但是他并不是做的 toy experiment，而是用 wide-resnet 在 cifar 和 ImageNet 上做了实验。教师网络无论是 wide-resnet 还是 DenseNet，无论是增加深度还是宽度，都是会有 degradation。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/8.png" class=""><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/9.png" class=""><p>而在 ImageNet 上的结果，有点出人意料，可能是 wide-resnet 的缘故，也可能是 ImageNet 的缘故，增加深度，性能不断下降，且 KD 完全无效。学生网络为 ResNet18，教师网络无论选什么，都比学生网络没有蒸馏的差。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/10.png" class="" width="500" height="500"><p>作者将 degradation 的原因归于教师网络和学生网络 capacity 的 mismatch，教师网络太过强大，因此作者提出两种小策略，来选出 capacity 相对较小的教师网络。</p><h3 id="Early-stopping-KD-ESKD"><a href="#Early-stopping-KD-ESKD" class="headerlink" title="Early stopping KD(ESKD)"></a>Early stopping KD(ESKD)</h3><p>作者比较 ResNet18 在蒸馏下和无蒸馏下的 ImageNet 训练曲线发现，KD 一开始是有用的，但到后来就比 scratch 的要差，无论教师网络选择 ResNet34 还是 ResNet50。这两张图直接否定了 KD 的有效性，因此 ImageNet 是否是一个比较难进行知识蒸馏的数据集呢？因为很多 KD 的文章都没有在 ImageNet 上进行验证。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/11.png" class=""><p>基于上面的观察，作者决定提前结束 KD 过程，即 ESKD，结果如下，这时候 KD 确实有效果了，但是网络深度增加，degradation 现象依旧存在。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/12.png" class="" width="500" height="500"><p>ESKD 的训练曲线</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/13.png" class=""><h3 id="Early-stopped-teacher"><a href="#Early-stopped-teacher" class="headerlink" title="Early-stopped teacher"></a>Early-stopped teacher</h3><p>解决 degradation 问题，就要把 teacher 的 capacity 降到 student 能够触碰的范围内，一个简单的方法就是早停策略，即不完全训练的 teacher。不完全训练的 teacher 表现上就和小网络一样。完全训练的 teacher 的实验设定为 200 epoch，60 epoch 将学习率（60/200），不完全训练的 teacher 遵循 (15/50，10/35) 等策略。</p><p>下图为训练不完全的 teacher 用来蒸馏的效果，可以看出都比训练完全的 teacher 要好。</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/14.png" class=""><p>用不同的学生和教师网络同样验证 ES teacher 的有效性</p><img src="/2019/11/04/Discussion-on-the-efficacy-of-teacher-networks-in-knowledge-distillation/15.png" class=""><p>这篇文章主要是实验型文章（实验结果很多），研究教师网络对于 KD 有效性的影响，并且提出两种策略来使得教师网络的 capacity 和学生网络相匹配，第一种方法为提前结束 KD 过程，至于为什么 KD 到了后面会不如 scratch，原因或许出于软标签上；而第二种方法为教师网络主动降低 capacity 来 match 学生网络。</p><p>目前为止的这两篇文章都是围绕如何找到 match 学生网络 capacity 的教师网络。这里改进的点有很多。</p><p><br></p><h2 id="Distilling-Knowledge-From-a-Deep-Pose-Regressor-Network"><a href="#Distilling-Knowledge-From-a-Deep-Pose-Regressor-Network" class="headerlink" title="Distilling Knowledge From a Deep Pose Regressor Network"></a>Distilling Knowledge From a Deep Pose Regressor Network</h2><p>这篇文章在前面有专门的博客介绍，其关注的是回归问题，而不是分类问题，作者认为回归问题的解空间过大，因此对于学生网络不容易学习，并且回归问题中，网络输出是一张图，而不是一个概率分布，一张图是没有任何限制的，因此教师网络很有可能会给出非常错误的知识，因为回归网络的输出并没有任何约束。所以作者提出要对教师网络的输出进行约束，约束为：若教师网络生成的结果很差，就不用 KD，在 KD Loss 前面为每个样本添加一个系数，来衡量该样本是否值得知识迁移。</p><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍几篇最近看到的论文，这些论文都共同讨论了教师网络的有效性，当我们在进行知识蒸馏的时候，都会想到的一个问题是：应该选择什么样的教师网络去进行知识迁移？是否越深准确率越高的大网络就一定有利于知识蒸馏呢？答案不是肯定的。这几篇文章从实验的角度给我们展示了在不同教师网络设定下的知识蒸馏的结果，并且提出改进。&lt;/p&gt;
&lt;p&gt;本文讨论的论文如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improved Knowledge Distillation via Teacher Assistant: Bridging the Gap Between Student and Teacher&lt;/li&gt;
&lt;li&gt;On the Efﬁcacy of Knowledge Distillation&lt;/li&gt;
&lt;li&gt;Distilling Knowledge From a Deep Pose Regressor Network&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Data-Free Learning of Student Networks</title>
    <link href="http://vincentho.name/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/"/>
    <id>http://vincentho.name/2019/10/30/【论文阅读】——-Data-Free-Learning-of-Student-Networks/</id>
    <published>2019-10-30T01:47:36.000Z</published>
    <updated>2022-07-05T12:44:37.557Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title：Data-Free Learning of Student Networks<br>Authors：Hanting Chen, Yunhe Wang et.al<br>Conference：ICCV 2019<br>Abstract：作者提出了一种无需原始数据的蒸馏方式，通过用对抗生成网络（GAN）去生成数据集，能够达到原数据的蒸馏效果</p></blockquote><span id="more"></span><p><em>preface</em></p><p>传统的知识蒸馏框架是基于以下假设：用来训练教师网络的数据集，如 ImageNet、Cifar，同时用来做知识蒸馏时的数据集，但是在现实场景下，用来训练教师网络的数据可能会处于隐私保护的原因，不会公开出来，而公开的仅仅只有教师网络这一个模型，相当于是一个接口，这时候我们没有了训练教师网络的数据集，应该如何进行知识蒸馏来训练学生网络呢？</p><p>解决无数据下的知识蒸馏的基本思路是：构造合成数据集，使得合成的数据集能够模拟原数据集的数据分布。Data-Free 下的知识蒸馏的第一篇论文是 NIPS 2017 workshop 的一篇文章，<a href="https://arxiv.org/pdf/1710.07535.pdf"> Data-free knowledge distillation for deep neural networks</a>，这篇文章的主要思路是通过一些 meta-data 来重构数据集，meta-data 为训练教师网络时收集的一些信息，如网络输出层或中间层的激活值的均值或方差等，然后用这些 meta-data 来指导生成图片，使得合成的图片的激活值方差尽可能地接近 meta-data。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/1.png" class=""><p>但这种方法还是需要 meta-data 作为支撑，而 ICCV 2019 的这篇文章通过 GAN 直接模拟合成数据集，且合成的数据集蒸馏效果更好。</p><p><br></p><h2 id="GAN-Loss-Function"><a href="#GAN-Loss-Function" class="headerlink" title="GAN Loss Function"></a>GAN Loss Function</h2><p>作者提出的整体架构如下，作者把教师网络作为判别器去指导生成器的训练，训练好的生成器生成图片，然后分别通过教师和学生网络，然后进行知识蒸馏。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/2.png" class=""><p>但是传统 GAN 中的判别器时一个二分类的判别器，用来判断生成的图片的真假，而教师网络是多分类网络，用来判断输入图像属于哪一个类别，为了能够使得生成器生成的数据能够尽可能地像原数据集，作者提出了 3 个损失来约束生成器。</p><h3 id="One-hot-Loss"><a href="#One-hot-Loss" class="headerlink" title="One-hot Loss"></a>One-hot Loss</h3><p>先定义一些符号：</p><ul><li>生成器的输入是一些随机的向量：${z^1,z^2,…,z^n }$</li><li>生成器的输出是一些生成的图片：${x^1,x^2,…,x^n }$，$x^i=G(z^i)$</li><li>将生成的图片输入到判别器（教师网络）得到输出：${y^1_T,y^2_T,…,y^n_T }$，$y_T^i=D(x^i)$</li><li>判别器（教师网络）预测的类别：${t^1,t^2,…,t^n }$，$t^i=argmax_j(y^i_T)_j$</li></ul><p>要使生成的图片尽可能像原数据集，首先要使得生成图片通过教师网络后的结果 $y_T^i$ 尽可能地像一个 one-hot 向量，即能够预测出某一个类别出来，因此我们把 $t_i$ 看作是一个伪标签来约束生成器。</p><script type="math/tex; mode=display">L_{oh}=\frac{1}{n}\sum_i H_{cross\_entropy}(y_T^i, t^i)</script><h3 id="Information-Entropy-Loss"><a href="#Information-Entropy-Loss" class="headerlink" title="Information Entropy Loss"></a>Information Entropy Loss</h3><p>除了从单张图片去考虑生成器的生成质量，还要从整体上去考虑，要使生成器生成的图片尽可能地像训练集原始的图片，其次还要做到生成的图片每个类别是均衡的。这里作者用了信息熵来表示各种类别的均衡性，当每个类别生成的概率都一样时，信息熵达到最大值，因此通过最大化信息熵来训练网络，$H_{info}(p)=-\frac{1}{k}\sum_i p_ilog(p_i)$</p><script type="math/tex; mode=display">L_{ie}=-H_{info}(\frac{1}{n}\sum_i y^i_T)</script><p>每个类别的概率为教师网络输出层在不同样本下的平均</p><h3 id="Activation-Loss"><a href="#Activation-Loss" class="headerlink" title="Activation Loss"></a>Activation Loss</h3><p>第三个损失函数是考虑到图片的真实性，一般真实的图片对应的网络激活值都比较大，所以把网络激活值同时加到损失函数里面进行约束。这里用到的特征层为全连接层前的特征图 $f_T^i$</p><script type="math/tex; mode=display">L_a=-\frac{1}{n}\sum_i||f_T^i||_1</script><p><br></p><p>整体的 Loss 为三个 loss 的加权</p><script type="math/tex; mode=display">L_{Total}=L_{oh}+\alpha L_a + \beta L_{ie}</script><p>伪代码如下，训练分为两个阶段，先训练生成器，使得生成器合成的图片尽可能接近真实数据集分布，第二个阶段为用训练好的生成器生成图片来进行知识蒸馏。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/3.png" class=""><p><br></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p>先验证三个 loss 对应的作用，实验设置为：教师网络为 LeNet-5，学生网络为 LeNet-5-HALF，数据集为 MINST。下表结果为用不同损失函数训练出来的生成器进行知识蒸馏后学生网络的性能，从结果可以看出，在 MINST 这种简单的数据集，即使不训练生成器，随机的图片都有 88 的精度，而当不同 loss 被考虑的时候，可以看出信息熵损失是最有用的，当没有信息熵损失的时候，结果都很差。另外两个损失作为信息熵损失的补充，进一步提升了生成图片的质量</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/4.png" class=""><h3 id="Comparison-with-other-methods"><a href="#Comparison-with-other-methods" class="headerlink" title="Comparison with other methods"></a>Comparison with other methods</h3><h4 id="Results-in-MINST"><a href="#Results-in-MINST" class="headerlink" title="Results in MINST"></a>Results in MINST</h4><ul><li>Normal distribution：不训练生成器，直接用正态分布的随机数据去进行知识蒸馏训练学生网络，然后再用MINST 测试。</li><li>Alternative data：用一个类似 MINST 的数据集 USPS，也是一个手写数字的数据集，用这个数据集去进行知识蒸馏，再用 MINST 测试，可以看出即使是相近的数据集，他们的数据分布也会有一些不一样，所以当用 MINST 测试的时候性能会下降。</li><li>Meta-data：上面提到的 NIPS 2017 workshop 上的方法，用 meta-data 生成数据集，再用合成的数据集来进行知识蒸馏，再用 MINST 测试。</li><li>DAFL：用 GAN 的方式生成数据集，用合成的数据进行知识蒸馏，用用 MINST 测试。</li></ul><p>可以看出用 GAN 生成的数据集是最像原数据集的，因为用合成的图片训练的知识蒸馏比用原 MINST 数据知识蒸馏，性能并没有降太多。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/5.png" class=""><h4 id="Results-in-Cifar"><a href="#Results-in-Cifar" class="headerlink" title="Results in Cifar"></a>Results in Cifar</h4><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/6.png" class=""><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><p>从图片可以看出，生成图片的轮廓还是有点像原始图片的。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/7.png" class=""><p>用生成图片训练的学生网络的 filter 和用原数据训练的教师网络的 filter 接近。</p><img src="/2019/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Data-Free-Learning-of-Student-Networks/8.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title：Data-Free Learning of Student Networks&lt;br&gt;Authors：Hanting Chen, Yunhe Wang et.al&lt;br&gt;Conference：ICCV 2019&lt;br&gt;Abstract：作者提出了一种无需原始数据的蒸馏方式，通过用对抗生成网络（GAN）去生成数据集，能够达到原数据的蒸馏效果&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【高级管理学】—— producer theory</title>
    <link href="http://vincentho.name/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/"/>
    <id>http://vincentho.name/2019/10/16/【高级管理学】——-producer-theory/</id>
    <published>2019-10-16T04:23:48.000Z</published>
    <updated>2022-07-05T12:44:37.755Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>课程名称：高级管理学<br>授课人：Ying Kong<br>本章梗概：本章讲述生产者理论，从利润最大化，成本最小化角度进入，并介绍纯粹竞争以及垄断者模型，最后介绍博弈论模型。</p></blockquote><span id="more"></span><h2 id="Production-Function"><a href="#Production-Function" class="headerlink" title="Production Function"></a>Production Function</h2><p>生产者理论和消费者理论很接近，下表总结两者的异同</p><div class="table-container"><table><thead><tr><th style="text-align:center">生产者理论</th><th style="text-align:center">消费者理论</th></tr></thead><tbody><tr><td style="text-align:center">production function: $y = f(x_1, …,x_n)$，，$x_i$ 为 input level，即每个输入单位数，$y$ 为输出的单位数</td><td style="text-align:center">utility function：$U=f(x_1,…,x_n)$</td></tr><tr><td style="text-align:center">y output unit isoquant：生产单位为 $y$ 的各种 input 组合</td><td style="text-align:center">indifference curve：效用为 U 的各种 bundle</td></tr><tr><td style="text-align:center">perfect substitute：$y=a_1x_1+…+a_nx_n$</td><td style="text-align:center">perfect substitute：$U=x_1+x_2$</td></tr><tr><td style="text-align:center">perfect complement：$y=min(a_1x_1,…,a_nx_n)$</td><td style="text-align:center">perfect complement：$U=min(k_1x_1,k_2x_2)$</td></tr><tr><td style="text-align:center">marginal product：增加一个单位的 $x_i$ 所带来的输出单位数的增加，$MP_i=\frac{\partial P}{\partial x_i}$</td><td style="text-align:center">marginal utility：增加一个单位的 $x_i$ 所带来的效用的增加，$MU_i = \frac{\partial U}{\partial x_i}$</td></tr><tr><td style="text-align:center">technical rate-of-substitution：isoquant 某个点的斜率，$TRS=-\frac{MP_1}{MP_2}$</td><td style="text-align:center">marginal rate-of-substitution(MRS)：indifference curve 某个点的斜率，$MRS=-\frac{MU_1}{MU_2}$</td></tr><tr><td style="text-align:center">long run：生产函数中每一个输入 $x_i$ 都可变，即生产过程不受任何输入约束；short run：生产过程至少一个输入变量为常数。</td></tr></tbody></table></div><p><br></p><h2 id="Profit-and-Cost-theory"><a href="#Profit-and-Cost-theory" class="headerlink" title="Profit and Cost theory"></a>Profit and Cost theory</h2><h3 id="Profit-Maximization"><a href="#Profit-Maximization" class="headerlink" title="Profit Maximization"></a>Profit Maximization</h3><p>生产者在生产过程需要注意的几个变量：</p><ul><li>输入原料：$x_1,…,x_m$</li><li>输出产品：$y_1,…,y_n$</li><li>输入原料价格：$w_1,…,w_m$</li><li>输出产品价格：$p_1,…,p_n$</li></ul><p>生产者利润 profit 的定义：</p><script type="math/tex; mode=display">\Pi = p_1y_1 + ...+ p_ny_n - w_1x_1 - ... - w_mx_m</script><p>假设现在输入只有 $x_1$ 和 $x_2$，输出只有一个 $y$，并且输入为 long run，需要求利润 $\Pi$ 的最大值。问题中，变量为 $x_1, x_2,y$，常量为 $p,w_1,w_2$，利润为 $\Pi=py-w_1x_1-w_2x_2$，而 $y = f(x_1,x_2)$，因此变量减少为两个，分别对 $x_1,x_2$ 求偏导，并令其为 0，则可求得最大值。 </p><script type="math/tex; mode=display">\frac{\partial \Pi}{\partial x_1}=p \times \frac{\partial y}{\partial x_1}-w_1=p \times MP_1 - w_1 = 0</script><script type="math/tex; mode=display">\frac{\partial \Pi}{\partial x_2}=p \times MP_2 - w_2 = 0</script><p>可得</p><script type="math/tex; mode=display">p\times MP_1=w_1, \ p\times MP_2=w_2</script><p>$p\times MP$ 为 marginal revenue，因此 profit 最大的时候，marginal revenue with respect to $x_i$ 等于 marginal cost with respect to $x_i$，这里的 marginal cost with respect to $x_i$ 代表的是增加一单位的输入$x_i$ 所增加的 cost，那明显是等于输入单价 $w_i$</p><h3 id="Cost-Minimization"><a href="#Cost-Minimization" class="headerlink" title="Cost Minimization"></a>Cost Minimization</h3><p>当生产者需要生产 $y$ （已知常数）个产品时，应该以怎样的输入组合才会实现花费最少？这个问题的解法思路和消费者理论中寻求在 budget 约束下的最大效用一样。</p><p>画出 y output unit isoquant，$cost=w_1x_1+w_2x_2$，这个问题就是寻找一个跟曲线相切的点，这个点即为成本最低的能生产 y 个产品的输入 bundle。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/1.png" class="" width="500" height="500"><h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h3><p>我们研究一个企业的开销成本，只考察 cost 和 output level $y$ 的关系，不考察其和 input level $x_i$ 的关系，因此 cost function 定义为 $c(y)$，其可以表示为以下形式</p><script type="math/tex; mode=display">c(y)=F+c_v(y)</script><ul><li><p>$F$ 为生产过程中固定的费用，无论生产多少个产品都固定的费用</p></li><li><p>$c_v(y)$ 为 variable cost function，它随着 input level 而改变</p></li></ul><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/2.png" class="" width="500" height="500"><p>将 output level 加入 cost function 可得 averaged cost function(AC 或 ATC)</p><script type="math/tex; mode=display">AC(y)=\frac{c(y)}{y}=\frac{F}{y}+\frac{c_v(y)}{y}=AFC(y)+AVC(y)</script><p>随着 y 不断增大，AFC 会趋近于 0，AVC 趋近 AC</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/3.png" class="" width="500" height="500"><h3 id="marginal-cost-function"><a href="#marginal-cost-function" class="headerlink" title="marginal cost function"></a>marginal cost function</h3><p>这里的边界成本指的时 output level 变化时所增加的 cost，而上面提到的 marginal cost with respect to $x_i$，是某个输入发生变化时的带来 cost 的变化，其为一个恒定的值，等于 $w_i$，与这里提到的 marginal cost 不同，marginal cost 的定义如下</p><script type="math/tex; mode=display">MC(y)=\frac{\partial c(y)}{\partial y}=\frac{\partial c_v(y)}{\partial y}</script><p>由于 $MC(y)$ 为 $c_v(y)$ 的导数，那么 $c_v(y)$ 则为 $MC(y)$ 的不定积分</p><script type="math/tex; mode=display">c_v(y^\prime)=\int_0^{y^\prime}MC(z)dz</script><p><strong>MC 和 AVC 的关系</strong></p><script type="math/tex; mode=display">\frac{\partial AVC(y)}{\partial y}=\frac{y\times MC(y)-c_v(y)}{y^2}</script><ul><li><p>$\frac{\partial AVC(y)}{\partial y}&gt;0$，$MC(y)&gt;\frac{c_v(y)}{y}=AVC(y)$</p></li><li><p>$\frac{\partial AVC(y)}{\partial y}&lt;0$，$MC(y)&lt;\frac{c_v(y)}{y}=AVC(y)$</p></li><li>$\frac{\partial AVC(y)}{\partial y}=0$，$MC(y)=\frac{c_v(y)}{y}=AVC(y)$</li></ul><p>即 AVC 的最低点是其和 MC 的交点，当 AVC 上升的时候，MC 比它大，当 AVC 下降的时候，MC 比它小</p><p><strong>MC 和 ATC 的关系</strong></p><script type="math/tex; mode=display">\frac{\partial ATC(y)}{\partial y}=\frac{y\times MC(y)-c(y)}{y^2}</script><ul><li><p>$\frac{\partial ATC(y)}{\partial y}&gt;0$，$MC(y)&gt;\frac{c(y)}{y}=ATC(y)$</p></li><li><p>$\frac{\partial ATC(y)}{\partial y}&lt;0$，$MC(y)&lt;\frac{c(y)}{y}=ATC(y)$</p></li><li>$\frac{\partial ATC(y)}{\partial y}=0$，$MC(y)=\frac{c(y)}{y}=ATC(y)$</li></ul><p>同样的结论，即 ATC 的最低点是其和 MC 的交点，当 ATC 上升的时候，MC 比它大，当 ATC 下降的时候，MC 比它小</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/4.png" class="" width="500" height="500"><p><br></p><h2 id="Competition-theory"><a href="#Competition-theory" class="headerlink" title="Competition theory"></a>Competition theory</h2><h3 id="Pure-Competition"><a href="#Pure-Competition" class="headerlink" title="Pure Competition"></a>Pure Competition</h3><blockquote><p>Also regarded as perfect competition, pure competition is a situation in which the market for a product is populated with so many consumers and producers that no one entity has the ability to influence the price of the product sufficiently to cause a fluctuation. Within this type of market setting, sellers are considered to be price takers, indicating that they are not in a position to set the price for their products outside a certain range, given the fact that so many other producers are active within the market. At the same time, consumers have little influence over the prices offered by the producers, since there is no singular group of consumers that dominates the demand. </p></blockquote><p>一个企业对某样产品的市场价格没有影响，而这个产品的市场价格由市场上所有的公司共同决定，其为市场需求和市场供给的交点，如果一个企业将产品价格设高于市场价格，那么它的需求量为 0，因为没有人会买；而如果将产品价格设低于市场价格，那么该企业的需求量为市场的总需求量。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/5.png" class="" width="500" height="500"><p>因此我们可以得到一个企业对于某个产品的需求曲线如下，它是一条平行于 x 轴的直线，高度等于市场价格，意味着企业如果定价等于市场价格，它的需求是没有限制的，而如果价格高于市场价，需求为0。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/6.png" class="" width="500" height="500"><p>对于给定的市场价格 $p$，一个企业应该如何决定生产量 $y$ 使得利润最大化呢，问题定义为</p><script type="math/tex; mode=display">max_{y\ge0}\Pi_s(y)=py-c_S(y)</script><p>对于利润 $\Pi_S(y)$，唯一自变量为 $y$，求利润最大值需要解下面两个条件</p><ul><li><p>一阶导数为 0，得出极值点，$\frac{d\Pi_S(y)}{dy}=p-MC_S(y)=0$</p></li><li><p>二阶导数小于 0，得出极大值点，$\frac{d^2\Pi_S(y)}{dy^2} = -\frac{dMC_S(y)}{dy}&lt;0$</p></li></ul><p>从上面条件，我们可以得出利润最大化的 $y_S^\ast$ 应该满足</p><ul><li>$MC_S(y)$ 与 p 的交点</li><li>交点处于 $MC_S(y)$ 的上升阶段</li></ul><p>上面的步骤只是求得利润的最大值，但并非最大值一定是正的，也可能为负值，当为负值的时候，证明企业在亏损，我们可以比较在交点处的 AC 值和 p 的大小关系，来判断取到最大值时，利润是否为正</p><script type="math/tex; mode=display">\Pi_S(y)=p(y-\frac{C_S(y)}{y})=p(y-AC(y))</script><p>若 $AC(y_S^\ast) \le p$，则不亏， 若 $AC(y_S^\ast)=p$，我们称其为 breakeven price，保本价格，因为无亏损也无盈利，若 $AC(y_S^\ast)&gt;p$，则利润为负，再把成本拆开</p><script type="math/tex; mode=display">\Pi_S(y)=p(y-\frac{C_v(y)}{y})-F=p(y-AVC(y))-F</script><p>若 $AVC(y_S^\ast)&lt;p&lt;AC(y_S^\ast)$，则企业勉强可以生存，虽然依旧亏损，但是起码能支付得起 $c_v(y)$</p><p>若 $AVC(y_S^\ast)&gt;p$，则企业需要关闭，称 $AVC(y_S^\ast)=p$ 的点为 breakdown price</p><p><br></p><h3 id="Producer-surplus-amp-Profit"><a href="#Producer-surplus-amp-Profit" class="headerlink" title="Producer surplus &amp; Profit"></a>Producer surplus &amp; Profit</h3><p>$PS=p\times y^\ast(p)-\int_0^{y^\ast(p)}MC_S(y)=revenue-c_v(y^\ast(p))$</p><p>$\Pi=revenue-c(y^\ast(p))=revenue-c_v(y^\ast(p))-F$</p><p>$PS=Profit+F$</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/7.png" class="" width="500" height="500"><p><br></p><h3 id="Long-Run-Market-Equilibrium-Price"><a href="#Long-Run-Market-Equilibrium-Price" class="headerlink" title="Long-Run Market Equilibrium Price"></a>Long-Run Market Equilibrium Price</h3><p>假设 market demand 曲线固定不变，而 market supply 由市场中的企业所决定，假设一开始只有两个企业，那么市场价格为两条曲线的交点 $p_2$，在 $p_2$ 下企业会盈利，就会导致有第三个企业进入市场，这时候 market supply 曲线发生改变，市场价格 $p_3$ 也因此降低，但此时企业依旧盈利，第四个企业进入，市场价格为 $p_4$，此时企业亏损，有企业会离开市场。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/8.png" class=""><p>以此类推，当市场中的企业足够的多和小的话，那么 market supply 曲线将会是一条水平线，水平线的高度为 $min\ AC(y)$，所以 long run market price $p^e=min\ AC(y)$</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/9.png" class="" width="300" height="300"><p><br></p><h2 id="Monopoly-theory"><a href="#Monopoly-theory" class="headerlink" title="Monopoly theory"></a>Monopoly theory</h2><h3 id="Pure-monopoly"><a href="#Pure-monopoly" class="headerlink" title="Pure monopoly"></a>Pure monopoly</h3><blockquote><p>A market in which one company has control over the entire market for a product, usually because of a barrier to entry such as a technology only available to that company.</p></blockquote><p>pure competition 中的企业都是 market price taker，而pure monopoly 的市场价格完全由垄断者所决定，因此垄断者的利润定义为</p><script type="math/tex; mode=display">\Pi(y)=p(y)y-c(y)</script><p>价格由自己的 demand function 所决定</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/10.png" class="" width="500" height="500"><p>要使得利润 $\Pi(y)$ 最大，求其对 output level $y$ 的偏导，利润最大值下的 output level $y^\ast$ 满足 marginal revenue 等于 marginal cost。</p><script type="math/tex; mode=display">\frac{d \Pi(y)}{dy}=\frac{d}{dy}(p(y)y)-\frac{dc(y)}{dy}=MR(y)-MC(y)=0</script><p>例子：</p><ul><li><p>$p(y)=a-by$，$R(y)=p(y)y=ay-by^2$，$MR(y)=a-2by$</p></li><li><p>$c(y)=F+\alpha y+\beta y^2$，$MC(y)=\alpha+2\beta y$</p></li></ul><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/11.png" class="" width="600" height="600"><p><br></p><h3 id="Monopolistic-Pricing-amp-Own-Price-Elasticity"><a href="#Monopolistic-Pricing-amp-Own-Price-Elasticity" class="headerlink" title="Monopolistic Pricing &amp; Own-Price Elasticity"></a>Monopolistic Pricing &amp; Own-Price Elasticity</h3><script type="math/tex; mode=display">MR(y)=\frac{d}{dy}p(y)y=p(y)+y\frac{dp(y)}{dy}=p(y)(1+\frac{1}{\epsilon})</script><p>假设 $MC(y) = k$，$k$ 为一个常数，那么</p><script type="math/tex; mode=display">p(y^\ast)=\frac{k}{1+\frac{1}{\epsilon}}</script><p>当 $\epsilon$ 往 -1 增大时，垄断者会调整 output level 使得市场价格上升，并且垄断者为了使得自己的 marginal revenue 为正值，会选择弹性商品，即 $\epsilon &lt; -1$</p><p><strong>markup pricing：</strong>市场价格和成本之差</p><script type="math/tex; mode=display">markup = p(y^\ast)-MC(y^\ast)=\frac{k}{1+\frac{1}{\epsilon}}-k=-\frac{k}{1+\epsilon}</script><p>所以当 $\epsilon$ 往 -1 增大时，markup price 也随之增大</p><p><br></p><h2 id="Two-player-Game-Theory"><a href="#Two-player-Game-Theory" class="headerlink" title="Two-player Game Theory"></a>Two-player Game Theory</h2><p>A game consists of</p><ul><li>a set of players</li><li>a set of strategies for each player</li><li>the payoffs to each player for every possible choice of strategies by the players. Payoff matrix is always used to represent the relationship.</li></ul><p>我们只研究两个 player 且每个 player 两种决策的博弈论</p><h3 id="Pure-Strategy"><a href="#Pure-Strategy" class="headerlink" title="Pure Strategy"></a>Pure Strategy</h3><p>每个 player 只能从自己的决策选项中选择一个，考虑下面的例子</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/12.png" class="" width="500" height="500"><p><strong>Nash Equilibrium(NE)：</strong>A play of the game where each strategy is a best reply to the other.</p><p>上面例子中 (U,L) 和 (D,R) 都是 NE，比如当 player A 选择 U 的时候，player B 肯定会选择 L，反过来一样。</p><p>一个 game 可能会有多个 NE，上面的例子，player A 和 B 是同时做选择的，称为 simultaneous play games，我们很难判断这两个 NE 哪个较好；而 sequential play games 通常是先后做选择，先做选择的为 leader，后作选择的为 follower，当选择有先后时，就比较容易判断哪个 NE 较好。下面的图表示如果 A 先做选择，(U,L) 会较好。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/13.png" class="" width="500" height="500"><h3 id="Mixed-Strategy"><a href="#Mixed-Strategy" class="headerlink" title="Mixed Strategy"></a>Mixed Strategy</h3><p>有些 game 如果只用 pure strategy 的话，可能得不到 NE，即无论 player A 怎么选择，player B 总能选出更好的，使得 player A 接着改变选择。而 Mixed strategy 下，player 可以以某个概率去选择某个 strategy，使得整体的 expected payoff 达到 NE。</p><p>下面的例子没有 pure strategy，但是有 Mixed strategy</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/14.png" class="" width="500" height="500"><p>对于有限个玩家且玩家的决策有限的情况，至少会有一个 NE，如果没有 pure strategy NE，那么肯定有 mixed strategy NE。</p><p><br></p><h2 id="Best-Responses-amp-Nash-Equilibrium"><a href="#Best-Responses-amp-Nash-Equilibrium" class="headerlink" title="Best Responses &amp; Nash Equilibrium"></a>Best Responses &amp; Nash Equilibrium</h2><p>上面用 payoff matrix 来找 NE，下面将介绍 best response 的方法来寻找 NE。</p><h3 id="Pure-strategy"><a href="#Pure-strategy" class="headerlink" title="Pure strategy"></a>Pure strategy</h3><p>假设 player A 的两个 action 分别为 $a_1^A$ 和 $a_2^A$，player B 的两个 action 分别为 $a_1^B$ 和 $a_2^B$，payoff matrix 写成类似效用函数的形式</p><ul><li>$U^A(a_1^A,a_1^B)=6$ and $U^B(a_1^A,a_1^B)=4$</li><li>$U^A(a_1^A,a_2^B)=3$ and $U^B(a_1^A,a_2^B)=5$</li><li>$U^A(a_2^A,a_1^B)=4$ and $U^B(a_2^A,a_1^B)=3$</li><li>$U^A(a_2^A,a_2^B)=5$ and $U^B(a_2^A,a_2^B)=7$</li></ul><p>如果 A 选择 $a_1^A$，B 的 best response 为 $a_2^B$；如果 A 选择 $a_2^A$，B 的 best response 为 $a_2^B$。</p><p>如果 B 选择 $a_1^B$，A 的 best response 为 $a_1^A$；如果 B 选择 $a_2^B$，B 的 best response 为 $a_2^A$。</p><p>第一幅图为 B 选择变化时，A 的 best response；第二幅图为 A 选择变化时，B 的 best response，注意横纵坐标不同，将两幅图放在一起，交点即为 NE，即 $(a_2^A,a_2^B)$</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/15.png" class=""><h3 id="Mixed-Strategy-1"><a href="#Mixed-Strategy-1" class="headerlink" title="Mixed Strategy"></a>Mixed Strategy</h3><p>假设 payoff matrix 如下</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/16.png" class="" width="500" height="500"><p>$\pi^A_1$ 为 A 选择 $a_1^A$ 的概率，$1-\pi^A_1$ 为 A 选择 $a_2^A$ 的概率；$\pi^B_1$ 为 B 选择 $a_1^B$ 的概率，$1-\pi^B_1$ 为 B 选择 $a_2^B$ 的概率。假设给定 $\pi_1^B$，我们可以得到 A 选择不同 action 下的平均 payoff</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/17.png" class="" width="400" height="400"><p>当给定 $\pi_1^B$ 时，A 的 best response 为</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/18.png" class="" width="400" height="400"><p>对应的 best response curve 为</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/19.png" class="" width="400" height="400"><p>同理，给定 $\pi_1^A$ 时，B 的情况</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/20.png" class="" width="400" height="400"><p>B 的 best response curve 为</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/21.png" class="" width="400" height="400"><p>找两个曲线的交点，即为 NE，有三个 NE，两个为 pure strategy NE，一个为 mixed strategy NE。</p><img src="/2019/10/16/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-producer-theory/22.png" class=""><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;课程名称：高级管理学&lt;br&gt;授课人：Ying Kong&lt;br&gt;本章梗概：本章讲述生产者理论，从利润最大化，成本最小化角度进入，并介绍纯粹竞争以及垄断者模型，最后介绍博弈论模型。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【高级管理学】—— consumer theory</title>
    <link href="http://vincentho.name/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/"/>
    <id>http://vincentho.name/2019/10/04/【高级管理学】——-consumer-theory/</id>
    <published>2019-10-04T13:56:42.000Z</published>
    <updated>2022-07-05T12:44:37.749Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>课程名称：高级管理学<br>授课人：Ying Kong<br>本章梗概：介绍了消费者的相关理论，如效用函数，需求曲线，弹性等概念。</p></blockquote><span id="more"></span><h2 id="Preference"><a href="#Preference" class="headerlink" title="Preference"></a>Preference</h2><p>bundle：多个不同种类商品的集合，比如 bundle x 为 5 个商品 1 和 10 个商品 2 组成。</p><p>preference：对于不同的 bundle，消费者可以选择其中的一个，对于消费者，两个 bundle 之间会有选择偏好，这就是 preference。对于两个 bundle $x$ 和 $y$，他们之间有三种关系，（由于找不到相关的经济学符号，因此用数学符号来代替）</p><ul><li><p>strict preference：$x$ is more preferred than $y$, denoted as $x&gt;y$</p></li><li><p>weak preference：$x$ is as at least preferred as y, denoted as $x \geq y$</p></li><li><p>indifference：$x$ is exactly as preferred as y, denoted as $x \sim y$</p></li></ul><p>preference relations</p><ul><li><p>$(x \geq y) \ and\ (y\geq x)\ \rightarrow \ (x\sim y)$</p></li><li><p>$(x \geq y)\ and \ (not\  y \geq x) \ \rightarrow \ (x &gt; y)$</p></li><li><p>For any two bundles $x$ and $y$, $(x \geq y)\ or \ (y \geq x)$</p></li><li><p>Any bundle $x$ is always at least as preferred as itself, $x \geq x$</p></li><li><p>$(x \geq y) \  and \ (y \geq x) \ \rightarrow \ (x \geq z)$</p></li></ul><p><br></p><h2 id="Indifference-Curve"><a href="#Indifference-Curve" class="headerlink" title="Indifference Curve"></a>Indifference Curve</h2><p>假设一个 bundle 为 $x$，indifference curve 指的是所有可能的 bundle $y$ 使得 $y \sim x$，即 ${y|y\sim x}$，因此也叫 indifference set。当我们的 bundle 只考虑两种商品 $x_1$ 和 $x_2$ 时，indifference curve 为二维平面上的一条线，如下图：</p><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/1.png" class="" width="500" height="500"><p>一条曲线代表一条 indifference curve，curve 上的任意两个点 $x = (x_1,x_2)$ 和 $y = (x_1^\prime, x_2^\prime)$ 都满足 $x\sim y$，而不同的两条线上的点必定满足 strict preference 的关系，越往右上方的点，越会被 preferred，因此 $l_1$ 上的点都 strict preferred 于 $l_2$ 上的点。</p><p><em>Note：</em>任意两条 indifference curve 必定是无交点的</p><h3 id="Two-Extreme-Cases-of-Indifference-Curve"><a href="#Two-Extreme-Cases-of-Indifference-Curve" class="headerlink" title="Two Extreme Cases of Indifference Curve"></a>Two Extreme Cases of Indifference Curve</h3><h4 id="Perfect-Substitute"><a href="#Perfect-Substitute" class="headerlink" title="Perfect Substitute"></a>Perfect Substitute</h4><p>同样是考虑两种商品组成的 bundle，如果消费者认为商品一和商品二是等同的，那么这两个商品就是 perfect  substitute，由于两者等同，因此在比较不同 bundle 哪个更加被 preferred 的时候，只需考虑两种商品的总数量即可。indifference curve 如下，不同的 curve 的斜率均为 -1。</p><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/2.png" class="" width="500" height="500"><h4 id="Perfect-Complement"><a href="#Perfect-Complement" class="headerlink" title="Perfect Complement"></a>Perfect Complement</h4><p>商品一和商品二总是以固定的比例出现，比如对于一辆小汽车，总是 4 个车轮和 1 个发动机，因此商品一和商品二的比例总是 4:1，即使一个 bundle 里面有再多的车轮或者再多的发动机，我们也只能考虑能够成对的数量，作为是否被 preferred 的依据 (only the number of pairs of units of the two commodities determines the preference rank-order of bundles)</p><p>下面的例子中，商品一和商品二总是以 1:1 的比例出现，因此 (9,5)、(5,5) 和 (5,9) 都是 equally preferred，因为他们都有 5 pairs，而 (9,9) 则 strict preferred 于前面的三个点，因为它有 9 pairs，indifference curve 的形状为直角。</p><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/3.png" class="" width="500" height="500"><h3 id="Marginal-Rate-of-Substitution-MRS"><a href="#Marginal-Rate-of-Substitution-MRS" class="headerlink" title="Marginal Rate-of-Substitution(MRS)"></a>Marginal Rate-of-Substitution(MRS)</h3><p>一条 indifference curve 的斜率就叫做 MRS，它所表示的意思是，我们愿意牺牲多少数量的商品一，去换取商品二，从而使得 equally preferred。对于 perfect substitute 来说，其 MRS 均为 -1，因为两者等同，因此少一个商品二，就会多一个商品一。</p><p><br></p><h2 id="Utility-Function"><a href="#Utility-Function" class="headerlink" title="Utility Function"></a>Utility Function</h2><p>在前面，我们一直用 preference 来衡量两个 bundle 之间的关系，而 utility function（效用函数） 就是用来代表 preference 的</p><ul><li><p>若 $x &gt; y$，则 $U(x) &gt; U(y)$ （前者是 strict preference 符号，后者是数学符号）</p></li><li><p>若 $x \sim y$，则 $U(x) = U(y)$</p></li></ul><p>因此一条 indifference curve 上的所有点，我们都可以说他们的效用是一样的。</p><p><em>Note：</em>效用值是一个 ordinal 的概念，即只关注两个 bundle 间效用的大小关系，至于效用值具体数值并不是关键，比如 x 的效用值为 6，y 的效用值为 2，只能说明 x 比 y 更加 preferred，并不表示 x 比 y 三倍的 preferred。因此假设 x 比 y 更为 preferred，我们可以赋值给 $U(x)$ 和 $U(y)$ 任何值，只要满足 $U(x) &gt; U(y)$ 即可。</p><p>现在我们可以将 indifference curve 和 utility function 放在同一个坐标系里面，xOy 平面依旧是 indifference curve，z 维度表示效用值。</p><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/4.png" class="" width="300" height="300"><p>indifference map：所有的 indifference curve 的集合，其等同于 utility function。</p><p>几种不同的 utility function：</p><ul><li><p>perfect substitute：$U(x_1,x_2)=x_1+x_2$</p></li><li><p>perfect complement：$U(x_1,x_2)=min(k_1x_1,k_2x_2)$</p></li><li><p>quasi-linear：$U(x_1,x_2)=f(x_1)+x_2$</p></li><li>Cobb-Douglas：$U(x_1,x_2)=x_1^ax_2^b$，indifference curve 都是双曲线状</li></ul><h3 id="Marginal-Utility"><a href="#Marginal-Utility" class="headerlink" title="Marginal Utility"></a>Marginal Utility</h3><p>The marginal utility of commodity $i$ is the rate-of-change of total utility as the quantity of commodity $i$ consumed changes.</p><script type="math/tex; mode=display">MU_i=\frac{\partial U}{\partial x_i}</script><p><strong>Marginal Utility &amp; Marginal Rate-of-Substitution</strong></p><p>考虑具体的一条 indifference curve：$U(x_1, x_2)=k$</p><p>全微分后得：</p><script type="math/tex; mode=display">\frac{\partial U}{\partial x_1}dx_1+\frac{\partial U}{\partial x_2}dx_2=0</script><p>化简后得到 MRS 和 MU 的关系</p><script type="math/tex; mode=display">MRS=\frac{dx_2}{dx_1}=-\frac{\partial U/\partial x_1}{\partial U/\partial x_2}=-\frac{MU_1}{MU_2}</script><p><strong>Monotonic transformation &amp; MRS</strong> </p><p>假设 $V=f(U)$，对于新的效用函数 $V$，其对应的 MRS 为</p><script type="math/tex; mode=display">MRS=-\frac{\partial V/\partial x_1}{\partial V/\partial x_2}=-\frac{f^\prime(U) \times\partial U/\partial x_1}{f^\prime(U) \times\partial U/\partial x_2}=-\frac{\partial U/\partial x_1}{\partial U/\partial x_2}</script><p>因此 MRS 在经过一个正单向变换后，并不会改变</p><p><br></p><h2 id="Optimal-Choice-and-Demand-Function"><a href="#Optimal-Choice-and-Demand-Function" class="headerlink" title="Optimal Choice and Demand Function"></a>Optimal Choice and Demand Function</h2><h3 id="Rational-Constrained-Choice"><a href="#Rational-Constrained-Choice" class="headerlink" title="Rational Constrained Choice"></a>Rational Constrained Choice</h3><p>作为消费者，我们当然想选择 utility 尽可能高的 bundle，但同时我们受商品价格以及预算的约束，假设商品一的价格为 $p_1$，商品二的价格为 $p_2$，预算为 $m$，那么我们选择的 bundle 必须满足 $p_1x_1+p_2x_2\leq m$，在这个约束下，我们再去考虑 utility 最大的 bundle。</p><p>假设 $p_1=p_2=1$，$m=4$，在约束下的为 affordable bundles，然后找到一条刚好与约束线相切的 indifference curve，相交点即为 most preferred affordable bundle，记为 $(x_1^{\ast},x_2^{\ast})$，又称为 ordinary demand。</p><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/5.png" class="" width="300" height="300"><p>对于 ordinary demand，其满足两个条件：</p><ul><li><p>预算用完：$p_1x_1^\ast+p_2x_2^\ast=m$</p></li><li><p>$(x_1^\ast,x_2^\ast)$ 处的斜率等于 constraint 的斜率 $-p_1/p_2$</p></li></ul><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/6.png" class="" width="300" height="300"><h3 id="几种不同效用函数下的-ordinary-demand"><a href="#几种不同效用函数下的-ordinary-demand" class="headerlink" title="几种不同效用函数下的 ordinary demand"></a>几种不同效用函数下的 ordinary demand</h3><h4 id="Cobb-Douglas"><a href="#Cobb-Douglas" class="headerlink" title="Cobb-Douglas"></a>Cobb-Douglas</h4><p>$U(x_1,x_2)=x_1^ax_2^b$，该效用函数的 indifference curve 为双曲线，就像上面的图，因此我们需要找到切点，用 MU 计算 MRS，让其等于约束方程的斜率，即可算到 ordinary demand 为</p><script type="math/tex; mode=display">(x_1^*,x_2^*)=(\frac{am}{(a+b)p_1},\frac{bm}{(a+b)p_2})</script><h4 id="Perfect-Substitute-1"><a href="#Perfect-Substitute-1" class="headerlink" title="Perfect Substitute"></a>Perfect Substitute</h4><p>简单的通过图示法即可得到 ordinary demand，因为 perfect substitute 的 indifference curve 均为斜率 -1 的线，找到效用最大的即可。根据 $p_1$ 和 $p_2$ 的大小关系分为三种情况：</p><ul><li>$p_1 &gt; p_2$，$(x_1^\ast,x_2^\ast)=(0,\frac{m}{p_2})$</li><li>$p_1 &lt; p_2$，$(x_1^\ast,x_2^\ast)=(\frac{m}{p_1},0)$</li><li>$p_1 = p_2$，$(x_1^\ast,x_2^\ast)$ 为 budget constraint 上的点</li></ul><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/7.png" class="" width="700" height="700"><h4 id="Perfect-Complement-1"><a href="#Perfect-Complement-1" class="headerlink" title="Perfect Complement"></a>Perfect Complement</h4><p>同样用图示法去解，ordinary demand 必定在直角拐点处，因此可以得到 ordinary demand 为</p><script type="math/tex; mode=display">(x_1^*,x_2^*)=(\frac{m}{p_1+ap_2},\frac{am}{p_1+ap_2})</script><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/8.png" class="" width="500" height="500"><h3 id="Demand-Function"><a href="#Demand-Function" class="headerlink" title="Demand Function"></a>Demand Function</h3><p>又叫 ordinary demand funtion，研究 $(x_1^\ast,x_2^\ast)$ 会随着 $p_1$、$p_2$ 和 $m$ 的变化而怎么变化，由于 $p_1$、$p_2$ 和 $m$ 会影响到 budget constraint，因此研究 demand function 可以让我们更快更直接的得到 ordinary demand。</p><p>在这里我们重点关注 own-price changes，比如在 $p_2$ 和 $m$ 不变的情况下，只改变 $p_1$，如下图，右边的即为 demand function，描述 $x_1^\ast$ 和 $p_1$ 之间的关系；</p><p>左边绿色的线是所有 ordinary demand 的连线，p1 price offer curve 指的是固定 $p_2$ 和 $m$， 只改变 $p_1$ 下的 ordinary demand 的变化线。因此可以从每个点中，算出对应的 $p_1$。<br><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/9.png" class="" width="500" height="500"></p><p><br></p><h2 id="Market-Demand-amp-Elasticity"><a href="#Market-Demand-amp-Elasticity" class="headerlink" title="Market Demand &amp; Elasticity"></a>Market Demand &amp; Elasticity</h2><p>市场的 demand function 等于市场中每个消费者各自的 demand function 的和，即整个市场的需求量等于各个个体需求量之和</p><script type="math/tex; mode=display">X_j(p_1,p_2,m^1,...,m^n)=\sum_{i=1}^nx_j^{*i}(p_1,p_2,m^i)</script><p>弹性的一般定义如下，研究的是一个变量 x 会随着另一个变量 y 如何变化</p><script type="math/tex; mode=display">\epsilon_{x,y}=\frac{\%dx}{\%dy}=\frac{dx/x}{dy/y}</script><p><strong>Own-Price Elasticity：</strong>Own-Price Elasticity 指的是价格 $p$ 和需求 $x^\ast$ 之间的弹性，它是一个点概念，一般我们不说某一条 demand function 的弹性，而说 demand function 的某一点的弹性，因为市场中我们一般处在 demand function 中的某一点，我们需要关注的是在这一点的基础上，增加或减少价格所带来需求的变化。其定义如下</p><script type="math/tex; mode=display">\epsilon_{X_i^*,p_i}=\frac{p_i}{X_i^*}\times\frac{dX_i^*}{dp_i}</script><p>demand function 中每个点的弹性可能都不一样，下面的例子中，根据弹性的大小分为三类：</p><ul><li>$-\infty &lt; \epsilon &lt; -1$，own-price elastic</li><li>$\epsilon=-1$，own-price unit elastic</li><li>$-1 &lt; \epsilon &lt; 0$，own-price inelastic</li></ul><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/10.png" class="" width="500" height="500"><p><strong>revenue &amp; own-price elasticity</strong></p><p>销售者的 revenue 为：$R(p)=p \times X^*(p)$</p><p>revenue 随着价格 $p$ 的变化率为：</p><script type="math/tex; mode=display">\frac{dR}{dp}=X^*(p)+p\frac{dX^*}{xp}=X^*(p)(1+\frac{p}{X^*(p)}\frac{dX^*}{dp})=X^*(p)(1+\epsilon)</script><p>因此：</p><ul><li>$-\infty &lt; \epsilon &lt; -1$，$\frac{dR}{dq}&lt;0$，升价会导致销售者收入减少</li><li>$\epsilon=-1$，$\frac{dR}{dq}=0$，升价不会影响销售者收入</li><li>$-1 &lt; \epsilon &lt; 0$，$\frac{dR}{dq}&gt;0$，升价会导致销售者收入增加</li></ul><p>我们考虑需求函数的反函数 $p(q)$，其代表当销售者卖出 $q$ 件商品时的价格 $p$，因此 revenue 可以表示为 $R(q) = p(q)\times q$</p><p>同理 mariginal revenue 为：</p><script type="math/tex; mode=display">MR(q)=\frac{dp(q)}{dq}q+p(q)=p(q)(q+\frac{q}{p(q)}\frac{dp(q)}{dq})=p(q)(1+\frac{1}{\epsilon})</script><p>因此：</p><ul><li>$-\infty &lt; \epsilon &lt; -1$，$MR(q)&gt;0$，需求增多会提高收入</li><li>$\epsilon=-1$，$MR(q)=0$，需求增多不会影响收入</li><li>$-1 &lt; \epsilon &lt; 0$，$MR(q)&lt;0$，需求增多会减少收入</li></ul><p><strong>Note：</strong>$\frac{dR}{dp}$ 不能称为 marginal revenue，所有边界的概念都是指增加一单位的物品所带来的另外变量的变化，因此 $dp(q)/dq$ 才是 marginal revenue，而 $dR/dp$ 只能叫做 revenue 随着价格的变化率。</p><p>两种表达方式所表述的东西是一样的，假设 $\epsilon &lt; -1$，那么增加一单位的价格带来的需求的减少量必定超过一单位，因此收入减少；而增加一单位的商品，价格的减少量是小于一单位的，因此收入增多。</p><p><br></p><h2 id="Consumer-Surplus"><a href="#Consumer-Surplus" class="headerlink" title="Consumer Surplus"></a>Consumer Surplus</h2><p>对于 demand curve $p_1=v^\prime(x_1)$，当消费者计划消费 $x_1^\prime$ 个商品一的时候，其消费者剩余为</p><script type="math/tex; mode=display">CS=\int_0^{x_1^\prime}v^\prime(x_1)dx_1-p_1^\prime x_1^\prime</script><img src="/2019/10/04/%E3%80%90%E9%AB%98%E7%BA%A7%E7%AE%A1%E7%90%86%E5%AD%A6%E3%80%91%E2%80%94%E2%80%94-consumer-theory/11.png" class="" width="300" height="300"><p>消费者剩余指的是：消费者本身对商品有一个预期的价格，而市场价格比预期价格要低，因此出现了剩余，从公式中可以看出，第二项为实际支付的钱，而第一项则为需求在 $x_1^\prime$ 下的该消费者的平均预期所需要支付的钱，我们可以将积分项拆开</p><script type="math/tex; mode=display">\int_0^{x_1^\prime}v^\prime(x_1)dx_1=lim_{n\rightarrow \infty}\sum_{i=1}^nv^\prime(x_1)\frac{x_1^\prime}{n}=lim_{n\rightarrow \infty}\frac{1}{n}\sum_{i=1}^nv^\prime(x_1)x_1^\prime</script><p>$v^\prime(x_1)x_1^\prime$ 为价格为 $v^\prime(x_1)$ 下购买 $x_1^\prime$ 个商品所需要支付的钱，将不同价格下所需要支付的钱进行一个平均，即为该消费者平均预期所需要支付的钱。</p><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;课程名称：高级管理学&lt;br&gt;授课人：Ying Kong&lt;br&gt;本章梗概：介绍了消费者的相关理论，如效用函数，需求曲线，弹性等概念。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>【论文阅读】—— Image Super-Resolution Using Knowledge Distillation</title>
    <link href="http://vincentho.name/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/"/>
    <id>http://vincentho.name/2019/09/18/【论文阅读】——-Image-Super-Resolution-Using-Knowledge-Distillation/</id>
    <published>2019-09-18T11:25:56.000Z</published>
    <updated>2022-07-05T12:44:37.624Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Title: Image Super-Resolution Using Knowledge Distillation<br>Authors: Qinquan Gao, et al<br>Conference: ACCV, 2018<br>Abstract: 作者第一次将知识蒸馏用到超分任务上，并取得了提升。</p></blockquote><span id="more"></span><h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><h3 id="Teacher-network"><a href="#Teacher-network" class="headerlink" title="Teacher network"></a>Teacher network</h3><p>并没有采用比较通用的超分模型，而是自己设计了一个20层的网络，分为三个部分：feature extraction，Non-linear Mapping 以及 reconstruction，结构图如下</p><ul><li>非线性映射部分采用 residual block 堆叠的方式，每个 block 为两个卷积层组成。</li><li>卷积核大小采用 $3 \times 3$，通道数固定为 64.</li></ul><img src="/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/1.png" class="" width="500" height="500"><h3 id="Student-Network"><a href="#Student-Network" class="headerlink" title="Student Network"></a>Student Network</h3><p>和 teacher 网络基本一样，层数也一样，但是为了减少学生网络的参数以及计算开销，每个 residual block 采用的是 depthwise 卷积。</p><img src="/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/2.png" class="" width="500" height="500"><h3 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h3><p>只采用了特征蒸馏，并没有采用软标签蒸馏，对于特征蒸馏，提出四种特征提取方式</p><ul><li>$(G<em>{mean})^pF=(\frac{1}{C}\sum</em>{i=1}^CF_i)^p$</li><li>$(G^p)<em>{mean}F=\frac{1}{C}\sum</em>{i=1}^C(F_i^p)$</li><li>$G<em>{max}F=max</em>{i=1,C}F_i$</li><li>$G<em>{min}F=min</em>{i=1,C}F_i$</li></ul><p>特征位置的选取上，由于教师和学生网络在 NonLinear Mapping 部分均为 10 层，因此作者提取 第 4、7、10 层的特征。模型整体的 Loss 如下，$Y$ 为 HR image。</p><script type="math/tex; mode=display">loss = loss_0(\tilde{Y},Y) + \lambda_1loss_1(s_1,t_1)+\lambda_2loss_2(s_2,t_2)+\lambda_3loss_3(s_3,t_3)</script><p><br></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="特征选取位置的影响"><a href="#特征选取位置的影响" class="headerlink" title="特征选取位置的影响"></a>特征选取位置的影响</h3><p>实验结果如下，个人觉得这实验结果并没有说服力，因为随机性太强，作者认为最好的结果也没有特别明显，并且在过程中，改变了 $\lambda_0$，才取得最好的结果，而 $\lambda_0$ 和特征位置的选取并没有关系，理应固定；而当固定 $\lambda_0$ 为 1 的时候，可以看出结果并没有特别大的区别，(1, 0, 0) 和 (0, 1, 0) 均为一样的结果。</p><img src="/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/3.png" class="" width="500" height="500"><h3 id="特征提取方式的影响"><a href="#特征提取方式的影响" class="headerlink" title="特征提取方式的影响"></a>特征提取方式的影响</h3><p>作者比较四种特征提取方式，以及不同的 $p$ 值，实验结果如下。$(G_{mean})^2$ 的结果最好，且蒸馏有效。</p><img src="/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/4.png" class="" width="500" height="500">>### 蒸馏整体的有效性<img src="/2019/09/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Image-Super-Resolution-Using-Knowledge-Distillation/5.png" class="" width="500" height="500"><p><br></p><p><em>In Conclusion</em></p><p>作者确实验证了蒸馏在超分上的有效性，但是网络选择方面没有选择通用的超分网络，而是自己搭建了一个网络，这样，自己搭建的网络是否适用于超分任务也很难说明，另外蒸馏方面只用到特征的蒸馏，而没有采用标签的蒸馏。</p><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Title: Image Super-Resolution Using Knowledge Distillation&lt;br&gt;Authors: Qinquan Gao, et al&lt;br&gt;Conference: ACCV, 2018&lt;br&gt;Abstract: 作者第一次将知识蒸馏用到超分任务上，并取得了提升。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
</feed>

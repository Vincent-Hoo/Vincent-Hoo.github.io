---
title: 【概率论和数理统计】——参数估计
date: 2018-11-09 16:51:00
mathjax: True
tags:
- 概率论
---

> 课程名称：概率论与数理统计
> 开设学校：中科大
> 课程平台：icourse
> 第四章：数理统计入门，从概率论过渡到数理统计，讲述数理统计的几个基本概念，以及参数估计，包括点估计和区间估计。

<!-- more -->

*preface*

统计分为描述性统计和数理统计，描述性统计主要对数据进行简单化的分析，如加减乘除，算均值中位数等；而数理统计是以数学和概率论为工具，研究如何有效收集随机性数据、如何分析数据、以及在给定的统计模型下进行统计推断。下面具体讲解数理统计的这三个研究方向。

- 数据收集
  - 主要通过抽样和设计试验，抽样一般针对社会科学，进行抽样调查
  - 抽样得到的随机数据要具有代表性，要反映整个样本空间
  - 试验要有对照
- 数据分析
  - 涉及统计分析的方法
- 统计推断
  - 估计（estimate）：点估计，区间估计
  - 检验（test）：参数检验，非参数检验

数理统计不同于一般的资料统计，它更侧重于应用随机现象本身的规律性进行资料的收集、整理和分析。由于大量的随即现象必然呈现出它的规律性，因而从理论上讲，只要对随机现象进行足够多次观察，被研究的随机现象的规律性一定能够清楚地呈现出来。但在客观上只允许我们对随机现象进行次数不多的观察实验，也就是说，我们获得的只是局部观察资料。

数理统计的基本思想是：从所要研究对象的全体中，抽取一小部分进行观测和试验，以取得信息，从而对整体做出推断。每个推断必须伴随一定的概率，以表明推断的可靠性（数理推断）。

数理统计的基本任务是：以大数定律、中心极限定理为理论基础，根据实际掌握的部分信息对有关主体试验的分布、数字特征做出估计并加以检验的数理推断。

<br>

# 数理统计的几个基本概念

## 总体

- 总体（population）：研究对象的全体，总体中的每个成员称为个体，总体中所包含的个体的个数称为总体的容量。根据总体容量，可以将总体分为有限总体和无限总体。
  - 在数理统计研究中，人们往往研究有关对象的某一项数量指标，为此，对这一指标进行随机试验，观察试验结果的全部观察值，从而考察该数量指标的分布情况，这时我们研究的对象就是总体的某个数量指标。
  - 由于每个个体的出现是随机的，所以相应的数量指标的出现也是随机的，因此可以把这种数量指标看作一个随机变量，随机变量的分布就是该数量指标在总体中的分布
  - 总体可以用一个随机变量及其分布来描述，因此在理论上可以把总体和概率分布等同起来。

## 样本

- 样本（sample）：总体的分布一般是未知的，或只知道包含未知参数的分布。因此为了推断总体的分布及其各种特征，按照一定规则从总体中抽取若干个体进行观察试验，以获得有关总体的信息，这一抽取的过程称为**抽样**，所抽取的部分个体称为**样本**，样本所包含的个体数量称为**样本容量**。
  - 总体可以看成是一个随机变量 $X$，对总体 $X$ 在相同的条件下，进行  $n$ 次重复、独立的观察，其结果记为 $X_1, X_2, ..., X_n$。这样得到的随机变量 $X_1, X_2, ..., X_n$ 是来自总体 $X$ 的一个**简单随机样本**，与总体随机变量具有相同的分布。可以看出，样本也可以看成是一个随机变量。
  - 抽样的样本应具有：
    - 代表性：$X_1, X_2, ..., X_n$ 中每一个与所观察的总体有相同的分布。
    - 独立性：$X_1, X_2, ..., X_n$ 是相互独立的随机变量。
  - 简单随机样本：是一种理想化的样本。
    - 对于有限总体，若采用有放回抽取，则可得到简单样本；若采用无放回抽取，则无法保证每次抽取的独立性。但若有限总体的容量远大于样本容量，则无放回抽取近似有放回抽取。
    - 对于无限总体，抽取部分个体后放回与否对总体成分影响不大，因此可采用无放回抽取获得简单样本。
  - 若总体的分布函数为 $F(x)$，概率密度函数为 $f(x)$
    - 则简单随机样本的联合分布函数为：$F(x_1, x_2, ...,x_n) = F(x_1)F(x_2)...F(x_n)$ 
    - 则简单随机样本的联合概率密度函数为：$f(x_1, x_2, ...,x_n) = f(x_1)f(x_2)...f(x_n)$  
- 样本值：一旦给定一组样本 $X_1, X_2, ..., X_n$，得到 $n$ 个具体的数值 $(x_1, x_2, ..., x_n)$，则称为样本的一次观察值，简称样本值。 
- 三者的关系：事实上，我们抽样后得到的资料都是具体的、确定的值，我们只能观察到随机变量取的值，而见不到随机变量。
  - 统计就是从手中已有的资料（样本值），去推断总体的分布情况，而样本是联系总体和样本值的桥梁。总体分布决定了样本取值的概率规律，也就是样本取到样本值的规律，因而可以由样本值去推断总体。
- 样本二重性：另外一套理论是，不区分样本和样本值，而是认为样本具有二重性。
  - 当决定了抽样方案，但是没有实施时，样本是一组随机变量
  - 当抽样方案实施后，样本是一组数

## 统计量

- 统计量是为了刻画总体某个特征，而对样本进行某种加工。换句话说，统计量是样本的函数，且不带任何参数。
- 由于样本具有二重性，统计量也具有二重性，它可以是一个随机变量，也可以是一个数。所以在研究统计量的时候，需要研究它的两种形态，一般理论上我们研究的统计量是把它看成随机变量。
- 常见的统计量
  - 样本均值：$\bar{X} = \frac{1}{n}\sum X_i$，由大数定律得出，$\bar{X} \rightarrow E(X)$ 
  - 样本方差：$s^2 = \frac{1}{n-1}\sum(X_i - \bar{X})^2$，同样由大数定律得出，$s^2 \rightarrow Var(X)$ 
  - k阶样本中心矩：$v_k = \frac{1}{n}\sum(X_i - \bar{X})^k$
  - k阶样本原点矩：$\mu_k = \frac{1}{n}\sum X_i^k$
- 顺序统计量：设样本为 $X_1, X_2, ..., X_n$，构造统计量 $X_{(i)}$ 等于样本 $X_1, X_2, ..., X_n$ 中第 $i$ 小的数，显然 $X_{(i)}$ 是一个统计量，因为它是样本的函数。因此可以得到 $X_{(1)} \le X_{(2)} \le ...\le X_{(n)}$ 
- 构造了顺序统计量之后，就可以得到其它的统计量，如极差 $R = X_{(n)} - X_{(1)}$，中位数



**Note:  ** $\mu$ 和 $\sigma^2$ 是未知常数，不会变化；$\bar{X}$ 和 $S^2$ 或是随机变量或是一个数，但他们都是一个统计量。


<br>
# 参数估计(parametric estimation)

- 定义：参数估计问题是利用从总体抽样得到的部分信息来估计总体的某些参数或者总体的某些数字特征。
- 参数估计的两个研究方向：
  - 在已知总体分布类型的前提下，由样本信息估计出总体未知参数的近似值，从而近似估计总体分布。
  - 有时关心的不是总体服从具体什么分布，而是关注总体的某些数字特征，如均值、方差等。
- 估计量：设总体 $X$ 的分布函数为 $F(x,\theta)$，其中 $\theta$ 为未知参数，$X_1, X_2, ..., X_n$ 为来自总体的样本，由样本构造一个统计量 $\hat{\theta} = g(X_1, X_2, ..., X_n)$，若以这个样本函数去估计参数 $\theta$，则称 $\hat{\theta}$ 为参数 $\theta$ 的估计量；若样本试验已经实施，那么 $\hat{\theta}$ 为参数 $\theta$ 的估计值。
- 参数估计主要分为：点估计和区间估计



## 点估计

点估计分为两种：矩估计和极大似然估计

### 矩估计

- 原理：依据大数定理，用样本矩代替总体矩
- 假设总体分布有 $p$ 个参数，计算 $p$ 个样本矩 $J_1$ 到 $J_p$，然后根据矩估计原理，总体矩等于样本矩，总体矩是关于参数的函数，所以反解方程算出参数
- 总体均值等于样本均值，因为总体一阶原点矩可以用样本一阶原点矩代替；同理，总体方差等于样本方差
- 矩估计不唯一，由于估计量也是一个统计量，因此也是随机变量；而总体的真实参数是一个未知常数，非随机变量。

### 极大似然估计

- 思想：极大似然估计法，是建立在最大似然原理的基础上的求点估计量的方法，最大似然原理的直观想法是：在试验中概率最大的事件最有可能发生。在已得试验结果的条件下，应该寻找使得该结果出现可能性最大的那个参数值作为真正参数的估计。

- 似然函数：设 $X_1, X_2, ..., X_n$ 是取自总体 $X$ 的一个样本，总体的密度函数为 $f(x, \theta)$，样本的联合密度为 $f(x_1, x_2, ...,x_n, \theta) = \prod f(x_i,\theta)$，记 $L(x, \theta) = \prod f(x_i, \theta)$
  - 若给定 $\theta$，则 $L(x,\theta)$ 是密度函数
  - 若给定 $x$，则 $L(x,\theta)$ 是似然函数 

- 极大似然估计指：给定样本值，估计参数 $\theta$，使得似然函数取到最大值，似然函数实际上可以看成是一个概率值，因为 $f(x)dx$ 就可以看成是概率，$L(x,\theta)dx$ 相当于抽样得到这一组样本值的概率，现在要求一个参数 $\theta$ 使得这个概率最大；把 $dx$ 去掉，转成求似然函数 $L(x,\theta)$ 最大值。

- 对于离散型随机变量，似然函数为 
    $$L(\theta) = P(X_1 = x_1, X_2 = x_2, ..., X_n = x_n; \theta) = \prod P(X = x_i; \theta)$$

  对于连续型随机变量，似然函数为 
  $$L(\theta) = \prod f(x_i; \theta)$$  

- 极大似然估计的步骤

  - 求出似然函数，$L(x, \theta) = \prod f(x_i, \theta)$ 
  - 若似然函数可导，求出 $ln L(x,\theta)$ 及似然方程 $\frac{dlnL(x,\theta)}{d\theta_i} = 0, (i = 1,2,...,m)$ 
  - 解似然方程得到极大似然估计值
  - 最后得到极大似然估计量

- 例题

  1. 设 $X$ 服从参数为 $\lambda$ 的泊松分布，$\lambda$ 是未知常数，$X_1, X_2, ...., X_n$ 是来自 $X$ 的一个样本，求 $\lambda$ 的极大似然估计量
    - $X$ 的分布律为：
    $$P(X = x) = \frac{\lambda^x}{x!}e^{-\lambda}$$ 
    - 似然函数：
    $$L(\lambda) = \prod(\frac{\lambda^{x_i}}{x_i!}e^{-\lambda}) = e^{-n\lambda}\frac{\lambda^{\sum x_i}}{\prod(x_i!)}$$ 
    - 对数似然函数： 
    $$lnL(\lambda) = -n\lambda + (\sum x_i)ln\lambda - \sum ln(x_i!)$$ 
    - 解似然方程：
    $$\frac{dlnL(\lambda)}{d\lambda} = -n + \frac{\sum x_i}{\lambda} = 0$$
    - 似然估计值：
    $$\hat{\lambda} = \frac{1}{n}\sum x_i = \bar{x}$$
    - 似然估计量：
    $$\hat{\lambda} = \frac{1}{n}\sum X_i = \bar{X}$$ 
  <br>
  2. 设总体 $X$ 具有分布列如下，已知取得样本值1、2、1、2、2、3、3，求 $\theta$ 的极大似然估计值
    - $P(X=1) = \theta^2, P(X=2)=2\theta(1-\theta), P(X=3)=(1-\theta)^2$
    - $L(\theta) = P(X_1 = 1, X_2 = 2, ..., X_7 = 3) = 8\theta^7(1-\theta)^7$ 
    - $\frac{dlnL(\theta)}{d\theta} = \frac{7}{\theta} - \frac{7}{1-\theta} = 0$
    - $\hat{\theta} = 0.5$  
  <br>
  3. 设总体 $X \sim N(\mu, \sigma^2)$，$X_1, ..., X_n$ 为来自总体的样本，求 $\mu$ 和 $\sigma^2$ 的极大似然估计量

    - $X$ 的分布函数为：
    $$f(x;\mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma} exp(-\frac{(x-\mu)^2}{2\sigma^2})$$ 
    - 似然函数：
    $$L(\mu, \sigma^2) = \prod \frac{1}{\sqrt{2\pi}\sigma} exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) = (\frac{1}{2\pi\sigma^2})^{\frac{n}{2}}exp(-\frac{\sum (x_i - \mu)^2}{2\sigma^2})$$ 
    - 对数似然函数：
    $$lnL(\mu, \sigma^2) = -\frac{n}{2}ln(2\pi) - \frac{n}{2}ln\sigma^2 -\frac{\sum (x_i - \mu)^2}{2\sigma^2} $$ 
    - 令偏导等于0
    $$\frac{\partial lnL(\mu, \sigma^2)}{\partial \mu} = \frac{1}{\sigma^2}(\sum x_i - n\mu) = 0$$
    $$\frac{\partial lnL(\mu, \sigma^2)}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2} \sum (x_i - \mu)^2 = 0$$  
    - 解得：
    $$\hat{\mu} = \frac{1}{n} \sum x_i = \bar{x}$，$\hat{\sigma}^2 = \frac{1}{n}\sum (x_i - \bar{x})^2$$ 
  <br>
  4. 从鱼塘里随机捕获500条鱼，做好标记后重新放入鱼池里，充分混合后再捕获1000条，发现其中有72条带标记，问鱼塘里可能有多少条鱼。

    - 假设鱼塘有 $N$ 条鱼，$P(X = 72) = \frac{C_{500}^{72} C_{N-500}^{1000-72}}{C_N^{1000}}$ 
    - 可以将这个问题看成极大似然估计的问题，估计参数 $N$，使得上面的概率最大。

### 点估计优良性准则

使用矩估计方法和极大似然估计得到的参数估计量可能相同，也可能不同，那么如何评判估计量的好坏呢？主要通过无偏性、有效性和一致性判断。

#### 无偏性

- 定义：设 $\hat{\theta}$ 是未知参数 $\theta$ 的估计量，若 $E\hat{\theta} = \theta$，则称 $\hat{\theta}$ 为 $\theta$ 的无偏估计量，或者称估计量 $\hat{\theta}$ 具有无偏性，$\theta - E\hat{\theta}$ 称为系统误差。
- 估计量在试验实施前是一个随机变量，无偏性要求多次试验实施的参数平均值就等于真实的参数值。
- 定理：
  - 样本均值 $\bar{X}$ 是总体均值 $\mu$ 的无偏估计量，反过来，总体均值 $\mu$ 的无偏估计不唯一，估计量 $\hat{\mu}_1 = \sum w_i X_i, \sum w_i=1$，这也是总体均值的无偏估计
  - 样本方差 $S_n^2$ （二阶中心矩）不是总体方差 $\sigma^2$ 的无偏估计量，证明如下：
    - {% asset_img esn2.png %}
  - 因为二阶中心矩对总体方差的估计偏小，因此修正样本方差为：$S^2 = \frac{1}{n-1}\sum (X_i - \bar{X})^2$  
- 不是无偏的估计量可以通过修正得到无偏估计量。

#### 有效性（最小方差无偏性）

- 定义：设 $\hat{\theta}_1$ 和 $\hat{\theta}_2$ 都是未知参数 $\theta$ 的无偏估计量，若 $Var(\hat{\theta}_1) \le Var(\hat{\theta}_2)$，则称 $\hat{\theta}_1$ 比 $\hat{\theta}_2$ 更有效
- 注意：有效性是以无偏性为前提的

#### 相合性（一致性）

- 定义：设 $\hat{\theta}$ 都是未知参数 $\theta$ 的无偏估计量，若 $\hat{\theta}$ 依概率收敛于 $\theta$，即对于任意 $\epsilon > 0$，有 $lim_{n \rightarrow \infty}P(|\hat{\theta} - \theta| \ge \epsilon) = 0$，则称 $\hat{\theta}$ 为 $\theta$ 的相合估计量
- 样本方差虽然不是无偏估计量，但是它依旧相合 

#### 渐近正态性

- 如果估计量经过标准化的极限分布为标准正态分布，则称该统计量具有渐近正态性
- 渐近正态性能保证样本量较大时，估计量的渐近分布已知， 这样当估计量的分布难以得出或者过于复杂时候，可以使用其近似分布来进行计算。




<br>
## 区间估计

点估计是用样本算得的一个值去估计未知参数，但是点估计仅仅是未知参数的一个近似值，它没有反映出这个近似值的精确度以及误差范围。而区间估计正好弥补了点估计的这个缺陷，我们希望确定一个区间，使我们能以比较高的可靠程度相信它包含真参数值，这里所说的可靠程度是用概率来度量的，称为置信水平或置信度。

#### 几个基本概念

- 置信区间：设 $\theta$ 是一个待估参数，给定 $\alpha > 0$，若由样本 $X_1, X_2, ... , X_n$ 确定的两个统计量 $\underline{\theta}$ 和 $\overline{\theta}$ ($\underline{\theta} <\overline{\theta}$) 满足 $P(\underline{\theta} < \theta < \overline{\theta}) \ge 1- \alpha$，则称区间 $(\underline{\theta} ,\overline{\theta})$ 是 $\theta$ 的置信度为 $1-\alpha$ 的置信区间，$\underline{\theta}$ 和 $\overline{\theta}$ 分别称为置信下限和置信上限。
- 可信度：$1-\alpha$ 
- 精度：区间的长度，$\overline{\theta} - \underline{\theta}$ 

#### 区间估计的基本要求

- 寻找两个统计量，$\underline{\theta}$ 和 $\overline{\theta}$ 使得区间 $(\underline{\theta} ,\overline{\theta})$ 以指定概率包含真值 $\theta$。
- 要求 $\theta$ 以很大的可能被包含在区间 $(\underline{\theta} ,\overline{\theta})$ 内，就是说，概率 $P(\underline{\theta} < \theta < \overline{\theta})$ 要尽可能的大，即要求估计尽量可靠。
- 估计的精度要尽可能地高，即要求区间长度尽可能地短。

#### 一些注意点

- 可靠度和精度是一对矛盾，一般是保证可靠度的条件下尽可能地提高精度。
- 被估计的参数 $\theta$ 虽然未知，但是它是一个常数，没有随机性，而区间 $(\underline{\theta} ,\overline{\theta})$ 是随机的，因此置信区间的本质是，随机区间 $(\underline{\theta} ,\overline{\theta})$ 以 $1-\alpha$ 的概率包含参数 $\theta$ 的真值，而不能说参数 $\theta$ 以 $1-\alpha$ 的概率落入随即区间 $(\underline{\theta} ,\overline{\theta})$。
- 若反复抽样多次，每个样本值确定一个区间 $(\underline{\theta} ,\overline{\theta})$，每个这样的区间可能包含 $\theta$ 的真值，也可能不包含，按照伯努利大数定理，在这样多的区间中，包含 $\theta$ 真值的约占 $1-\alpha$，不包含的约占 $\alpha$ 

#### 置信区间求解

1. 寻找待估参数 $\theta$ 的一个良好的点估计 $\hat{\theta}$
2. 寻找一个待估参数 $\theta$ 和点估计量 $\hat{\theta}$ 的函数 $U(\hat{\theta}, \theta)$，且其分布为已知。
3. 对于给定的置信水平 $1-\alpha$，根据 $U(\hat{\theta}, \theta)$ 的分布，确定常数 $a$ 和 $b$，使得 $P(a \le U(\hat{\theta}, \theta) \le b) = 1-\alpha$
4. 对 $a \le U(\hat{\theta}, \theta) \le b$ 作等价变形，得到 $\underline{\theta}(\hat{\theta}) < \theta < \overline{\theta}(\hat{\theta})$，置信区间为 $(\underline{\theta} ,\overline{\theta})$

**Note**

- 区间估计是基于点估计的
- 确定区间估计很关键的是要寻找一个待估参数 $\theta$ 和点估计量 $\hat{\theta}$ 的函数 $U(\hat{\theta}, \theta)$，且其分布为已知，不依赖任何未知参数。而这与总体分布有关，所以总体分布的形式是否已知，是怎样的类型，至关重要。
- 上面的第三步求解常数 $a$ 和 $b$，会有很多个解，我们需要从里面挑出精度最高的，即 $b-a$ 最小的。而一般根据待估参数不同，精度最高的常数 $a$ 和 $b$ 满足的条件不同，如果 $U(\hat{\theta}, \theta)$ 为单峰且对称的情况，那么当 $a = -b$ 的时候，置信区间长度最短。

#### 单正态总体的区间估计

设 $X_1, X_2, ..., X_n$ 取自总体 $X\sim N(\mu, \sigma^2)$，样本均值 $\bar{X} = \frac{1}{n}\sum X_i $，样本修正方差 $S^2 = \frac{1}{n-1} \sum (X_i - \bar{X})^2$，$\mu$ 的区间估计结构为 $[\bar{X} - d, \bar{X} + d]$，2d为精度；$\sigma^2$ 的区间估计结构为 $[S^2 / c, S^2 / d]$  

- 总体方差 $\sigma^2$ 已知，估计总体均值 $\mu$ 的置信区间
  1. 寻找总体均值较优的点估计量，$\hat{\mu} = \bar{X}$
  2. 构造不依赖待估参数且具有已知分布的统计量 $\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$，标准化的随机变量 $\bar{X}$ 
  3. 令 $a = -b$，计算
  $$P(|\frac{\bar{X} - \mu}{\sigma / \sqrt{n}}| < a) = 1-\alpha$$
  $$P(\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} > a) = \alpha / 2$$
  解得： $a = u_{\alpha /2}$ 
  4.  因此置信区间 
  $$(\bar{X} - u_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{X} + u_{\alpha/2} \frac{\sigma}{\sqrt{n}})$$ 
<br>
- 总体方差 $\sigma^2$ 未知，用样本方差 $S^2$ 代替，估计总体均值 $\mu$ 的置信区间
  - 总体方差未知，用样本方差代替，构造统计量 $\frac{\bar{X} - \mu}{S/ \sqrt{n}} \sim t_{n-1}$，t分布
  - 置信区间
   $$(\bar{X} - (n-1)t_{\alpha/2} \frac{S}{\sqrt{n}}, \bar{X} + (n-1)t_{\alpha/2} \frac{S}{\sqrt{n}})$$ 
<br>
- 估计总体方差 $\sigma^2$
  - 构造统计量 $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$  
  - 计算 
  $$P(\frac{(n-1)S^2}{\sigma^2} \ge K_2) = \alpha / 2$$ 
  以及 
  $$P(\frac{(n-1)S^2}{\sigma^2} \le K_2) = \alpha / 2$$
  - 解得：
  $$K_2 = \chi^2_{\alpha/2}, K_1 = \chi^2_{1-\alpha/2}$$ 
  - 置信区间：
   $$(\frac{(n-1)S^2}{\chi^2_{\alpha/2}}, \frac{(n-1)S^2}{\chi^2_{1-\alpha/2}})$$  

**Note：**

- 上面的例子，总体 $X$ 都是服从正态分布，当给定 $\alpha$ 时，查正态分布表或者t分布表，确定临界值，从而确定置信区间
- 但是如果总体 $X$ 分布是未知的，样本均值 $\bar{X}$ 就不是正态，单这时只要 $n$ 充分的大，根据中心极限定理，$\frac{\bar{X} - \mu}{\sigma / \sqrt{n} }$ 会近似于标准正态分布，$\frac{\bar{X} - \mu}{S/ \sqrt{n} }$ 是t分布，而t分布也会趋于标准正态分布





<br>

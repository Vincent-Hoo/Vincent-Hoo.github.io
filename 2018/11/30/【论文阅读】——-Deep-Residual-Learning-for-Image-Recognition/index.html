<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-small.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-small.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="Nameless rookie" type="application/atom+xml" />






<meta name="description" content="Title：Deep Residual Learning for Image RecognitionAuthors：Kaiming He et alSession：CVPR, 2016Abstract：这就是传说中的ResNet，作者提出了残差学习(residual learning)，解决了深层网络的退化问题(degradation)，并且破天荒地将网络层数加深到 152 层，并且揽获 ILS">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读】—— Deep Residual Learning for Image Recognition">
<meta property="og:url" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/index.html">
<meta property="og:site_name" content="Nameless rookie">
<meta property="og:description" content="Title：Deep Residual Learning for Image RecognitionAuthors：Kaiming He et alSession：CVPR, 2016Abstract：这就是传说中的ResNet，作者提出了残差学习(residual learning)，解决了深层网络的退化问题(degradation)，并且破天荒地将网络层数加深到 152 层，并且揽获 ILS">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/degradation.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/7.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/residual_block.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/1.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/2.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/bottleneck.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/3.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/4.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/5.png">
<meta property="og:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/6.png">
<meta property="article:published_time" content="2018-11-30T06:51:01.000Z">
<meta property="article:modified_time" content="2022-07-05T12:44:37.569Z">
<meta property="article:author" content="Vincent Ho">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/degradation.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://vincentho.name/2018/11/30/【论文阅读】——-Deep-Residual-Learning-for-Image-Recognition/"/>





  <title>【论文阅读】—— Deep Residual Learning for Image Recognition | Nameless rookie</title>
  








<meta name="generator" content="Hexo 6.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Nameless rookie</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">keep foolish</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://vincentho.name/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/ProfilePhoto.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Nameless rookie">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">【论文阅读】—— Deep Residual Learning for Image Recognition</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-30T14:51:01+08:00">
                2018-11-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>Title：Deep Residual Learning for Image Recognition<br>Authors：Kaiming He et al<br>Session：CVPR, 2016<br>Abstract：这就是传说中的ResNet，作者提出了残差学习(residual learning)，解决了深层网络的退化问题(degradation)，并且破天荒地将网络层数加深到 152 层，并且揽获 ILSVRC 2015 的所有比赛冠军（分类，检测，定位）。</p>
</blockquote>
<span id="more"></span>
<p><br></p>
<p><em>preface</em></p>
<p>深度神经网络已经在前几年 ILSVRC 中展示了它的威力，像 VGG 和 GoogLeNet 都将网络层数提升到了 20 层左右，但是作者发现随着神经网络的加深，网络会出现退化问题(degradation problem)，即训练误差不降反升，从下图可以看出，56 层的网络训练误差比 20 层的网络还高，这不是由于过拟合所致，2015 年已经有很多防过拟合的方法出现，如 batch normalization，dropout，各种初始化方式；且如果是过拟合的问题，那么训练误差理应更低，但是从下图可以看出，深层的网络训练误差和测试误差都比浅层网络要高，所以退化问题不是过拟合所致。</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/degradation.png" class="">
<p><br></p>
<h1 id="Residual-Learning"><a href="#Residual-Learning" class="headerlink" title="Residual Learning"></a>Residual Learning</h1><p>网络的退化问题表明，不是所有的网络都是容易优化的，起码深层网络比浅层网络难以优化和收敛。</p>
<blockquote>
<p>Identity mapping(function)：恒等映射（函数）是指输出等于输入的映射，即 $y = x$。</p>
</blockquote>
<p>假如我们将上面例子的浅层网络（20层网络）通过在其后面叠加恒等函数（不是真的叠加，而是让后面的层去学习一个恒等函数，从而得到恒等函数的效果），我们就可以得到一个深层网络，理论上这个深层网络和浅层网络是等同效果的（如果能学习到恒等函数的话），深层网络可以看成是浅层网络的一个 counterpart，因此深层网络的错误率不应该比浅层网络要高。但是上面的实验也表明了，深层网络有退化问题，这个浅层网络的 counterpart 的错误率要比浅层网络本身要高。</p>
<p>因此作者提出猜想：<strong>或许非线性层比较难学习出一个恒等函数</strong>，因此连浅层网络的错误率都无法逼近，更不用说降低错误率了。</p>
<p>那么如何才能更加有效地学习恒等函数呢？作者提出了残差学习，只要能解决这个问题，就相当于能够解决网络的退化问题。</p>
<p>我们假设网络某几层非线性层（不一定要整个网络）需要学习的 mapping 为 $H(x)$，即潜在真实的 mapping 就为 $H(x)$。与其让这几层非线性层学习整个 $H(x)$，我们让它学习 $F(x)$，$F(x) = H(x) - x$，$F(x)$ 称为原映射 $H(x)$ 的残差；作者假设残差的学习要比原映射容易，一个极端的例子是：假设我们要学习的真实映射 $H(x)$ 就是一个恒等函数，即 $H(x) = x$，那么我们只需要学习让这几层非线性层输出 $F(x) = 0$ 即可；但是如果不是 residual learning，即上面提到的情况，让这几层非线性层直接学习 $g(x) = x$，这要比让这些非线性层学习 $g(x) = 0$ 要难，$g(x)$ 为这几层线性层学习到的映射。</p>
<p><br></p>
<h1 id="Why-Resnets-work"><a href="#Why-Resnets-work" class="headerlink" title="Why Resnets work?"></a>Why Resnets work?</h1><p>考虑一下下面的这个网络，输出为：</p>
<script type="math/tex; mode=display">a^{[l+2]} = Relu(z^{[l+2]} + a^{[l]}) = Relu(w^{[l+2]}a^{[l+1]} + b^{[l+2]} +a^{[l]})</script><p>假设由于正则或 weight decay 使得 $w^{[l+2]}a^{[l+1]} + b^{[l+2]} = 0$，那么 $a^{[l+2]} = a^{[l]}$，即一个恒等函数。</p>
<p>这表明 residual block 很容易会学到恒等函数，因此在下面的 big NN 后面添加这些 residual block，并不会 hurt 原来 NN 的能力，也就是说添加 residual block 至少不会使得性能下降，反而还会学到一些有用的信息使得性能上升。</p>
<p>而 plain network 当加深的时候，网络甚至连恒等函数都学不到，这也就是为什么网络加深，反而性能下降的原因。而 residual block 解决退化问题的最主要原因是，这些 residual block 能够保证不会 hurt performance，有时候还会 help performance。</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/7.png" class="">
<p>假设我们现在将网络的所有层都改为 residual block，即把上面例子的 Big NN 改成 residual block 的形式，首先这样改动，并不会改变这个 Big NN 的性能，因为假设几层非线性层能够逼近任意函数 $H(x)$，那么它肯定能够逼近 $H(x) - x$。因此基于 residual block 的 big NN 会学到和没有 residual block 的 big NN 一样的函数。在这基础上，根据上面的证明，在它后面加很多个 residual block，也不会 hurt performance，所以就可以解决退化问题了。</p>
<p><br></p>
<h1 id="Identity-Mapping-by-Shortcuts"><a href="#Identity-Mapping-by-Shortcuts" class="headerlink" title="Identity Mapping by Shortcuts"></a>Identity Mapping by Shortcuts</h1><p>作者基于上面的理论和猜想，提出了 residual block，如下图</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/residual_block.png" class="">
<p>作者称这种首尾相连的线为 shortcut 或者 skip-connection，它们是用来实现 Identity Mapping 的，一个 block 的方程如下，非线性层只需学习残差即可</p>
<script type="math/tex; mode=display">(1)：y = F(x, \{ W_i\}) +x</script><p>这种 shortcut 连接并没有引入任何的参数和很多的计算量（除了 element-wise 加法），但是却能解决退化问题。</p>
<p>当 $F(x, {  W_i})$ 的输出与 $x$ 的维度不匹配的时候，我们还需要将输入 $x$ 进行 projection。</p>
<script type="math/tex; mode=display">(2)：y = F(x, \{  W_i\}) +W_s x</script><p>公式 (1) 称为 Identity Mapping，而公式 (2) 称为 projection shortcut，一般上除非维度不匹配，否则都用 Identity Mapping 即可，没有太多必要引入额外的参数。</p>
<p><br></p>
<h1 id="ResNet结构"><a href="#ResNet结构" class="headerlink" title="ResNet结构"></a>ResNet结构</h1><p>下图是 VGG-19、plain network 以及 residual network 的网络图。plain network 和 residual network 都去掉了全连接层，而改用了 global pooling，residual network 中的实线连接为 Identity mapping，而虚线连接为 projection shortcut。</p>
<p>在具体实现上，projection shortcut 有两种选择</p>
<ol>
<li>直接通过 zero padding，使得输入和输出的维度相同。</li>
<li>通过上面的公式 (2) 用 $1\times 1$ 的卷积核将输入映射到输出。</li>
</ol>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/1.png" class="">
<p>作者共实现了层数分别为18、34、50、101 和 152 的 resnet，网络结构如下图，通过不断地堆叠 residual block，注意一点，卷积操作都是采取 SAME 卷积，feature map 维度减小是在每一个 conv i_x 的开头通过设置 stride = 2 将其缩小一半，具体看上图的虚线连接的 block。</p>
<p>从下表可以看出随着层数的增多，resnet 的计算量并没有提升很多，而参数也是要比 VGG 等网络要少。</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/2.png" class="">
<p>作者在构建 50 层以上的 resnet 的时候，采用了 GoogLeNet 一样的策略，用一个 $1 \times 1$ 的卷积核作为 bottleneck，来减少参数和计算量。</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/bottleneck.png" class="">
<p><br></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><strong>实验设置：</strong></p>
<ul>
<li>训练阶段：预处理时像 VGG 一样随机采样 [256, 480] 的最短边，然后随机 crop 出 $224 \times 224$ 的图像以及水平翻转，然后做mean substracted。 </li>
<li>测试阶段：预测时候使用 AlexNet 的10-crop测试法，最好的结果是跟从 VGG 中的全卷积后的 multi-scale 评估，scale为 {224, 256, 384, 480, 640}。</li>
</ul>
<h2 id="Plain-Network-vs-Residual-Network"><a href="#Plain-Network-vs-Residual-Network" class="headerlink" title="Plain Network vs Residual Network"></a>Plain Network vs Residual Network</h2><ul>
<li>深层的 plain 网络的误差要比浅层的 plain 网络误差要高，表明出现退化问题。</li>
<li>作者分析了深层 plain 网络的前向激活和反向梯度值，都没有发生 vanish 的现象，证明不是梯度消失所导致。</li>
<li>residual network 为了和 plain network作对比，用的是 Identity mapping 和 zero padding for dismatch dimension，这是为了不引入额外的参数。</li>
<li>对比 plain network，resnet-34 的错误率要比 resnet-18 要低，意味着退化问题可以用 residual learning 解决。</li>
<li>当网络不是很深的时候，如 18 层，resnet 和 plain network 差不多，但是 resnet 收敛要更快。</li>
</ul>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/3.png" class="">
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/4.png" class="">
<h2 id="Identity-Mapping-vs-Projection-Shortcuts"><a href="#Identity-Mapping-vs-Projection-Shortcuts" class="headerlink" title="Identity Mapping vs Projection Shortcuts"></a>Identity Mapping vs Projection Shortcuts</h2><p>skip-connection 的三种设置</p>
<ul>
<li>A. zero padding for increased dimension；parameter-free Identity mapping for other shortcuts.</li>
<li>B. projection shortcuts for increased dimension；parameter-free Identity mapping for other shortcuts.</li>
<li>C. all shortcuts are projection. （输入输出维度相同的也用一个 $1 \times 1$ 的卷积核去处理）</li>
</ul>
<p>结果表明 B 要比 A 稍微好一点，C 比 B 稍微好一点，但整体差不多，说明解决退化问题，projection shortcut 并不是必须。</p>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/5.png" class="">
<h2 id="Comparision-with-other-models"><a href="#Comparision-with-other-models" class="headerlink" title="Comparision with other models"></a>Comparision with other models</h2><ul>
<li>深度越深的 resnet 准确率越高，且没有出现退化问题。</li>
<li>实验表明，resnet 要比其他模型要好，且参数和计算量都要少。</li>
</ul>
<img src="/2018/11/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Deep-Residual-Learning-for-Image-Recognition/6.png" class="">
<p>作者还把 resnet 应用到了 CIFAR-10 分类上，且使用了 1000 层的resnet，错误率降低到 1% 以下，这表明 resnet 能够解决深层网络的退化问题。</p>
<p><br></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/29/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Going-deeper-with-convolutions/" rel="next" title="【论文阅读】—— Going deeper with convolutions">
                <i class="fa fa-chevron-left"></i> 【论文阅读】—— Going deeper with convolutions
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E2%80%94%E2%80%94-Identity-Mappings-in-Deep-Residual-Networks/" rel="prev" title="【论文阅读】—— Identity Mappings in Deep Residual Networks">
                【论文阅读】—— Identity Mappings in Deep Residual Networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/ProfilePhoto.jpg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">63</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Vincent-Hoo" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:vincent.ho.2497@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://google.com/" title="Google" target="_blank">Google</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://bing.com/" title="Bing" target="_blank">Bing</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Residual-Learning"><span class="nav-number">1.</span> <span class="nav-text">Residual Learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Why-Resnets-work"><span class="nav-number">2.</span> <span class="nav-text">Why Resnets work?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Identity-Mapping-by-Shortcuts"><span class="nav-number">3.</span> <span class="nav-text">Identity Mapping by Shortcuts</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ResNet%E7%BB%93%E6%9E%84"><span class="nav-number">4.</span> <span class="nav-text">ResNet结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">5.</span> <span class="nav-text">实验结果</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Plain-Network-vs-Residual-Network"><span class="nav-number">5.1.</span> <span class="nav-text">Plain Network vs Residual Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Identity-Mapping-vs-Projection-Shortcuts"><span class="nav-number">5.2.</span> <span class="nav-text">Identity Mapping vs Projection Shortcuts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comparision-with-other-models"><span class="nav-number">5.3.</span> <span class="nav-text">Comparision with other models</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Vincent</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>



  <div class="footer-custom">Thank you so much for visiting the site.</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
